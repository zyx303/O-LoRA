+ export CUDA_DEVICE_ORDER=PCI_BUS_ID
+ CUDA_DEVICE_ORDER=PCI_BUS_ID
+ export TRANSFORMERS_CACHE=/data/yongxi/.cache/huggingface
+ TRANSFORMERS_CACHE=/data/yongxi/.cache/huggingface
++ shuf -i25000-30000 -n1
+ port=28490
+ CUDA_VISIBLE_DEVICES=6,7
+ deepspeed --master_port 28490 src/run_uie_lora.py --do_train --do_predict --predict_with_generate --model_name_or_path initial_model/t5-large --data_dir CL_Benchmark --task_config_dir configs/order1_configs/dbpedia --instruction_file configs/instruction_config.json --instruction_strategy single --output_dir logs_and_outputs/sdlora/order_1/outputs/1-dbpedia --per_device_train_batch_size 8 --per_device_eval_batch_size 128 --gradient_accumulation_steps 1 --learning_rate 1e-03 --num_train_epochs 1 --deepspeed configs/ds_configs/stage2.config --run_name order1_round1_sdlora --max_source_length 512 --max_target_length 50 --generation_max_length 50 --add_task_name True --add_dataset_name True --overwrite_output_dir --overwrite_cache --lr_scheduler_type constant --warmup_steps 0 --logging_strategy steps --logging_steps 10 --evaluation_strategy no --save_strategy no --save_steps 1500 --lamda_1 1 --lamda_2 0 --peft_type SDLORA
[2025-08-27 18:18:23,873] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-08-27 18:18:24,983] [WARNING] [runner.py:196:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=6,7: setting --include=localhost:6,7
[2025-08-27 18:18:25,040] [INFO] [runner.py:555:main] cmd = /home/yongxi/miniconda3/envs/sd-lora/bin/python3.10 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbNiwgN119 --master_addr=127.0.0.1 --master_port=28490 --enable_each_rank_log=None src/run_uie_lora.py --do_train --do_predict --predict_with_generate --model_name_or_path initial_model/t5-large --data_dir CL_Benchmark --task_config_dir configs/order1_configs/dbpedia --instruction_file configs/instruction_config.json --instruction_strategy single --output_dir logs_and_outputs/sdlora/order_1/outputs/1-dbpedia --per_device_train_batch_size 8 --per_device_eval_batch_size 128 --gradient_accumulation_steps 1 --learning_rate 1e-03 --num_train_epochs 1 --deepspeed configs/ds_configs/stage2.config --run_name order1_round1_sdlora --max_source_length 512 --max_target_length 50 --generation_max_length 50 --add_task_name True --add_dataset_name True --overwrite_output_dir --overwrite_cache --lr_scheduler_type constant --warmup_steps 0 --logging_strategy steps --logging_steps 10 --evaluation_strategy no --save_strategy no --save_steps 1500 --lamda_1 1 --lamda_2 0 --peft_type SDLORA
[2025-08-27 18:18:26,195] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-08-27 18:18:27,516] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [6, 7]}
[2025-08-27 18:18:27,516] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=2, node_rank=0
[2025-08-27 18:18:27,516] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1]})
[2025-08-27 18:18:27,516] [INFO] [launch.py:163:main] dist_world_size=2
[2025-08-27 18:18:27,516] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=6,7
[2025-08-27 18:18:30,067] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-27 18:18:30,068] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/fairscale/experimental/nn/offload.py:19: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_fwd(orig_func)  # type: ignore
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/fairscale/experimental/nn/offload.py:30: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_bwd(orig_func)  # type: ignore
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/fairscale/experimental/nn/offload.py:19: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_fwd(orig_func)  # type: ignore
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/fairscale/experimental/nn/offload.py:30: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_bwd(orig_func)  # type: ignore
[2025-08-27 18:18:30,959] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2025-08-27 18:18:30,959] [INFO] [comm.py:616:init_distributed] cdb=None
[2025-08-27 18:18:30,959] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-08-27 18:18:30,984] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2025-08-27 18:18:30,984] [INFO] [comm.py:616:init_distributed] cdb=None
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
08/27/2025 18:18:31 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
08/27/2025 18:18:31 - WARNING - datasets.builder - Using custom data configuration default-8a6abe4434e90f8a
08/27/2025 18:18:31 - WARNING - datasets.builder - Reusing dataset uie_instructions (logs_and_outputs/sdlora/order_1/outputs/1-dbpedia/17925c6a81583bc3da5a4b7d196aba0a/uie_instructions/default-8a6abe4434e90f8a/2.0.0/c490e7f13dec80785fc335819009163a45c86ae2816040c8d81800108e7e4374)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 721.04it/s]
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
08/27/2025 18:18:31 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: False
08/27/2025 18:18:31 - WARNING - datasets.builder - Using custom data configuration default-8a6abe4434e90f8a
08/27/2025 18:18:31 - WARNING - datasets.builder - Reusing dataset uie_instructions (logs_and_outputs/sdlora/order_1/outputs/1-dbpedia/17925c6a81583bc3da5a4b7d196aba0a/uie_instructions/default-8a6abe4434e90f8a/2.0.0/c490e7f13dec80785fc335819009163a45c86ae2816040c8d81800108e7e4374)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 691.25it/s]
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/torch/nn/init.py:511: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/torch/nn/init.py:511: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
-----Gradient checkpointing: False -----
-----Gradient checkpointing: False -----
[93m [WARNING] [0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!
Using /home/yongxi/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /home/yongxi/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[93m [WARNING] [0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!
Using /home/yongxi/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.3437161445617676 seconds
Rank: 1 partition count [2] and sizes[(1179648, False)] 
[rank1]:[W827 18:18:42.580850332 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.4521124362945557 seconds
Rank: 0 partition count [2] and sizes[(1179648, False)] 
[rank0]:[W827 18:18:42.660929576 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3596: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  warnings.warn(
  0%|          | 0/875 [00:00<?, ?it/s]/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3596: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  warnings.warn(
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1830: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1830: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
  0%|          | 1/875 [00:00<10:40,  1.36it/s]  0%|          | 2/875 [00:01<08:25,  1.73it/s]  0%|          | 3/875 [00:01<07:32,  1.93it/s]  0%|          | 4/875 [00:02<07:08,  2.03it/s]  1%|          | 5/875 [00:02<07:48,  1.86it/s]  1%|          | 6/875 [00:03<07:24,  1.95it/s]  1%|          | 7/875 [00:03<07:10,  2.01it/s]  1%|          | 8/875 [00:04<07:00,  2.06it/s]  1%|          | 9/875 [00:04<06:54,  2.09it/s]  1%|          | 10/875 [00:05<06:49,  2.11it/s]                                                {'loss': 3.3021, 'learning_rate': 0.001, 'epoch': 0.01}
  1%|          | 10/875 [00:05<06:49,  2.11it/s]  1%|▏         | 11/875 [00:05<06:44,  2.14it/s]  1%|▏         | 12/875 [00:05<06:42,  2.14it/s]  1%|▏         | 13/875 [00:06<06:37,  2.17it/s]  2%|▏         | 14/875 [00:06<06:35,  2.18it/s]  2%|▏         | 15/875 [00:07<06:34,  2.18it/s]  2%|▏         | 16/875 [00:07<06:35,  2.17it/s]  2%|▏         | 17/875 [00:08<06:35,  2.17it/s]  2%|▏         | 18/875 [00:08<06:35,  2.17it/s]  2%|▏         | 19/875 [00:09<06:33,  2.18it/s]  2%|▏         | 20/875 [00:09<06:29,  2.19it/s]                                                {'loss': 0.2664, 'learning_rate': 0.001, 'epoch': 0.02}
  2%|▏         | 20/875 [00:09<06:29,  2.19it/s]  2%|▏         | 21/875 [00:10<06:28,  2.20it/s]  3%|▎         | 22/875 [00:10<06:26,  2.21it/s]  3%|▎         | 23/875 [00:10<06:23,  2.22it/s]  3%|▎         | 24/875 [00:11<06:27,  2.19it/s]  3%|▎         | 25/875 [00:11<06:27,  2.19it/s]  3%|▎         | 26/875 [00:12<06:25,  2.20it/s]  3%|▎         | 27/875 [00:12<06:25,  2.20it/s]  3%|▎         | 28/875 [00:13<06:24,  2.20it/s]  3%|▎         | 29/875 [00:13<06:29,  2.17it/s]  3%|▎         | 30/875 [00:14<06:30,  2.16it/s]                                                {'loss': 0.1654, 'learning_rate': 0.001, 'epoch': 0.03}
  3%|▎         | 30/875 [00:14<06:30,  2.16it/s]  4%|▎         | 31/875 [00:14<06:31,  2.16it/s]  4%|▎         | 32/875 [00:15<06:30,  2.16it/s]  4%|▍         | 33/875 [00:15<06:30,  2.16it/s]  4%|▍         | 34/875 [00:16<06:31,  2.15it/s]  4%|▍         | 35/875 [00:16<06:31,  2.14it/s]  4%|▍         | 36/875 [00:16<06:30,  2.15it/s]  4%|▍         | 37/875 [00:17<06:30,  2.15it/s]  4%|▍         | 38/875 [00:17<06:31,  2.14it/s]  4%|▍         | 39/875 [00:18<06:31,  2.14it/s]  5%|▍         | 40/875 [00:18<06:32,  2.13it/s]                                                {'loss': 0.1537, 'learning_rate': 0.001, 'epoch': 0.05}
  5%|▍         | 40/875 [00:18<06:32,  2.13it/s]  5%|▍         | 41/875 [00:19<06:29,  2.14it/s]  5%|▍         | 42/875 [00:19<06:29,  2.14it/s]  5%|▍         | 43/875 [00:20<06:28,  2.14it/s]  5%|▌         | 44/875 [00:20<06:27,  2.14it/s]  5%|▌         | 45/875 [00:21<06:26,  2.15it/s]  5%|▌         | 46/875 [00:21<06:26,  2.14it/s]  5%|▌         | 47/875 [00:22<06:29,  2.13it/s]  5%|▌         | 48/875 [00:22<06:29,  2.12it/s]  6%|▌         | 49/875 [00:23<06:26,  2.14it/s]  6%|▌         | 50/875 [00:23<06:26,  2.13it/s]                                                {'loss': 0.1132, 'learning_rate': 0.001, 'epoch': 0.06}
  6%|▌         | 50/875 [00:23<06:26,  2.13it/s]  6%|▌         | 51/875 [00:23<06:26,  2.13it/s]  6%|▌         | 52/875 [00:24<06:24,  2.14it/s]  6%|▌         | 53/875 [00:24<06:24,  2.14it/s]  6%|▌         | 54/875 [00:25<06:25,  2.13it/s]  6%|▋         | 55/875 [00:25<06:26,  2.12it/s]  6%|▋         | 56/875 [00:26<06:24,  2.13it/s]  7%|▋         | 57/875 [00:26<06:23,  2.14it/s]  7%|▋         | 58/875 [00:27<06:22,  2.14it/s]  7%|▋         | 59/875 [00:27<06:24,  2.12it/s]  7%|▋         | 60/875 [00:28<06:25,  2.12it/s]                                                {'loss': 0.0349, 'learning_rate': 0.001, 'epoch': 0.07}
  7%|▋         | 60/875 [00:28<06:25,  2.12it/s]  7%|▋         | 61/875 [00:28<06:24,  2.12it/s]  7%|▋         | 62/875 [00:29<06:26,  2.10it/s]  7%|▋         | 63/875 [00:29<06:26,  2.10it/s]  7%|▋         | 64/875 [00:30<06:24,  2.11it/s]  7%|▋         | 65/875 [00:30<06:22,  2.12it/s]  8%|▊         | 66/875 [00:31<06:20,  2.13it/s]  8%|▊         | 67/875 [00:31<06:18,  2.13it/s]  8%|▊         | 68/875 [00:31<06:17,  2.14it/s]  8%|▊         | 69/875 [00:32<06:14,  2.15it/s]  8%|▊         | 70/875 [00:32<06:12,  2.16it/s]                                                {'loss': 0.1712, 'learning_rate': 0.001, 'epoch': 0.08}
  8%|▊         | 70/875 [00:32<06:12,  2.16it/s]  8%|▊         | 71/875 [00:33<06:11,  2.17it/s]  8%|▊         | 72/875 [00:33<06:10,  2.17it/s]  8%|▊         | 73/875 [00:34<06:11,  2.16it/s]  8%|▊         | 74/875 [00:34<06:09,  2.17it/s]  9%|▊         | 75/875 [00:35<06:05,  2.19it/s]  9%|▊         | 76/875 [00:35<06:04,  2.19it/s]  9%|▉         | 77/875 [00:36<06:35,  2.02it/s]  9%|▉         | 78/875 [00:36<06:29,  2.04it/s]  9%|▉         | 79/875 [00:37<06:58,  1.90it/s]  9%|▉         | 80/875 [00:37<06:42,  1.97it/s]                                                {'loss': 0.0285, 'learning_rate': 0.001, 'epoch': 0.09}
  9%|▉         | 80/875 [00:37<06:42,  1.97it/s]  9%|▉         | 81/875 [00:38<06:34,  2.01it/s]  9%|▉         | 82/875 [00:38<06:29,  2.03it/s]  9%|▉         | 83/875 [00:39<06:23,  2.06it/s] 10%|▉         | 84/875 [00:39<06:18,  2.09it/s] 10%|▉         | 85/875 [00:40<06:12,  2.12it/s] 10%|▉         | 86/875 [00:40<06:07,  2.14it/s] 10%|▉         | 87/875 [00:41<06:02,  2.17it/s] 10%|█         | 88/875 [00:41<05:59,  2.19it/s] 10%|█         | 89/875 [00:41<05:58,  2.19it/s] 10%|█         | 90/875 [00:42<05:57,  2.20it/s]                                                {'loss': 0.0481, 'learning_rate': 0.001, 'epoch': 0.1}
 10%|█         | 90/875 [00:42<05:57,  2.20it/s] 10%|█         | 91/875 [00:42<05:57,  2.19it/s] 11%|█         | 92/875 [00:43<06:17,  2.08it/s] 11%|█         | 93/875 [00:43<06:10,  2.11it/s] 11%|█         | 94/875 [00:44<06:04,  2.14it/s] 11%|█         | 95/875 [00:44<05:59,  2.17it/s] 11%|█         | 96/875 [00:45<05:56,  2.19it/s] 11%|█         | 97/875 [00:45<05:54,  2.20it/s] 11%|█         | 98/875 [00:46<06:31,  1.98it/s] 11%|█▏        | 99/875 [00:46<06:23,  2.02it/s] 11%|█▏        | 100/875 [00:47<06:16,  2.06it/s]                                                 {'loss': 0.0764, 'learning_rate': 0.001, 'epoch': 0.11}
 11%|█▏        | 100/875 [00:47<06:16,  2.06it/s] 12%|█▏        | 101/875 [00:47<06:44,  1.91it/s] 12%|█▏        | 102/875 [00:48<06:29,  1.98it/s] 12%|█▏        | 103/875 [00:48<06:21,  2.02it/s] 12%|█▏        | 104/875 [00:49<06:18,  2.04it/s] 12%|█▏        | 105/875 [00:49<06:12,  2.07it/s] 12%|█▏        | 106/875 [00:50<06:06,  2.10it/s] 12%|█▏        | 107/875 [00:50<06:03,  2.11it/s] 12%|█▏        | 108/875 [00:51<06:02,  2.11it/s] 12%|█▏        | 109/875 [00:51<06:01,  2.12it/s] 13%|█▎        | 110/875 [00:52<05:59,  2.13it/s]                                                 {'loss': 0.0569, 'learning_rate': 0.001, 'epoch': 0.13}
 13%|█▎        | 110/875 [00:52<05:59,  2.13it/s] 13%|█▎        | 111/875 [00:52<05:58,  2.13it/s] 13%|█▎        | 112/875 [00:52<05:58,  2.13it/s] 13%|█▎        | 113/875 [00:53<05:57,  2.13it/s] 13%|█▎        | 114/875 [00:53<05:57,  2.13it/s] 13%|█▎        | 115/875 [00:54<05:56,  2.13it/s] 13%|█▎        | 116/875 [00:54<05:55,  2.14it/s] 13%|█▎        | 117/875 [00:55<06:28,  1.95it/s] 13%|█▎        | 118/875 [00:55<06:17,  2.01it/s] 14%|█▎        | 119/875 [00:56<06:09,  2.05it/s] 14%|█▎        | 120/875 [00:56<06:03,  2.07it/s]                                                 {'loss': 0.1131, 'learning_rate': 0.001, 'epoch': 0.14}
 14%|█▎        | 120/875 [00:56<06:03,  2.07it/s] 14%|█▍        | 121/875 [00:57<06:03,  2.08it/s] 14%|█▍        | 122/875 [00:57<06:00,  2.09it/s] 14%|█▍        | 123/875 [00:58<06:01,  2.08it/s] 14%|█▍        | 124/875 [00:58<05:57,  2.10it/s] 14%|█▍        | 125/875 [00:59<05:56,  2.10it/s] 14%|█▍        | 126/875 [00:59<05:54,  2.12it/s] 15%|█▍        | 127/875 [01:00<05:51,  2.13it/s] 15%|█▍        | 128/875 [01:00<05:49,  2.14it/s] 15%|█▍        | 129/875 [01:01<05:47,  2.15it/s] 15%|█▍        | 130/875 [01:01<05:48,  2.14it/s]                                                 {'loss': 0.0539, 'learning_rate': 0.001, 'epoch': 0.15}
 15%|█▍        | 130/875 [01:01<05:48,  2.14it/s] 15%|█▍        | 131/875 [01:02<06:19,  1.96it/s] 15%|█▌        | 132/875 [01:02<06:08,  2.01it/s] 15%|█▌        | 133/875 [01:03<06:01,  2.05it/s] 15%|█▌        | 134/875 [01:03<05:56,  2.08it/s] 15%|█▌        | 135/875 [01:04<05:52,  2.10it/s] 16%|█▌        | 136/875 [01:04<05:49,  2.11it/s] 16%|█▌        | 137/875 [01:04<05:47,  2.12it/s] 16%|█▌        | 138/875 [01:05<05:47,  2.12it/s] 16%|█▌        | 139/875 [01:05<05:50,  2.10it/s] 16%|█▌        | 140/875 [01:06<05:49,  2.10it/s]                                                 {'loss': 0.0202, 'learning_rate': 0.001, 'epoch': 0.16}
 16%|█▌        | 140/875 [01:06<05:49,  2.10it/s] 16%|█▌        | 141/875 [01:06<05:49,  2.10it/s] 16%|█▌        | 142/875 [01:07<05:47,  2.11it/s] 16%|█▋        | 143/875 [01:07<05:46,  2.11it/s] 16%|█▋        | 144/875 [01:08<05:43,  2.13it/s] 17%|█▋        | 145/875 [01:08<05:42,  2.13it/s] 17%|█▋        | 146/875 [01:09<05:42,  2.13it/s] 17%|█▋        | 147/875 [01:09<05:41,  2.13it/s] 17%|█▋        | 148/875 [01:10<05:42,  2.12it/s] 17%|█▋        | 149/875 [01:10<05:42,  2.12it/s] 17%|█▋        | 150/875 [01:11<05:41,  2.12it/s]                                                 {'loss': 0.1554, 'learning_rate': 0.001, 'epoch': 0.17}
 17%|█▋        | 150/875 [01:11<05:41,  2.12it/s] 17%|█▋        | 151/875 [01:11<05:40,  2.12it/s] 17%|█▋        | 152/875 [01:12<05:40,  2.13it/s] 17%|█▋        | 153/875 [01:12<05:38,  2.13it/s] 18%|█▊        | 154/875 [01:12<05:37,  2.14it/s] 18%|█▊        | 155/875 [01:13<05:37,  2.14it/s] 18%|█▊        | 156/875 [01:13<05:36,  2.13it/s] 18%|█▊        | 157/875 [01:14<05:37,  2.13it/s] 18%|█▊        | 158/875 [01:14<06:06,  1.96it/s] 18%|█▊        | 159/875 [01:15<05:57,  2.00it/s] 18%|█▊        | 160/875 [01:15<05:50,  2.04it/s]                                                 {'loss': 0.0608, 'learning_rate': 0.001, 'epoch': 0.18}
 18%|█▊        | 160/875 [01:15<05:50,  2.04it/s] 18%|█▊        | 161/875 [01:16<05:46,  2.06it/s] 19%|█▊        | 162/875 [01:16<05:40,  2.09it/s] 19%|█▊        | 163/875 [01:17<05:33,  2.13it/s] 19%|█▊        | 164/875 [01:17<05:29,  2.15it/s] 19%|█▉        | 165/875 [01:18<05:27,  2.17it/s] 19%|█▉        | 166/875 [01:18<05:24,  2.18it/s] 19%|█▉        | 167/875 [01:19<05:23,  2.19it/s] 19%|█▉        | 168/875 [01:19<05:21,  2.20it/s] 19%|█▉        | 169/875 [01:20<05:20,  2.20it/s] 19%|█▉        | 170/875 [01:20<05:50,  2.01it/s]                                                 {'loss': 0.0632, 'learning_rate': 0.001, 'epoch': 0.19}
 19%|█▉        | 170/875 [01:20<05:50,  2.01it/s] 20%|█▉        | 171/875 [01:21<05:40,  2.07it/s] 20%|█▉        | 172/875 [01:21<05:33,  2.11it/s] 20%|█▉        | 173/875 [01:21<05:29,  2.13it/s] 20%|█▉        | 174/875 [01:22<05:25,  2.15it/s] 20%|██        | 175/875 [01:22<05:23,  2.17it/s] 20%|██        | 176/875 [01:23<05:19,  2.19it/s] 20%|██        | 177/875 [01:23<05:17,  2.20it/s] 20%|██        | 178/875 [01:24<05:15,  2.21it/s] 20%|██        | 179/875 [01:24<05:15,  2.21it/s] 21%|██        | 180/875 [01:25<05:14,  2.21it/s]                                                 {'loss': 0.0184, 'learning_rate': 0.001, 'epoch': 0.21}
 21%|██        | 180/875 [01:25<05:14,  2.21it/s] 21%|██        | 181/875 [01:25<05:48,  1.99it/s] 21%|██        | 182/875 [01:26<05:42,  2.02it/s] 21%|██        | 183/875 [01:26<05:39,  2.04it/s] 21%|██        | 184/875 [01:27<05:34,  2.06it/s] 21%|██        | 185/875 [01:27<05:30,  2.09it/s] 21%|██▏       | 186/875 [01:28<05:26,  2.11it/s] 21%|██▏       | 187/875 [01:28<05:24,  2.12it/s] 21%|██▏       | 188/875 [01:29<05:23,  2.12it/s] 22%|██▏       | 189/875 [01:29<05:23,  2.12it/s] 22%|██▏       | 190/875 [01:29<05:22,  2.12it/s]                                                 {'loss': 0.0427, 'learning_rate': 0.001, 'epoch': 0.22}
 22%|██▏       | 190/875 [01:29<05:22,  2.12it/s] 22%|██▏       | 191/875 [01:30<05:23,  2.12it/s] 22%|██▏       | 192/875 [01:31<05:51,  1.94it/s] 22%|██▏       | 193/875 [01:31<05:43,  1.99it/s] 22%|██▏       | 194/875 [01:32<05:36,  2.03it/s] 22%|██▏       | 195/875 [01:32<05:31,  2.05it/s] 22%|██▏       | 196/875 [01:32<05:27,  2.07it/s] 23%|██▎       | 197/875 [01:33<05:25,  2.08it/s] 23%|██▎       | 198/875 [01:33<05:22,  2.10it/s] 23%|██▎       | 199/875 [01:34<05:20,  2.11it/s] 23%|██▎       | 200/875 [01:34<05:20,  2.10it/s]                                                 {'loss': 0.004, 'learning_rate': 0.001, 'epoch': 0.23}
 23%|██▎       | 200/875 [01:34<05:20,  2.10it/s] 23%|██▎       | 201/875 [01:35<05:19,  2.11it/s] 23%|██▎       | 202/875 [01:35<05:17,  2.12it/s] 23%|██▎       | 203/875 [01:36<05:16,  2.12it/s] 23%|██▎       | 204/875 [01:36<05:15,  2.13it/s] 23%|██▎       | 205/875 [01:37<05:14,  2.13it/s] 24%|██▎       | 206/875 [01:37<05:13,  2.13it/s] 24%|██▎       | 207/875 [01:38<05:12,  2.14it/s] 24%|██▍       | 208/875 [01:38<05:11,  2.14it/s] 24%|██▍       | 209/875 [01:39<05:13,  2.13it/s] 24%|██▍       | 210/875 [01:39<05:13,  2.12it/s]                                                 {'loss': 0.1018, 'learning_rate': 0.001, 'epoch': 0.24}
 24%|██▍       | 210/875 [01:39<05:13,  2.12it/s] 24%|██▍       | 211/875 [01:40<05:13,  2.12it/s] 24%|██▍       | 212/875 [01:40<05:13,  2.11it/s] 24%|██▍       | 213/875 [01:40<05:13,  2.11it/s] 24%|██▍       | 214/875 [01:41<05:13,  2.11it/s] 25%|██▍       | 215/875 [01:41<05:14,  2.10it/s] 25%|██▍       | 216/875 [01:42<05:10,  2.12it/s] 25%|██▍       | 217/875 [01:42<05:05,  2.15it/s] 25%|██▍       | 218/875 [01:43<05:02,  2.17it/s] 25%|██▌       | 219/875 [01:43<05:29,  1.99it/s] 25%|██▌       | 220/875 [01:44<05:20,  2.04it/s]                                                 {'loss': 0.0707, 'learning_rate': 0.001, 'epoch': 0.25}
 25%|██▌       | 220/875 [01:44<05:20,  2.04it/s] 25%|██▌       | 221/875 [01:44<05:13,  2.09it/s] 25%|██▌       | 222/875 [01:45<05:07,  2.12it/s] 25%|██▌       | 223/875 [01:45<05:03,  2.15it/s] 26%|██▌       | 224/875 [01:46<04:59,  2.17it/s] 26%|██▌       | 225/875 [01:46<04:58,  2.18it/s] 26%|██▌       | 226/875 [01:47<04:56,  2.19it/s] 26%|██▌       | 227/875 [01:47<04:54,  2.20it/s] 26%|██▌       | 228/875 [01:47<04:54,  2.20it/s] 26%|██▌       | 229/875 [01:48<04:53,  2.20it/s] 26%|██▋       | 230/875 [01:48<04:53,  2.20it/s]                                                 {'loss': 0.0587, 'learning_rate': 0.001, 'epoch': 0.26}
 26%|██▋       | 230/875 [01:48<04:53,  2.20it/s] 26%|██▋       | 231/875 [01:49<04:54,  2.18it/s] 27%|██▋       | 232/875 [01:49<04:52,  2.19it/s] 27%|██▋       | 233/875 [01:50<04:51,  2.20it/s] 27%|██▋       | 234/875 [01:50<04:50,  2.21it/s] 27%|██▋       | 235/875 [01:51<04:49,  2.21it/s] 27%|██▋       | 236/875 [01:51<04:49,  2.21it/s] 27%|██▋       | 237/875 [01:52<04:50,  2.19it/s] 27%|██▋       | 238/875 [01:52<04:50,  2.19it/s] 27%|██▋       | 239/875 [01:52<04:48,  2.20it/s] 27%|██▋       | 240/875 [01:53<04:49,  2.19it/s]                                                 {'loss': 0.0729, 'learning_rate': 0.001, 'epoch': 0.27}
 27%|██▋       | 240/875 [01:53<04:49,  2.19it/s] 28%|██▊       | 241/875 [01:53<04:51,  2.18it/s] 28%|██▊       | 242/875 [01:54<04:51,  2.17it/s] 28%|██▊       | 243/875 [01:54<04:52,  2.16it/s] 28%|██▊       | 244/875 [01:55<04:54,  2.14it/s] 28%|██▊       | 245/875 [01:55<04:55,  2.13it/s] 28%|██▊       | 246/875 [01:56<04:53,  2.14it/s] 28%|██▊       | 247/875 [01:56<04:52,  2.14it/s] 28%|██▊       | 248/875 [01:57<04:52,  2.15it/s] 28%|██▊       | 249/875 [01:57<04:49,  2.17it/s] 29%|██▊       | 250/875 [01:58<04:46,  2.18it/s]                                                 {'loss': 0.0202, 'learning_rate': 0.001, 'epoch': 0.29}
 29%|██▊       | 250/875 [01:58<04:46,  2.18it/s] 29%|██▊       | 251/875 [01:58<04:46,  2.18it/s] 29%|██▉       | 252/875 [01:59<04:49,  2.15it/s] 29%|██▉       | 253/875 [01:59<04:49,  2.15it/s] 29%|██▉       | 254/875 [01:59<04:49,  2.15it/s] 29%|██▉       | 255/875 [02:00<04:48,  2.15it/s] 29%|██▉       | 256/875 [02:00<04:47,  2.15it/s] 29%|██▉       | 257/875 [02:01<04:47,  2.15it/s] 29%|██▉       | 258/875 [02:01<04:48,  2.14it/s] 30%|██▉       | 259/875 [02:02<04:47,  2.14it/s] 30%|██▉       | 260/875 [02:02<04:48,  2.14it/s]                                                 {'loss': 0.0492, 'learning_rate': 0.001, 'epoch': 0.3}
 30%|██▉       | 260/875 [02:02<04:48,  2.14it/s] 30%|██▉       | 261/875 [02:03<04:46,  2.14it/s] 30%|██▉       | 262/875 [02:03<04:46,  2.14it/s] 30%|███       | 263/875 [02:04<04:45,  2.15it/s] 30%|███       | 264/875 [02:04<04:44,  2.15it/s] 30%|███       | 265/875 [02:05<04:44,  2.14it/s] 30%|███       | 266/875 [02:05<04:43,  2.15it/s] 31%|███       | 267/875 [02:06<04:42,  2.15it/s] 31%|███       | 268/875 [02:06<04:43,  2.14it/s] 31%|███       | 269/875 [02:06<04:43,  2.14it/s] 31%|███       | 270/875 [02:07<04:43,  2.13it/s]                                                 {'loss': 0.0832, 'learning_rate': 0.001, 'epoch': 0.31}
 31%|███       | 270/875 [02:07<04:43,  2.13it/s] 31%|███       | 271/875 [02:07<04:40,  2.16it/s] 31%|███       | 272/875 [02:08<04:38,  2.17it/s] 31%|███       | 273/875 [02:08<04:35,  2.19it/s] 31%|███▏      | 274/875 [02:09<04:33,  2.20it/s] 31%|███▏      | 275/875 [02:09<04:31,  2.21it/s] 32%|███▏      | 276/875 [02:10<04:31,  2.21it/s] 32%|███▏      | 277/875 [02:10<04:32,  2.19it/s] 32%|███▏      | 278/875 [02:11<04:59,  2.00it/s] 32%|███▏      | 279/875 [02:11<04:49,  2.06it/s] 32%|███▏      | 280/875 [02:12<04:44,  2.09it/s]                                                 {'loss': 0.0085, 'learning_rate': 0.001, 'epoch': 0.32}
 32%|███▏      | 280/875 [02:12<04:44,  2.09it/s] 32%|███▏      | 281/875 [02:12<04:41,  2.11it/s] 32%|███▏      | 282/875 [02:13<04:36,  2.14it/s] 32%|███▏      | 283/875 [02:13<04:33,  2.16it/s] 32%|███▏      | 284/875 [02:13<04:33,  2.16it/s] 33%|███▎      | 285/875 [02:14<04:31,  2.18it/s] 33%|███▎      | 286/875 [02:14<04:29,  2.18it/s] 33%|███▎      | 287/875 [02:15<04:28,  2.19it/s] 33%|███▎      | 288/875 [02:15<04:27,  2.20it/s] 33%|███▎      | 289/875 [02:16<04:26,  2.20it/s] 33%|███▎      | 290/875 [02:16<04:24,  2.21it/s]                                                 {'loss': 0.0934, 'learning_rate': 0.001, 'epoch': 0.33}
 33%|███▎      | 290/875 [02:16<04:24,  2.21it/s] 33%|███▎      | 291/875 [02:17<04:24,  2.21it/s] 33%|███▎      | 292/875 [02:17<04:22,  2.22it/s] 33%|███▎      | 293/875 [02:18<04:22,  2.22it/s] 34%|███▎      | 294/875 [02:18<04:22,  2.22it/s] 34%|███▎      | 295/875 [02:18<04:22,  2.21it/s] 34%|███▍      | 296/875 [02:19<04:21,  2.21it/s] 34%|███▍      | 297/875 [02:19<04:21,  2.21it/s] 34%|███▍      | 298/875 [02:20<04:20,  2.21it/s] 34%|███▍      | 299/875 [02:20<04:19,  2.22it/s] 34%|███▍      | 300/875 [02:21<04:20,  2.21it/s]                                                 {'loss': 0.0243, 'learning_rate': 0.001, 'epoch': 0.34}
 34%|███▍      | 300/875 [02:21<04:20,  2.21it/s] 34%|███▍      | 301/875 [02:21<04:20,  2.20it/s] 35%|███▍      | 302/875 [02:22<04:20,  2.20it/s] 35%|███▍      | 303/875 [02:22<04:19,  2.20it/s] 35%|███▍      | 304/875 [02:22<04:18,  2.21it/s] 35%|███▍      | 305/875 [02:23<04:18,  2.21it/s] 35%|███▍      | 306/875 [02:23<04:17,  2.21it/s] 35%|███▌      | 307/875 [02:24<04:17,  2.21it/s] 35%|███▌      | 308/875 [02:24<04:16,  2.21it/s] 35%|███▌      | 309/875 [02:25<04:16,  2.21it/s] 35%|███▌      | 310/875 [02:25<04:16,  2.20it/s]                                                 {'loss': 0.0472, 'learning_rate': 0.001, 'epoch': 0.35}
 35%|███▌      | 310/875 [02:25<04:16,  2.20it/s] 36%|███▌      | 311/875 [02:26<04:17,  2.19it/s] 36%|███▌      | 312/875 [02:26<04:16,  2.20it/s] 36%|███▌      | 313/875 [02:27<04:15,  2.20it/s] 36%|███▌      | 314/875 [02:27<04:15,  2.20it/s] 36%|███▌      | 315/875 [02:27<04:13,  2.21it/s] 36%|███▌      | 316/875 [02:28<04:12,  2.22it/s] 36%|███▌      | 317/875 [02:28<04:11,  2.22it/s] 36%|███▋      | 318/875 [02:29<04:10,  2.22it/s] 36%|███▋      | 319/875 [02:29<04:10,  2.22it/s] 37%|███▋      | 320/875 [02:30<04:09,  2.23it/s]                                                 {'loss': 0.0552, 'learning_rate': 0.001, 'epoch': 0.37}
 37%|███▋      | 320/875 [02:30<04:09,  2.23it/s] 37%|███▋      | 321/875 [02:30<04:09,  2.22it/s] 37%|███▋      | 322/875 [02:31<04:08,  2.22it/s] 37%|███▋      | 323/875 [02:31<04:08,  2.22it/s] 37%|███▋      | 324/875 [02:32<04:08,  2.22it/s] 37%|███▋      | 325/875 [02:32<04:08,  2.21it/s] 37%|███▋      | 326/875 [02:32<04:09,  2.20it/s] 37%|███▋      | 327/875 [02:33<04:07,  2.21it/s] 37%|███▋      | 328/875 [02:33<04:06,  2.22it/s] 38%|███▊      | 329/875 [02:34<04:07,  2.21it/s] 38%|███▊      | 330/875 [02:34<04:10,  2.17it/s]                                                 {'loss': 0.0302, 'learning_rate': 0.001, 'epoch': 0.38}
 38%|███▊      | 330/875 [02:34<04:10,  2.17it/s] 38%|███▊      | 331/875 [02:35<04:12,  2.15it/s] 38%|███▊      | 332/875 [02:35<04:14,  2.14it/s] 38%|███▊      | 333/875 [02:36<04:13,  2.14it/s] 38%|███▊      | 334/875 [02:36<04:13,  2.14it/s] 38%|███▊      | 335/875 [02:37<04:12,  2.14it/s] 38%|███▊      | 336/875 [02:37<04:11,  2.14it/s] 39%|███▊      | 337/875 [02:38<04:11,  2.14it/s] 39%|███▊      | 338/875 [02:38<04:11,  2.13it/s] 39%|███▊      | 339/875 [02:38<04:10,  2.14it/s] 39%|███▉      | 340/875 [02:39<04:09,  2.14it/s]                                                 {'loss': 0.0828, 'learning_rate': 0.001, 'epoch': 0.39}
 39%|███▉      | 340/875 [02:39<04:09,  2.14it/s] 39%|███▉      | 341/875 [02:39<04:11,  2.12it/s] 39%|███▉      | 342/875 [02:40<04:11,  2.12it/s] 39%|███▉      | 343/875 [02:40<04:10,  2.12it/s] 39%|███▉      | 344/875 [02:41<04:09,  2.13it/s] 39%|███▉      | 345/875 [02:41<04:10,  2.11it/s] 40%|███▉      | 346/875 [02:42<04:10,  2.11it/s] 40%|███▉      | 347/875 [02:42<04:08,  2.12it/s] 40%|███▉      | 348/875 [02:43<04:07,  2.13it/s] 40%|███▉      | 349/875 [02:43<04:07,  2.13it/s] 40%|████      | 350/875 [02:44<04:30,  1.94it/s]                                                 {'loss': 0.0456, 'learning_rate': 0.001, 'epoch': 0.4}
 40%|████      | 350/875 [02:44<04:30,  1.94it/s] 40%|████      | 351/875 [02:44<04:22,  1.99it/s] 40%|████      | 352/875 [02:45<04:17,  2.03it/s] 40%|████      | 353/875 [02:45<04:10,  2.09it/s] 40%|████      | 354/875 [02:46<04:05,  2.12it/s] 41%|████      | 355/875 [02:46<04:01,  2.15it/s] 41%|████      | 356/875 [02:47<03:59,  2.17it/s] 41%|████      | 357/875 [02:47<03:57,  2.18it/s] 41%|████      | 358/875 [02:47<03:56,  2.18it/s] 41%|████      | 359/875 [02:48<03:56,  2.18it/s] 41%|████      | 360/875 [02:48<03:55,  2.18it/s]                                                 {'loss': 0.0195, 'learning_rate': 0.001, 'epoch': 0.41}
 41%|████      | 360/875 [02:48<03:55,  2.18it/s] 41%|████▏     | 361/875 [02:49<03:55,  2.19it/s] 41%|████▏     | 362/875 [02:49<03:54,  2.19it/s] 41%|████▏     | 363/875 [02:50<03:53,  2.20it/s] 42%|████▏     | 364/875 [02:50<03:53,  2.19it/s] 42%|████▏     | 365/875 [02:51<04:14,  2.01it/s] 42%|████▏     | 366/875 [02:51<04:07,  2.06it/s] 42%|████▏     | 367/875 [02:52<04:03,  2.09it/s] 42%|████▏     | 368/875 [02:52<03:58,  2.12it/s] 42%|████▏     | 369/875 [02:53<03:56,  2.14it/s] 42%|████▏     | 370/875 [02:53<03:53,  2.16it/s]                                                 {'loss': 0.062, 'learning_rate': 0.001, 'epoch': 0.42}
 42%|████▏     | 370/875 [02:53<03:53,  2.16it/s] 42%|████▏     | 371/875 [02:54<03:56,  2.13it/s] 43%|████▎     | 372/875 [02:54<03:54,  2.15it/s] 43%|████▎     | 373/875 [02:55<03:52,  2.16it/s] 43%|████▎     | 374/875 [02:55<03:50,  2.18it/s] 43%|████▎     | 375/875 [02:55<03:48,  2.19it/s] 43%|████▎     | 376/875 [02:56<03:46,  2.20it/s] 43%|████▎     | 377/875 [02:56<03:45,  2.20it/s] 43%|████▎     | 378/875 [02:57<03:44,  2.21it/s] 43%|████▎     | 379/875 [02:57<03:43,  2.21it/s] 43%|████▎     | 380/875 [02:58<03:43,  2.22it/s]                                                 {'loss': 0.0472, 'learning_rate': 0.001, 'epoch': 0.43}
 43%|████▎     | 380/875 [02:58<03:43,  2.22it/s] 44%|████▎     | 381/875 [02:58<03:44,  2.20it/s] 44%|████▎     | 382/875 [02:59<03:45,  2.18it/s] 44%|████▍     | 383/875 [02:59<03:47,  2.17it/s] 44%|████▍     | 384/875 [03:00<03:48,  2.15it/s] 44%|████▍     | 385/875 [03:00<03:49,  2.13it/s] 44%|████▍     | 386/875 [03:00<03:48,  2.14it/s] 44%|████▍     | 387/875 [03:01<03:46,  2.16it/s] 44%|████▍     | 388/875 [03:01<03:44,  2.17it/s] 44%|████▍     | 389/875 [03:02<03:42,  2.18it/s] 45%|████▍     | 390/875 [03:02<03:41,  2.19it/s]                                                 {'loss': 0.0351, 'learning_rate': 0.001, 'epoch': 0.45}
 45%|████▍     | 390/875 [03:02<03:41,  2.19it/s] 45%|████▍     | 391/875 [03:03<03:39,  2.20it/s] 45%|████▍     | 392/875 [03:03<03:40,  2.19it/s] 45%|████▍     | 393/875 [03:04<03:40,  2.18it/s] 45%|████▌     | 394/875 [03:04<03:40,  2.18it/s] 45%|████▌     | 395/875 [03:05<03:47,  2.11it/s] 45%|████▌     | 396/875 [03:05<03:44,  2.14it/s] 45%|████▌     | 397/875 [03:06<03:40,  2.16it/s] 45%|████▌     | 398/875 [03:06<03:38,  2.18it/s] 46%|████▌     | 399/875 [03:06<03:37,  2.19it/s] 46%|████▌     | 400/875 [03:07<03:38,  2.17it/s]                                                 {'loss': 0.0512, 'learning_rate': 0.001, 'epoch': 0.46}
 46%|████▌     | 400/875 [03:07<03:38,  2.17it/s] 46%|████▌     | 401/875 [03:07<03:39,  2.16it/s] 46%|████▌     | 402/875 [03:08<03:38,  2.17it/s] 46%|████▌     | 403/875 [03:08<03:40,  2.14it/s] 46%|████▌     | 404/875 [03:09<03:38,  2.16it/s] 46%|████▋     | 405/875 [03:09<03:36,  2.17it/s] 46%|████▋     | 406/875 [03:10<03:35,  2.18it/s] 47%|████▋     | 407/875 [03:10<03:35,  2.17it/s] 47%|████▋     | 408/875 [03:11<03:34,  2.18it/s] 47%|████▋     | 409/875 [03:11<03:33,  2.18it/s] 47%|████▋     | 410/875 [03:12<03:32,  2.19it/s]                                                 {'loss': 0.0486, 'learning_rate': 0.001, 'epoch': 0.47}
 47%|████▋     | 410/875 [03:12<03:32,  2.19it/s] 47%|████▋     | 411/875 [03:12<03:31,  2.19it/s] 47%|████▋     | 412/875 [03:12<03:31,  2.19it/s] 47%|████▋     | 413/875 [03:13<03:42,  2.07it/s] 47%|████▋     | 414/875 [03:13<03:40,  2.09it/s] 47%|████▋     | 415/875 [03:14<03:37,  2.11it/s] 48%|████▊     | 416/875 [03:14<03:36,  2.12it/s] 48%|████▊     | 417/875 [03:15<03:35,  2.13it/s] 48%|████▊     | 418/875 [03:15<03:34,  2.13it/s] 48%|████▊     | 419/875 [03:16<03:47,  2.01it/s] 48%|████▊     | 420/875 [03:16<03:40,  2.06it/s]                                                 {'loss': 0.0664, 'learning_rate': 0.001, 'epoch': 0.48}
 48%|████▊     | 420/875 [03:16<03:40,  2.06it/s] 48%|████▊     | 421/875 [03:17<03:35,  2.10it/s] 48%|████▊     | 422/875 [03:17<03:31,  2.14it/s] 48%|████▊     | 423/875 [03:18<03:29,  2.16it/s] 48%|████▊     | 424/875 [03:18<03:26,  2.18it/s] 49%|████▊     | 425/875 [03:19<03:25,  2.19it/s] 49%|████▊     | 426/875 [03:19<03:23,  2.21it/s] 49%|████▉     | 427/875 [03:19<03:22,  2.21it/s] 49%|████▉     | 428/875 [03:20<03:22,  2.20it/s] 49%|████▉     | 429/875 [03:20<03:23,  2.19it/s] 49%|████▉     | 430/875 [03:21<03:22,  2.20it/s]                                                 {'loss': 0.0384, 'learning_rate': 0.001, 'epoch': 0.49}
 49%|████▉     | 430/875 [03:21<03:22,  2.20it/s] 49%|████▉     | 431/875 [03:21<03:22,  2.19it/s] 49%|████▉     | 432/875 [03:22<03:22,  2.19it/s] 49%|████▉     | 433/875 [03:22<03:22,  2.18it/s] 50%|████▉     | 434/875 [03:23<03:21,  2.19it/s] 50%|████▉     | 435/875 [03:23<03:20,  2.19it/s] 50%|████▉     | 436/875 [03:24<03:19,  2.20it/s] 50%|████▉     | 437/875 [03:24<03:20,  2.19it/s] 50%|█████     | 438/875 [03:24<03:20,  2.18it/s] 50%|█████     | 439/875 [03:25<03:18,  2.20it/s] 50%|█████     | 440/875 [03:25<03:17,  2.20it/s]                                                 {'loss': 0.0426, 'learning_rate': 0.001, 'epoch': 0.5}
 50%|█████     | 440/875 [03:25<03:17,  2.20it/s] 50%|█████     | 441/875 [03:26<03:16,  2.21it/s] 51%|█████     | 442/875 [03:26<03:15,  2.21it/s] 51%|█████     | 443/875 [03:27<03:15,  2.21it/s] 51%|█████     | 444/875 [03:27<03:15,  2.20it/s] 51%|█████     | 445/875 [03:28<03:14,  2.21it/s] 51%|█████     | 446/875 [03:28<03:14,  2.20it/s] 51%|█████     | 447/875 [03:29<03:15,  2.19it/s] 51%|█████     | 448/875 [03:29<03:13,  2.20it/s] 51%|█████▏    | 449/875 [03:29<03:12,  2.21it/s] 51%|█████▏    | 450/875 [03:30<03:12,  2.21it/s]                                                 {'loss': 0.0356, 'learning_rate': 0.001, 'epoch': 0.51}
 51%|█████▏    | 450/875 [03:30<03:12,  2.21it/s] 52%|█████▏    | 451/875 [03:30<03:12,  2.21it/s] 52%|█████▏    | 452/875 [03:31<03:12,  2.20it/s] 52%|█████▏    | 453/875 [03:31<03:10,  2.21it/s] 52%|█████▏    | 454/875 [03:32<03:10,  2.21it/s] 52%|█████▏    | 455/875 [03:32<03:10,  2.20it/s] 52%|█████▏    | 456/875 [03:33<03:10,  2.21it/s] 52%|█████▏    | 457/875 [03:33<03:09,  2.21it/s] 52%|█████▏    | 458/875 [03:34<03:08,  2.21it/s] 52%|█████▏    | 459/875 [03:34<03:07,  2.21it/s] 53%|█████▎    | 460/875 [03:34<03:06,  2.22it/s]                                                 {'loss': 0.0304, 'learning_rate': 0.001, 'epoch': 0.53}
 53%|█████▎    | 460/875 [03:34<03:06,  2.22it/s] 53%|█████▎    | 461/875 [03:35<03:06,  2.23it/s] 53%|█████▎    | 462/875 [03:35<03:05,  2.22it/s] 53%|█████▎    | 463/875 [03:36<03:05,  2.22it/s] 53%|█████▎    | 464/875 [03:36<03:04,  2.22it/s] 53%|█████▎    | 465/875 [03:37<03:03,  2.23it/s] 53%|█████▎    | 466/875 [03:37<03:03,  2.23it/s] 53%|█████▎    | 467/875 [03:38<03:03,  2.22it/s] 53%|█████▎    | 468/875 [03:38<03:03,  2.22it/s] 54%|█████▎    | 469/875 [03:39<03:20,  2.03it/s] 54%|█████▎    | 470/875 [03:39<03:14,  2.08it/s]                                                 {'loss': 0.0046, 'learning_rate': 0.001, 'epoch': 0.54}
 54%|█████▎    | 470/875 [03:39<03:14,  2.08it/s] 54%|█████▍    | 471/875 [03:40<03:10,  2.12it/s] 54%|█████▍    | 472/875 [03:40<03:08,  2.13it/s] 54%|█████▍    | 473/875 [03:40<03:06,  2.15it/s] 54%|█████▍    | 474/875 [03:41<03:04,  2.17it/s] 54%|█████▍    | 475/875 [03:41<03:02,  2.19it/s] 54%|█████▍    | 476/875 [03:42<03:01,  2.19it/s] 55%|█████▍    | 477/875 [03:42<03:00,  2.20it/s] 55%|█████▍    | 478/875 [03:43<02:59,  2.21it/s] 55%|█████▍    | 479/875 [03:43<02:59,  2.21it/s] 55%|█████▍    | 480/875 [03:44<02:58,  2.21it/s]                                                 {'loss': 0.069, 'learning_rate': 0.001, 'epoch': 0.55}
 55%|█████▍    | 480/875 [03:44<02:58,  2.21it/s] 55%|█████▍    | 481/875 [03:44<02:58,  2.21it/s] 55%|█████▌    | 482/875 [03:45<03:00,  2.18it/s] 55%|█████▌    | 483/875 [03:45<03:00,  2.17it/s] 55%|█████▌    | 484/875 [03:45<02:59,  2.18it/s] 55%|█████▌    | 485/875 [03:46<02:58,  2.19it/s] 56%|█████▌    | 486/875 [03:46<02:57,  2.19it/s] 56%|█████▌    | 487/875 [03:47<02:56,  2.20it/s] 56%|█████▌    | 488/875 [03:47<03:12,  2.01it/s] 56%|█████▌    | 489/875 [03:48<03:07,  2.06it/s] 56%|█████▌    | 490/875 [03:48<03:02,  2.11it/s]                                                 {'loss': 0.0265, 'learning_rate': 0.001, 'epoch': 0.56}
 56%|█████▌    | 490/875 [03:48<03:02,  2.11it/s] 56%|█████▌    | 491/875 [03:49<02:59,  2.14it/s] 56%|█████▌    | 492/875 [03:49<02:57,  2.15it/s] 56%|█████▋    | 493/875 [03:50<02:56,  2.16it/s] 56%|█████▋    | 494/875 [03:50<02:54,  2.18it/s] 57%|█████▋    | 495/875 [03:51<02:53,  2.18it/s] 57%|█████▋    | 496/875 [03:51<02:52,  2.19it/s] 57%|█████▋    | 497/875 [03:51<02:52,  2.20it/s] 57%|█████▋    | 498/875 [03:52<02:51,  2.19it/s] 57%|█████▋    | 499/875 [03:52<02:52,  2.18it/s] 57%|█████▋    | 500/875 [03:53<02:51,  2.18it/s]                                                 {'loss': 0.0511, 'learning_rate': 0.001, 'epoch': 0.57}
 57%|█████▋    | 500/875 [03:53<02:51,  2.18it/s] 57%|█████▋    | 501/875 [03:53<02:50,  2.19it/s] 57%|█████▋    | 502/875 [03:54<02:50,  2.19it/s] 57%|█████▋    | 503/875 [03:54<02:49,  2.20it/s] 58%|█████▊    | 504/875 [03:55<02:48,  2.20it/s] 58%|█████▊    | 505/875 [03:55<02:47,  2.21it/s] 58%|█████▊    | 506/875 [03:56<02:47,  2.21it/s] 58%|█████▊    | 507/875 [03:56<02:49,  2.17it/s] 58%|█████▊    | 508/875 [03:57<02:57,  2.06it/s] 58%|█████▊    | 509/875 [03:57<02:55,  2.08it/s] 58%|█████▊    | 510/875 [03:58<02:53,  2.10it/s]                                                 {'loss': 0.0197, 'learning_rate': 0.001, 'epoch': 0.58}
 58%|█████▊    | 510/875 [03:58<02:53,  2.10it/s] 58%|█████▊    | 511/875 [03:58<02:52,  2.11it/s] 59%|█████▊    | 512/875 [03:58<02:51,  2.12it/s] 59%|█████▊    | 513/875 [03:59<02:49,  2.13it/s] 59%|█████▊    | 514/875 [03:59<02:48,  2.14it/s] 59%|█████▉    | 515/875 [04:00<02:47,  2.14it/s] 59%|█████▉    | 516/875 [04:00<02:48,  2.14it/s] 59%|█████▉    | 517/875 [04:01<02:48,  2.13it/s] 59%|█████▉    | 518/875 [04:01<02:47,  2.14it/s] 59%|█████▉    | 519/875 [04:02<02:46,  2.14it/s] 59%|█████▉    | 520/875 [04:02<02:46,  2.13it/s]                                                 {'loss': 0.0372, 'learning_rate': 0.001, 'epoch': 0.59}
 59%|█████▉    | 520/875 [04:02<02:46,  2.13it/s] 60%|█████▉    | 521/875 [04:03<02:45,  2.13it/s] 60%|█████▉    | 522/875 [04:03<02:45,  2.14it/s] 60%|█████▉    | 523/875 [04:04<02:44,  2.14it/s] 60%|█████▉    | 524/875 [04:04<02:51,  2.04it/s] 60%|██████    | 525/875 [04:05<02:49,  2.07it/s] 60%|██████    | 526/875 [04:05<02:46,  2.10it/s] 60%|██████    | 527/875 [04:06<02:44,  2.12it/s] 60%|██████    | 528/875 [04:06<02:42,  2.13it/s] 60%|██████    | 529/875 [04:06<02:41,  2.14it/s] 61%|██████    | 530/875 [04:07<02:40,  2.15it/s]                                                 {'loss': 0.0279, 'learning_rate': 0.001, 'epoch': 0.61}
 61%|██████    | 530/875 [04:07<02:40,  2.15it/s] 61%|██████    | 531/875 [04:07<02:39,  2.15it/s] 61%|██████    | 532/875 [04:08<02:39,  2.15it/s] 61%|██████    | 533/875 [04:08<02:39,  2.14it/s] 61%|██████    | 534/875 [04:09<02:38,  2.15it/s] 61%|██████    | 535/875 [04:09<02:38,  2.15it/s] 61%|██████▏   | 536/875 [04:10<02:37,  2.16it/s] 61%|██████▏   | 537/875 [04:10<02:36,  2.16it/s] 61%|██████▏   | 538/875 [04:11<02:35,  2.17it/s] 62%|██████▏   | 539/875 [04:11<02:36,  2.15it/s] 62%|██████▏   | 540/875 [04:12<02:36,  2.14it/s]                                                 {'loss': 0.0212, 'learning_rate': 0.001, 'epoch': 0.62}
 62%|██████▏   | 540/875 [04:12<02:36,  2.14it/s] 62%|██████▏   | 541/875 [04:12<02:35,  2.14it/s] 62%|██████▏   | 542/875 [04:13<02:35,  2.14it/s] 62%|██████▏   | 543/875 [04:13<02:35,  2.14it/s] 62%|██████▏   | 544/875 [04:13<02:34,  2.14it/s] 62%|██████▏   | 545/875 [04:14<02:47,  1.97it/s] 62%|██████▏   | 546/875 [04:15<02:42,  2.02it/s] 63%|██████▎   | 547/875 [04:15<02:39,  2.06it/s] 63%|██████▎   | 548/875 [04:15<02:36,  2.08it/s] 63%|██████▎   | 549/875 [04:16<02:35,  2.10it/s] 63%|██████▎   | 550/875 [04:16<02:33,  2.12it/s]                                                 {'loss': 0.0603, 'learning_rate': 0.001, 'epoch': 0.63}
 63%|██████▎   | 550/875 [04:16<02:33,  2.12it/s] 63%|██████▎   | 551/875 [04:17<02:32,  2.13it/s] 63%|██████▎   | 552/875 [04:17<02:31,  2.13it/s] 63%|██████▎   | 553/875 [04:18<02:30,  2.14it/s] 63%|██████▎   | 554/875 [04:18<02:29,  2.14it/s] 63%|██████▎   | 555/875 [04:19<02:29,  2.14it/s] 64%|██████▎   | 556/875 [04:19<02:29,  2.14it/s] 64%|██████▎   | 557/875 [04:20<02:29,  2.13it/s] 64%|██████▍   | 558/875 [04:20<02:28,  2.13it/s] 64%|██████▍   | 559/875 [04:21<02:27,  2.14it/s] 64%|██████▍   | 560/875 [04:21<02:26,  2.15it/s]                                                 {'loss': 0.0582, 'learning_rate': 0.001, 'epoch': 0.64}
 64%|██████▍   | 560/875 [04:21<02:26,  2.15it/s] 64%|██████▍   | 561/875 [04:22<02:26,  2.14it/s] 64%|██████▍   | 562/875 [04:22<02:25,  2.15it/s] 64%|██████▍   | 563/875 [04:22<02:25,  2.15it/s] 64%|██████▍   | 564/875 [04:23<02:24,  2.15it/s] 65%|██████▍   | 565/875 [04:23<02:24,  2.14it/s] 65%|██████▍   | 566/875 [04:24<02:24,  2.14it/s] 65%|██████▍   | 567/875 [04:24<02:23,  2.15it/s] 65%|██████▍   | 568/875 [04:25<02:22,  2.15it/s] 65%|██████▌   | 569/875 [04:25<02:22,  2.15it/s] 65%|██████▌   | 570/875 [04:26<02:21,  2.15it/s]                                                 {'loss': 0.0305, 'learning_rate': 0.001, 'epoch': 0.65}
 65%|██████▌   | 570/875 [04:26<02:21,  2.15it/s] 65%|██████▌   | 571/875 [04:26<02:21,  2.15it/s] 65%|██████▌   | 572/875 [04:27<02:19,  2.17it/s] 65%|██████▌   | 573/875 [04:27<02:18,  2.19it/s] 66%|██████▌   | 574/875 [04:28<02:17,  2.20it/s] 66%|██████▌   | 575/875 [04:28<02:16,  2.20it/s] 66%|██████▌   | 576/875 [04:28<02:16,  2.20it/s] 66%|██████▌   | 577/875 [04:29<02:15,  2.20it/s] 66%|██████▌   | 578/875 [04:29<02:14,  2.20it/s] 66%|██████▌   | 579/875 [04:30<02:13,  2.21it/s] 66%|██████▋   | 580/875 [04:30<02:13,  2.21it/s]                                                 {'loss': 0.0264, 'learning_rate': 0.001, 'epoch': 0.66}
 66%|██████▋   | 580/875 [04:30<02:13,  2.21it/s] 66%|██████▋   | 581/875 [04:31<02:13,  2.20it/s] 67%|██████▋   | 582/875 [04:31<02:12,  2.21it/s] 67%|██████▋   | 583/875 [04:32<02:12,  2.21it/s] 67%|██████▋   | 584/875 [04:32<02:11,  2.21it/s] 67%|██████▋   | 585/875 [04:32<02:10,  2.22it/s] 67%|██████▋   | 586/875 [04:33<02:10,  2.22it/s] 67%|██████▋   | 587/875 [04:33<02:09,  2.22it/s] 67%|██████▋   | 588/875 [04:34<02:15,  2.12it/s] 67%|██████▋   | 589/875 [04:34<02:13,  2.14it/s] 67%|██████▋   | 590/875 [04:35<02:13,  2.13it/s]                                                 {'loss': 0.0458, 'learning_rate': 0.001, 'epoch': 0.67}
 67%|██████▋   | 590/875 [04:35<02:13,  2.13it/s] 68%|██████▊   | 591/875 [04:35<02:13,  2.12it/s] 68%|██████▊   | 592/875 [04:36<02:12,  2.13it/s] 68%|██████▊   | 593/875 [04:36<02:10,  2.16it/s] 68%|██████▊   | 594/875 [04:37<02:09,  2.17it/s] 68%|██████▊   | 595/875 [04:37<02:08,  2.18it/s] 68%|██████▊   | 596/875 [04:38<02:07,  2.20it/s] 68%|██████▊   | 597/875 [04:38<02:06,  2.20it/s] 68%|██████▊   | 598/875 [04:38<02:05,  2.20it/s] 68%|██████▊   | 599/875 [04:39<02:04,  2.21it/s] 69%|██████▊   | 600/875 [04:39<02:04,  2.22it/s]                                                 {'loss': 0.0067, 'learning_rate': 0.001, 'epoch': 0.69}
 69%|██████▊   | 600/875 [04:39<02:04,  2.22it/s] 69%|██████▊   | 601/875 [04:40<02:03,  2.22it/s] 69%|██████▉   | 602/875 [04:40<02:03,  2.22it/s] 69%|██████▉   | 603/875 [04:41<02:04,  2.19it/s] 69%|██████▉   | 604/875 [04:41<02:03,  2.19it/s] 69%|██████▉   | 605/875 [04:42<02:02,  2.20it/s] 69%|██████▉   | 606/875 [04:42<02:02,  2.20it/s] 69%|██████▉   | 607/875 [04:43<02:01,  2.20it/s] 69%|██████▉   | 608/875 [04:43<02:00,  2.21it/s] 70%|██████▉   | 609/875 [04:43<02:00,  2.20it/s] 70%|██████▉   | 610/875 [04:44<02:00,  2.21it/s]                                                 {'loss': 0.0388, 'learning_rate': 0.001, 'epoch': 0.7}
 70%|██████▉   | 610/875 [04:44<02:00,  2.21it/s] 70%|██████▉   | 611/875 [04:44<01:59,  2.21it/s] 70%|██████▉   | 612/875 [04:45<01:59,  2.20it/s] 70%|███████   | 613/875 [04:45<01:58,  2.21it/s] 70%|███████   | 614/875 [04:46<01:58,  2.20it/s] 70%|███████   | 615/875 [04:46<01:57,  2.21it/s] 70%|███████   | 616/875 [04:47<01:57,  2.20it/s] 71%|███████   | 617/875 [04:47<01:57,  2.20it/s] 71%|███████   | 618/875 [04:48<01:56,  2.20it/s] 71%|███████   | 619/875 [04:48<01:56,  2.20it/s] 71%|███████   | 620/875 [04:48<01:55,  2.20it/s]                                                 {'loss': 0.0492, 'learning_rate': 0.001, 'epoch': 0.71}
 71%|███████   | 620/875 [04:48<01:55,  2.20it/s] 71%|███████   | 621/875 [04:49<01:55,  2.21it/s] 71%|███████   | 622/875 [04:49<01:54,  2.21it/s] 71%|███████   | 623/875 [04:50<01:54,  2.21it/s] 71%|███████▏  | 624/875 [04:50<01:53,  2.21it/s] 71%|███████▏  | 625/875 [04:51<01:52,  2.22it/s] 72%|███████▏  | 626/875 [04:51<01:52,  2.21it/s] 72%|███████▏  | 627/875 [04:52<01:53,  2.18it/s] 72%|███████▏  | 628/875 [04:52<01:53,  2.17it/s] 72%|███████▏  | 629/875 [04:53<01:54,  2.15it/s] 72%|███████▏  | 630/875 [04:53<01:53,  2.15it/s]                                                 {'loss': 0.019, 'learning_rate': 0.001, 'epoch': 0.72}
 72%|███████▏  | 630/875 [04:53<01:53,  2.15it/s] 72%|███████▏  | 631/875 [04:54<01:53,  2.14it/s] 72%|███████▏  | 632/875 [04:54<01:53,  2.15it/s] 72%|███████▏  | 633/875 [04:54<01:53,  2.14it/s] 72%|███████▏  | 634/875 [04:55<01:53,  2.11it/s] 73%|███████▎  | 635/875 [04:55<01:53,  2.12it/s] 73%|███████▎  | 636/875 [04:56<01:52,  2.12it/s] 73%|███████▎  | 637/875 [04:56<01:52,  2.12it/s] 73%|███████▎  | 638/875 [04:57<01:51,  2.13it/s] 73%|███████▎  | 639/875 [04:57<01:51,  2.12it/s] 73%|███████▎  | 640/875 [04:58<01:51,  2.11it/s]                                                 {'loss': 0.0034, 'learning_rate': 0.001, 'epoch': 0.73}
 73%|███████▎  | 640/875 [04:58<01:51,  2.11it/s] 73%|███████▎  | 641/875 [04:58<02:00,  1.94it/s] 73%|███████▎  | 642/875 [04:59<02:07,  1.83it/s] 73%|███████▎  | 643/875 [04:59<02:01,  1.90it/s] 74%|███████▎  | 644/875 [05:00<01:57,  1.97it/s] 74%|███████▎  | 645/875 [05:00<01:54,  2.01it/s] 74%|███████▍  | 646/875 [05:01<01:52,  2.04it/s] 74%|███████▍  | 647/875 [05:01<01:50,  2.06it/s] 74%|███████▍  | 648/875 [05:02<01:49,  2.08it/s] 74%|███████▍  | 649/875 [05:02<01:47,  2.10it/s] 74%|███████▍  | 650/875 [05:03<01:47,  2.10it/s]                                                 {'loss': 0.0491, 'learning_rate': 0.001, 'epoch': 0.74}
 74%|███████▍  | 650/875 [05:03<01:47,  2.10it/s] 74%|███████▍  | 651/875 [05:03<01:47,  2.09it/s] 75%|███████▍  | 652/875 [05:04<01:46,  2.09it/s] 75%|███████▍  | 653/875 [05:04<01:46,  2.09it/s] 75%|███████▍  | 654/875 [05:05<01:45,  2.09it/s] 75%|███████▍  | 655/875 [05:05<01:45,  2.09it/s] 75%|███████▍  | 656/875 [05:06<01:45,  2.08it/s] 75%|███████▌  | 657/875 [05:06<01:44,  2.09it/s] 75%|███████▌  | 658/875 [05:07<01:43,  2.11it/s] 75%|███████▌  | 659/875 [05:07<01:41,  2.12it/s] 75%|███████▌  | 660/875 [05:08<01:40,  2.13it/s]                                                 {'loss': 0.062, 'learning_rate': 0.001, 'epoch': 0.75}
 75%|███████▌  | 660/875 [05:08<01:40,  2.13it/s] 76%|███████▌  | 661/875 [05:08<01:39,  2.16it/s] 76%|███████▌  | 662/875 [05:08<01:38,  2.17it/s] 76%|███████▌  | 663/875 [05:09<01:37,  2.18it/s] 76%|███████▌  | 664/875 [05:09<01:36,  2.19it/s] 76%|███████▌  | 665/875 [05:10<01:35,  2.19it/s] 76%|███████▌  | 666/875 [05:10<01:35,  2.19it/s] 76%|███████▌  | 667/875 [05:11<01:36,  2.16it/s] 76%|███████▋  | 668/875 [05:11<01:35,  2.18it/s] 76%|███████▋  | 669/875 [05:12<01:34,  2.17it/s] 77%|███████▋  | 670/875 [05:12<01:33,  2.18it/s]                                                 {'loss': 0.0126, 'learning_rate': 0.001, 'epoch': 0.77}
 77%|███████▋  | 670/875 [05:12<01:33,  2.18it/s] 77%|███████▋  | 671/875 [05:13<01:33,  2.17it/s] 77%|███████▋  | 672/875 [05:13<01:32,  2.19it/s] 77%|███████▋  | 673/875 [05:13<01:32,  2.19it/s] 77%|███████▋  | 674/875 [05:14<01:31,  2.19it/s] 77%|███████▋  | 675/875 [05:15<01:38,  2.03it/s] 77%|███████▋  | 676/875 [05:15<01:36,  2.07it/s] 77%|███████▋  | 677/875 [05:15<01:34,  2.10it/s] 77%|███████▋  | 678/875 [05:16<01:32,  2.13it/s] 78%|███████▊  | 679/875 [05:16<01:31,  2.15it/s] 78%|███████▊  | 680/875 [05:17<01:29,  2.17it/s]                                                 {'loss': 0.0084, 'learning_rate': 0.001, 'epoch': 0.78}
 78%|███████▊  | 680/875 [05:17<01:29,  2.17it/s] 78%|███████▊  | 681/875 [05:17<01:29,  2.18it/s] 78%|███████▊  | 682/875 [05:18<01:30,  2.14it/s] 78%|███████▊  | 683/875 [05:18<01:28,  2.16it/s] 78%|███████▊  | 684/875 [05:19<01:27,  2.18it/s] 78%|███████▊  | 685/875 [05:19<01:27,  2.18it/s] 78%|███████▊  | 686/875 [05:20<01:26,  2.17it/s] 79%|███████▊  | 687/875 [05:20<01:26,  2.18it/s] 79%|███████▊  | 688/875 [05:20<01:26,  2.15it/s] 79%|███████▊  | 689/875 [05:21<01:27,  2.12it/s] 79%|███████▉  | 690/875 [05:21<01:26,  2.14it/s]                                                 {'loss': 0.0693, 'learning_rate': 0.001, 'epoch': 0.79}
 79%|███████▉  | 690/875 [05:21<01:26,  2.14it/s] 79%|███████▉  | 691/875 [05:22<01:25,  2.15it/s] 79%|███████▉  | 692/875 [05:22<01:24,  2.17it/s] 79%|███████▉  | 693/875 [05:23<01:23,  2.18it/s] 79%|███████▉  | 694/875 [05:23<01:22,  2.19it/s] 79%|███████▉  | 695/875 [05:24<01:22,  2.19it/s] 80%|███████▉  | 696/875 [05:24<01:21,  2.19it/s] 80%|███████▉  | 697/875 [05:25<01:20,  2.20it/s] 80%|███████▉  | 698/875 [05:25<01:20,  2.20it/s] 80%|███████▉  | 699/875 [05:26<01:19,  2.21it/s] 80%|████████  | 700/875 [05:26<01:19,  2.19it/s]                                                 {'loss': 0.0415, 'learning_rate': 0.001, 'epoch': 0.8}
 80%|████████  | 700/875 [05:26<01:19,  2.19it/s] 80%|████████  | 701/875 [05:26<01:19,  2.18it/s] 80%|████████  | 702/875 [05:27<01:19,  2.19it/s] 80%|████████  | 703/875 [05:27<01:18,  2.19it/s] 80%|████████  | 704/875 [05:28<01:18,  2.19it/s] 81%|████████  | 705/875 [05:28<01:17,  2.20it/s] 81%|████████  | 706/875 [05:29<01:18,  2.16it/s] 81%|████████  | 707/875 [05:29<01:17,  2.17it/s] 81%|████████  | 708/875 [05:30<01:16,  2.18it/s] 81%|████████  | 709/875 [05:30<01:15,  2.20it/s] 81%|████████  | 710/875 [05:31<01:15,  2.20it/s]                                                 {'loss': 0.0193, 'learning_rate': 0.001, 'epoch': 0.81}
 81%|████████  | 710/875 [05:31<01:15,  2.20it/s] 81%|████████▏ | 711/875 [05:31<01:14,  2.19it/s] 81%|████████▏ | 712/875 [05:31<01:14,  2.20it/s] 81%|████████▏ | 713/875 [05:32<01:13,  2.21it/s] 82%|████████▏ | 714/875 [05:32<01:13,  2.20it/s] 82%|████████▏ | 715/875 [05:33<01:12,  2.20it/s] 82%|████████▏ | 716/875 [05:33<01:12,  2.20it/s] 82%|████████▏ | 717/875 [05:34<01:12,  2.19it/s] 82%|████████▏ | 718/875 [05:34<01:11,  2.18it/s] 82%|████████▏ | 719/875 [05:35<01:11,  2.18it/s] 82%|████████▏ | 720/875 [05:35<01:11,  2.18it/s]                                                 {'loss': 0.0516, 'learning_rate': 0.001, 'epoch': 0.82}
 82%|████████▏ | 720/875 [05:35<01:11,  2.18it/s] 82%|████████▏ | 721/875 [05:36<01:10,  2.19it/s] 83%|████████▎ | 722/875 [05:36<01:09,  2.19it/s] 83%|████████▎ | 723/875 [05:37<01:09,  2.19it/s] 83%|████████▎ | 724/875 [05:37<01:08,  2.19it/s] 83%|████████▎ | 725/875 [05:37<01:08,  2.19it/s] 83%|████████▎ | 726/875 [05:38<01:07,  2.19it/s] 83%|████████▎ | 727/875 [05:38<01:07,  2.20it/s] 83%|████████▎ | 728/875 [05:39<01:06,  2.21it/s] 83%|████████▎ | 729/875 [05:39<01:05,  2.22it/s] 83%|████████▎ | 730/875 [05:40<01:05,  2.21it/s]                                                 {'loss': 0.0117, 'learning_rate': 0.001, 'epoch': 0.83}
 83%|████████▎ | 730/875 [05:40<01:05,  2.21it/s] 84%|████████▎ | 731/875 [05:40<01:05,  2.21it/s] 84%|████████▎ | 732/875 [05:41<01:04,  2.22it/s] 84%|████████▍ | 733/875 [05:41<01:04,  2.21it/s] 84%|████████▍ | 734/875 [05:41<01:03,  2.21it/s] 84%|████████▍ | 735/875 [05:42<01:03,  2.20it/s] 84%|████████▍ | 736/875 [05:42<01:03,  2.19it/s] 84%|████████▍ | 737/875 [05:43<01:03,  2.19it/s] 84%|████████▍ | 738/875 [05:43<01:02,  2.19it/s] 84%|████████▍ | 739/875 [05:44<01:01,  2.20it/s] 85%|████████▍ | 740/875 [05:44<01:01,  2.19it/s]                                                 {'loss': 0.027, 'learning_rate': 0.001, 'epoch': 0.85}
 85%|████████▍ | 740/875 [05:44<01:01,  2.19it/s] 85%|████████▍ | 741/875 [05:45<01:01,  2.19it/s] 85%|████████▍ | 742/875 [05:45<01:00,  2.20it/s] 85%|████████▍ | 743/875 [05:46<01:00,  2.18it/s] 85%|████████▌ | 744/875 [05:46<01:00,  2.16it/s] 85%|████████▌ | 745/875 [05:47<00:59,  2.17it/s] 85%|████████▌ | 746/875 [05:47<00:59,  2.17it/s] 85%|████████▌ | 747/875 [05:47<00:58,  2.18it/s] 85%|████████▌ | 748/875 [05:48<00:58,  2.18it/s] 86%|████████▌ | 749/875 [05:48<00:57,  2.19it/s] 86%|████████▌ | 750/875 [05:49<00:56,  2.20it/s]                                                 {'loss': 0.0748, 'learning_rate': 0.001, 'epoch': 0.86}
 86%|████████▌ | 750/875 [05:49<00:56,  2.20it/s] 86%|████████▌ | 751/875 [05:49<00:56,  2.19it/s] 86%|████████▌ | 752/875 [05:50<00:56,  2.18it/s] 86%|████████▌ | 753/875 [05:50<00:56,  2.17it/s] 86%|████████▌ | 754/875 [05:51<00:55,  2.17it/s] 86%|████████▋ | 755/875 [05:51<00:55,  2.16it/s] 86%|████████▋ | 756/875 [05:52<00:55,  2.16it/s] 87%|████████▋ | 757/875 [05:52<00:54,  2.15it/s] 87%|████████▋ | 758/875 [05:53<00:53,  2.17it/s] 87%|████████▋ | 759/875 [05:53<00:53,  2.18it/s] 87%|████████▋ | 760/875 [05:53<00:52,  2.19it/s]                                                 {'loss': 0.0066, 'learning_rate': 0.001, 'epoch': 0.87}
 87%|████████▋ | 760/875 [05:53<00:52,  2.19it/s] 87%|████████▋ | 761/875 [05:54<00:51,  2.20it/s] 87%|████████▋ | 762/875 [05:54<00:51,  2.20it/s] 87%|████████▋ | 763/875 [05:55<00:51,  2.19it/s] 87%|████████▋ | 764/875 [05:55<00:50,  2.19it/s] 87%|████████▋ | 765/875 [05:56<00:50,  2.20it/s] 88%|████████▊ | 766/875 [05:56<00:49,  2.20it/s] 88%|████████▊ | 767/875 [05:57<00:49,  2.20it/s] 88%|████████▊ | 768/875 [05:57<00:48,  2.20it/s] 88%|████████▊ | 769/875 [05:58<00:48,  2.19it/s] 88%|████████▊ | 770/875 [05:58<00:48,  2.18it/s]                                                 {'loss': 0.0179, 'learning_rate': 0.001, 'epoch': 0.88}
 88%|████████▊ | 770/875 [05:58<00:48,  2.18it/s] 88%|████████▊ | 771/875 [05:58<00:47,  2.19it/s] 88%|████████▊ | 772/875 [05:59<00:46,  2.19it/s] 88%|████████▊ | 773/875 [05:59<00:46,  2.19it/s] 88%|████████▊ | 774/875 [06:00<00:46,  2.18it/s] 89%|████████▊ | 775/875 [06:00<00:46,  2.17it/s] 89%|████████▊ | 776/875 [06:01<00:45,  2.17it/s] 89%|████████▉ | 777/875 [06:01<00:45,  2.16it/s] 89%|████████▉ | 778/875 [06:02<00:45,  2.15it/s] 89%|████████▉ | 779/875 [06:02<00:44,  2.16it/s] 89%|████████▉ | 780/875 [06:03<00:43,  2.17it/s]                                                 {'loss': 0.0234, 'learning_rate': 0.001, 'epoch': 0.89}
 89%|████████▉ | 780/875 [06:03<00:43,  2.17it/s] 89%|████████▉ | 781/875 [06:03<00:43,  2.18it/s] 89%|████████▉ | 782/875 [06:03<00:42,  2.19it/s] 89%|████████▉ | 783/875 [06:04<00:41,  2.20it/s] 90%|████████▉ | 784/875 [06:04<00:41,  2.19it/s] 90%|████████▉ | 785/875 [06:05<00:41,  2.18it/s] 90%|████████▉ | 786/875 [06:05<00:44,  2.00it/s] 90%|████████▉ | 787/875 [06:06<00:42,  2.06it/s] 90%|█████████ | 788/875 [06:06<00:41,  2.10it/s] 90%|█████████ | 789/875 [06:07<00:44,  1.95it/s] 90%|█████████ | 790/875 [06:07<00:41,  2.03it/s]                                                 {'loss': 0.0475, 'learning_rate': 0.001, 'epoch': 0.9}
 90%|█████████ | 790/875 [06:07<00:41,  2.03it/s] 90%|█████████ | 791/875 [06:08<00:40,  2.08it/s] 91%|█████████ | 792/875 [06:08<00:39,  2.12it/s] 91%|█████████ | 793/875 [06:09<00:38,  2.15it/s] 91%|█████████ | 794/875 [06:09<00:40,  1.98it/s] 91%|█████████ | 795/875 [06:10<00:39,  2.03it/s] 91%|█████████ | 796/875 [06:10<00:37,  2.08it/s] 91%|█████████ | 797/875 [06:11<00:36,  2.12it/s] 91%|█████████ | 798/875 [06:11<00:35,  2.14it/s] 91%|█████████▏| 799/875 [06:12<00:35,  2.16it/s] 91%|█████████▏| 800/875 [06:12<00:34,  2.18it/s]                                                 {'loss': 0.0835, 'learning_rate': 0.001, 'epoch': 0.91}
 91%|█████████▏| 800/875 [06:12<00:34,  2.18it/s] 92%|█████████▏| 801/875 [06:13<00:33,  2.19it/s] 92%|█████████▏| 802/875 [06:13<00:33,  2.20it/s] 92%|█████████▏| 803/875 [06:13<00:32,  2.20it/s] 92%|█████████▏| 804/875 [06:14<00:32,  2.21it/s] 92%|█████████▏| 805/875 [06:14<00:31,  2.21it/s] 92%|█████████▏| 806/875 [06:15<00:31,  2.20it/s] 92%|█████████▏| 807/875 [06:15<00:30,  2.21it/s] 92%|█████████▏| 808/875 [06:16<00:30,  2.22it/s] 92%|█████████▏| 809/875 [06:16<00:29,  2.21it/s] 93%|█████████▎| 810/875 [06:17<00:29,  2.19it/s]                                                 {'loss': 0.0216, 'learning_rate': 0.001, 'epoch': 0.93}
 93%|█████████▎| 810/875 [06:17<00:29,  2.19it/s] 93%|█████████▎| 811/875 [06:17<00:29,  2.19it/s] 93%|█████████▎| 812/875 [06:18<00:28,  2.20it/s] 93%|█████████▎| 813/875 [06:18<00:28,  2.20it/s] 93%|█████████▎| 814/875 [06:18<00:27,  2.19it/s] 93%|█████████▎| 815/875 [06:19<00:27,  2.20it/s] 93%|█████████▎| 816/875 [06:19<00:26,  2.20it/s] 93%|█████████▎| 817/875 [06:20<00:26,  2.20it/s] 93%|█████████▎| 818/875 [06:20<00:26,  2.18it/s] 94%|█████████▎| 819/875 [06:21<00:25,  2.19it/s] 94%|█████████▎| 820/875 [06:21<00:24,  2.20it/s]                                                 {'loss': 0.0377, 'learning_rate': 0.001, 'epoch': 0.94}
 94%|█████████▎| 820/875 [06:21<00:24,  2.20it/s] 94%|█████████▍| 821/875 [06:22<00:24,  2.20it/s] 94%|█████████▍| 822/875 [06:22<00:24,  2.21it/s] 94%|█████████▍| 823/875 [06:23<00:23,  2.21it/s] 94%|█████████▍| 824/875 [06:23<00:23,  2.21it/s] 94%|█████████▍| 825/875 [06:23<00:22,  2.21it/s] 94%|█████████▍| 826/875 [06:24<00:22,  2.18it/s] 95%|█████████▍| 827/875 [06:24<00:22,  2.17it/s] 95%|█████████▍| 828/875 [06:25<00:21,  2.16it/s] 95%|█████████▍| 829/875 [06:25<00:21,  2.18it/s] 95%|█████████▍| 830/875 [06:26<00:22,  2.03it/s]                                                 {'loss': 0.0121, 'learning_rate': 0.001, 'epoch': 0.95}
 95%|█████████▍| 830/875 [06:26<00:22,  2.03it/s] 95%|█████████▍| 831/875 [06:26<00:21,  2.07it/s] 95%|█████████▌| 832/875 [06:27<00:20,  2.11it/s] 95%|█████████▌| 833/875 [06:27<00:19,  2.14it/s] 95%|█████████▌| 834/875 [06:28<00:19,  2.15it/s] 95%|█████████▌| 835/875 [06:28<00:18,  2.17it/s] 96%|█████████▌| 836/875 [06:29<00:17,  2.18it/s] 96%|█████████▌| 837/875 [06:29<00:17,  2.18it/s] 96%|█████████▌| 838/875 [06:30<00:16,  2.18it/s] 96%|█████████▌| 839/875 [06:30<00:16,  2.20it/s] 96%|█████████▌| 840/875 [06:30<00:16,  2.19it/s]                                                 {'loss': 0.0457, 'learning_rate': 0.001, 'epoch': 0.96}
 96%|█████████▌| 840/875 [06:30<00:16,  2.19it/s] 96%|█████████▌| 841/875 [06:31<00:15,  2.19it/s] 96%|█████████▌| 842/875 [06:31<00:15,  2.19it/s] 96%|█████████▋| 843/875 [06:32<00:14,  2.18it/s] 96%|█████████▋| 844/875 [06:32<00:14,  2.19it/s] 97%|█████████▋| 845/875 [06:33<00:13,  2.19it/s] 97%|█████████▋| 846/875 [06:33<00:13,  2.17it/s] 97%|█████████▋| 847/875 [06:34<00:12,  2.19it/s] 97%|█████████▋| 848/875 [06:34<00:12,  2.19it/s] 97%|█████████▋| 849/875 [06:35<00:11,  2.19it/s] 97%|█████████▋| 850/875 [06:35<00:11,  2.19it/s]                                                 {'loss': 0.0546, 'learning_rate': 0.001, 'epoch': 0.97}
 97%|█████████▋| 850/875 [06:35<00:11,  2.19it/s] 97%|█████████▋| 851/875 [06:35<00:10,  2.19it/s] 97%|█████████▋| 852/875 [06:36<00:10,  2.17it/s] 97%|█████████▋| 853/875 [06:36<00:10,  2.19it/s] 98%|█████████▊| 854/875 [06:37<00:09,  2.19it/s] 98%|█████████▊| 855/875 [06:37<00:09,  2.19it/s] 98%|█████████▊| 856/875 [06:38<00:09,  2.00it/s] 98%|█████████▊| 857/875 [06:38<00:08,  2.06it/s] 98%|█████████▊| 858/875 [06:39<00:08,  2.11it/s] 98%|█████████▊| 859/875 [06:39<00:07,  2.13it/s] 98%|█████████▊| 860/875 [06:40<00:06,  2.15it/s]                                                 {'loss': 0.0497, 'learning_rate': 0.001, 'epoch': 0.98}
 98%|█████████▊| 860/875 [06:40<00:06,  2.15it/s] 98%|█████████▊| 861/875 [06:40<00:06,  2.16it/s] 99%|█████████▊| 862/875 [06:41<00:05,  2.17it/s] 99%|█████████▊| 863/875 [06:41<00:05,  2.17it/s] 99%|█████████▊| 864/875 [06:42<00:05,  2.18it/s] 99%|█████████▉| 865/875 [06:42<00:04,  2.19it/s] 99%|█████████▉| 866/875 [06:42<00:04,  2.20it/s] 99%|█████████▉| 867/875 [06:43<00:03,  2.20it/s] 99%|█████████▉| 868/875 [06:43<00:03,  2.21it/s] 99%|█████████▉| 869/875 [06:44<00:02,  2.21it/s] 99%|█████████▉| 870/875 [06:44<00:02,  2.22it/s]                                                 {'loss': 0.0424, 'learning_rate': 0.001, 'epoch': 0.99}
 99%|█████████▉| 870/875 [06:44<00:02,  2.22it/s]100%|█████████▉| 871/875 [06:45<00:01,  2.22it/s]100%|█████████▉| 872/875 [06:45<00:01,  2.18it/s]100%|█████████▉| 873/875 [06:46<00:00,  2.18it/s]100%|█████████▉| 874/875 [06:46<00:00,  2.18it/s]100%|██████████| 875/875 [06:47<00:00,  2.18it/s]                                                 {'train_runtime': 407.0491, 'train_samples_per_second': 34.394, 'train_steps_per_second': 2.15, 'train_loss': 0.08842565536499024, 'epoch': 1.0}
100%|██████████| 875/875 [06:47<00:00,  2.18it/s]100%|██████████| 875/875 [06:47<00:00,  2.15it/s]
***** train metrics *****
  epoch                    =        1.0
  train_loss               =     0.0884
  train_runtime            = 0:06:47.04
  train_samples            =      14000
  train_samples_per_second =     34.394
  train_steps_per_second   =       2.15
  0%|          | 0/30 [00:00<?, ?it/s]  7%|▋         | 2/30 [00:00<00:13,  2.08it/s] 10%|█         | 3/30 [00:01<00:18,  1.45it/s] 13%|█▎        | 4/30 [00:02<00:21,  1.23it/s] 17%|█▋        | 5/30 [00:03<00:21,  1.16it/s] 20%|██        | 6/30 [00:04<00:21,  1.12it/s] 23%|██▎       | 7/30 [00:05<00:20,  1.12it/s] 27%|██▋       | 8/30 [00:06<00:19,  1.13it/s] 30%|███       | 9/30 [00:07<00:19,  1.07it/s] 33%|███▎      | 10/30 [00:08<00:18,  1.10it/s] 37%|███▋      | 11/30 [00:09<00:18,  1.05it/s] 40%|████      | 12/30 [00:10<00:17,  1.04it/s] 43%|████▎     | 13/30 [00:13<00:24,  1.42s/it] 47%|████▋     | 14/30 [00:13<00:20,  1.26s/it] 50%|█████     | 15/30 [00:15<00:18,  1.25s/it] 53%|█████▎    | 16/30 [00:16<00:15,  1.14s/it] 57%|█████▋    | 17/30 [00:16<00:13,  1.07s/it] 60%|██████    | 18/30 [00:17<00:12,  1.02s/it] 63%|██████▎   | 19/30 [00:18<00:10,  1.01it/s] 67%|██████▋   | 20/30 [00:19<00:09,  1.03it/s] 70%|███████   | 21/30 [00:20<00:08,  1.04it/s] 73%|███████▎  | 22/30 [00:23<00:11,  1.42s/it] 77%|███████▋  | 23/30 [00:24<00:09,  1.29s/it] 80%|████████  | 24/30 [00:25<00:07,  1.26s/it] 83%|████████▎ | 25/30 [00:26<00:06,  1.26s/it] 87%|████████▋ | 26/30 [00:27<00:04,  1.22s/it] 90%|█████████ | 27/30 [00:28<00:03,  1.17s/it] 93%|█████████▎| 28/30 [00:29<00:02,  1.16s/it] 97%|█████████▋| 29/30 [00:30<00:01,  1.10s/it]100%|██████████| 30/30 [00:32<00:00,  1.16s/it]100%|██████████| 30/30 [00:35<00:00,  1.18s/it]
***** predict metrics *****
  epoch                           =        1.0
  predict_exact_match             =    98.4211
  predict_exact_match_for_TC      =    98.4211
  predict_exact_match_for_dbpedia =    98.4211
  predict_gen_len                 =     2.6517
  predict_global_step             =        875
  predict_loss                    =     0.0274
  predict_rouge1                  =    98.4211
  predict_rouge1_for_TC           =    98.4211
  predict_rouge1_for_dbpedia      =    98.4211
  predict_rougeL                  =    98.4211
  predict_rougeL_for_TC           =    98.4211
  predict_rougeL_for_dbpedia      =    98.4211
  predict_runtime                 = 0:00:36.71
  predict_samples                 =       7600
  predict_samples_per_second      =    206.987
  predict_steps_per_second        =      0.817
[rank0]:[W827 18:26:07.609333002 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[2025-08-27 18:26:08,997] [INFO] [launch.py:347:main] Process 761455 exits successfully.
[2025-08-27 18:26:08,997] [INFO] [launch.py:347:main] Process 761454 exits successfully.
+ sleep 5
+ CUDA_VISIBLE_DEVICES=6,7
+ deepspeed --master_port 28490 src/run_uie_lora.py --do_train --do_predict --predict_with_generate --model_name_or_path logs_and_outputs/sdlora/order_1/outputs/1-dbpedia/adapter --data_dir CL_Benchmark --task_config_dir configs/order1_configs/amazon --instruction_file configs/instruction_config.json --instruction_strategy single --output_dir logs_and_outputs/sdlora/order_1/outputs/2-amazon --per_device_train_batch_size 8 --per_device_eval_batch_size 128 --gradient_accumulation_steps 1 --learning_rate 1e-03 --num_train_epochs 1 --deepspeed configs/ds_configs/stage2.config --run_name order1_round2_sdlora --max_source_length 512 --max_target_length 50 --generation_max_length 50 --add_task_name True --add_dataset_name True --overwrite_output_dir --overwrite_cache --lr_scheduler_type constant --warmup_steps 0 --logging_strategy steps --logging_steps 10 --evaluation_strategy no --save_strategy no --save_steps 1500 --lamda_1 0.5 --lamda_2 0 --peft_type SDLORA
[2025-08-27 18:26:17,214] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-08-27 18:26:18,338] [WARNING] [runner.py:196:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=6,7: setting --include=localhost:6,7
[2025-08-27 18:26:18,397] [INFO] [runner.py:555:main] cmd = /home/yongxi/miniconda3/envs/sd-lora/bin/python3.10 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbNiwgN119 --master_addr=127.0.0.1 --master_port=28490 --enable_each_rank_log=None src/run_uie_lora.py --do_train --do_predict --predict_with_generate --model_name_or_path logs_and_outputs/sdlora/order_1/outputs/1-dbpedia/adapter --data_dir CL_Benchmark --task_config_dir configs/order1_configs/amazon --instruction_file configs/instruction_config.json --instruction_strategy single --output_dir logs_and_outputs/sdlora/order_1/outputs/2-amazon --per_device_train_batch_size 8 --per_device_eval_batch_size 128 --gradient_accumulation_steps 1 --learning_rate 1e-03 --num_train_epochs 1 --deepspeed configs/ds_configs/stage2.config --run_name order1_round2_sdlora --max_source_length 512 --max_target_length 50 --generation_max_length 50 --add_task_name True --add_dataset_name True --overwrite_output_dir --overwrite_cache --lr_scheduler_type constant --warmup_steps 0 --logging_strategy steps --logging_steps 10 --evaluation_strategy no --save_strategy no --save_steps 1500 --lamda_1 0.5 --lamda_2 0 --peft_type SDLORA
[2025-08-27 18:26:19,554] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-08-27 18:26:20,864] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [6, 7]}
[2025-08-27 18:26:20,864] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=2, node_rank=0
[2025-08-27 18:26:20,864] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1]})
[2025-08-27 18:26:20,864] [INFO] [launch.py:163:main] dist_world_size=2
[2025-08-27 18:26:20,865] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=6,7
[2025-08-27 18:26:23,144] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-27 18:26:23,194] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/fairscale/experimental/nn/offload.py:19: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_fwd(orig_func)  # type: ignore
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/fairscale/experimental/nn/offload.py:30: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_bwd(orig_func)  # type: ignore
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/fairscale/experimental/nn/offload.py:19: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_fwd(orig_func)  # type: ignore
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/fairscale/experimental/nn/offload.py:30: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_bwd(orig_func)  # type: ignore
[2025-08-27 18:26:24,120] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2025-08-27 18:26:24,120] [INFO] [comm.py:616:init_distributed] cdb=None
[2025-08-27 18:26:24,150] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2025-08-27 18:26:24,150] [INFO] [comm.py:616:init_distributed] cdb=None
[2025-08-27 18:26:24,150] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
08/27/2025 18:26:24 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
08/27/2025 18:26:24 - WARNING - datasets.builder - Using custom data configuration default-25178e251dd03be0
08/27/2025 18:26:24 - WARNING - datasets.builder - Reusing dataset uie_instructions (logs_and_outputs/sdlora/order_1/outputs/2-amazon/f236d5f0073f6b88182545d96de70db6/uie_instructions/default-25178e251dd03be0/2.0.0/c490e7f13dec80785fc335819009163a45c86ae2816040c8d81800108e7e4374)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 735.37it/s]
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
08/27/2025 18:26:24 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: False
08/27/2025 18:26:25 - WARNING - datasets.builder - Using custom data configuration default-25178e251dd03be0
08/27/2025 18:26:25 - WARNING - datasets.builder - Reusing dataset uie_instructions (logs_and_outputs/sdlora/order_1/outputs/2-amazon/f236d5f0073f6b88182545d96de70db6/uie_instructions/default-25178e251dd03be0/2.0.0/c490e7f13dec80785fc335819009163a45c86ae2816040c8d81800108e7e4374)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 705.76it/s]
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/torch/nn/init.py:511: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/torch/nn/init.py:511: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
-----Gradient checkpointing: False -----
-----Gradient checkpointing: False -----
[93m [WARNING] [0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!
Using /home/yongxi/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
[93m [WARNING] [0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!
Using /home/yongxi/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /home/yongxi/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.4285266399383545 seconds
Rank: 1 partition count [2] and sizes[(1179648, False)] 
[rank1]:[W827 18:26:37.932975211 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.4697258472442627 seconds
Rank: 0 partition count [2] and sizes[(1179648, False)] 
[rank0]:[W827 18:26:37.974248174 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3596: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  warnings.warn(
  0%|          | 0/313 [00:00<?, ?it/s]/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3596: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  warnings.warn(
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1830: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1830: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
  0%|          | 1/313 [00:00<04:04,  1.28it/s]  1%|          | 2/313 [00:01<03:05,  1.68it/s]  1%|          | 3/313 [00:01<02:45,  1.87it/s]  1%|▏         | 4/313 [00:02<02:35,  1.99it/s]  2%|▏         | 5/313 [00:02<02:31,  2.04it/s]  2%|▏         | 6/313 [00:03<02:30,  2.04it/s]  2%|▏         | 7/313 [00:03<02:27,  2.08it/s]  3%|▎         | 8/313 [00:04<02:23,  2.12it/s]  3%|▎         | 9/313 [00:04<02:22,  2.14it/s]  3%|▎         | 10/313 [00:04<02:21,  2.14it/s]                                                {'loss': 3.2752, 'learning_rate': 0.001, 'epoch': 0.03}
  3%|▎         | 10/313 [00:04<02:21,  2.14it/s]  4%|▎         | 11/313 [00:05<02:34,  1.95it/s]  4%|▍         | 12/313 [00:06<02:42,  1.86it/s]  4%|▍         | 13/313 [00:06<02:34,  1.94it/s]  4%|▍         | 14/313 [00:07<02:32,  1.96it/s]  5%|▍         | 15/313 [00:07<02:28,  2.01it/s]  5%|▌         | 16/313 [00:08<02:24,  2.06it/s]  5%|▌         | 17/313 [00:08<02:20,  2.10it/s]  6%|▌         | 18/313 [00:08<02:19,  2.12it/s]  6%|▌         | 19/313 [00:09<02:16,  2.15it/s]  6%|▋         | 20/313 [00:09<02:16,  2.15it/s]                                                {'loss': 0.8059, 'learning_rate': 0.001, 'epoch': 0.06}
  6%|▋         | 20/313 [00:09<02:16,  2.15it/s]  7%|▋         | 21/313 [00:10<02:16,  2.14it/s]  7%|▋         | 22/313 [00:10<02:16,  2.13it/s]  7%|▋         | 23/313 [00:11<02:16,  2.13it/s]  8%|▊         | 24/313 [00:11<02:14,  2.15it/s]  8%|▊         | 25/313 [00:12<02:13,  2.15it/s]  8%|▊         | 26/313 [00:12<02:12,  2.16it/s]  9%|▊         | 27/313 [00:13<02:12,  2.17it/s]  9%|▉         | 28/313 [00:13<02:10,  2.18it/s]  9%|▉         | 29/313 [00:14<02:09,  2.19it/s] 10%|▉         | 30/313 [00:14<02:09,  2.19it/s]                                                {'loss': 0.7679, 'learning_rate': 0.001, 'epoch': 0.1}
 10%|▉         | 30/313 [00:14<02:09,  2.19it/s] 10%|▉         | 31/313 [00:14<02:11,  2.15it/s] 10%|█         | 32/313 [00:15<02:11,  2.14it/s] 11%|█         | 33/313 [00:15<02:10,  2.14it/s] 11%|█         | 34/313 [00:16<02:09,  2.15it/s] 11%|█         | 35/313 [00:16<02:10,  2.13it/s] 12%|█▏        | 36/313 [00:17<02:10,  2.13it/s] 12%|█▏        | 37/313 [00:17<02:09,  2.14it/s] 12%|█▏        | 38/313 [00:18<02:08,  2.13it/s] 12%|█▏        | 39/313 [00:18<02:08,  2.14it/s] 13%|█▎        | 40/313 [00:19<02:07,  2.14it/s]                                                {'loss': 0.7533, 'learning_rate': 0.001, 'epoch': 0.13}
 13%|█▎        | 40/313 [00:19<02:07,  2.14it/s] 13%|█▎        | 41/313 [00:19<02:08,  2.11it/s] 13%|█▎        | 42/313 [00:20<02:07,  2.12it/s] 14%|█▎        | 43/313 [00:20<02:06,  2.13it/s] 14%|█▍        | 44/313 [00:21<02:05,  2.14it/s] 14%|█▍        | 45/313 [00:21<02:04,  2.16it/s] 15%|█▍        | 46/313 [00:22<02:03,  2.16it/s] 15%|█▌        | 47/313 [00:22<02:02,  2.17it/s] 15%|█▌        | 48/313 [00:22<02:01,  2.17it/s] 16%|█▌        | 49/313 [00:23<02:00,  2.18it/s] 16%|█▌        | 50/313 [00:23<02:03,  2.13it/s]                                                {'loss': 0.6583, 'learning_rate': 0.001, 'epoch': 0.16}
 16%|█▌        | 50/313 [00:23<02:03,  2.13it/s] 16%|█▋        | 51/313 [00:24<02:01,  2.15it/s] 17%|█▋        | 52/313 [00:24<02:00,  2.17it/s] 17%|█▋        | 53/313 [00:25<01:59,  2.18it/s] 17%|█▋        | 54/313 [00:25<01:58,  2.19it/s] 18%|█▊        | 55/313 [00:26<01:57,  2.20it/s] 18%|█▊        | 56/313 [00:26<01:56,  2.21it/s] 18%|█▊        | 57/313 [00:27<01:55,  2.22it/s] 19%|█▊        | 58/313 [00:27<01:55,  2.21it/s] 19%|█▉        | 59/313 [00:27<01:54,  2.23it/s] 19%|█▉        | 60/313 [00:28<01:53,  2.23it/s]                                                {'loss': 0.6444, 'learning_rate': 0.001, 'epoch': 0.19}
 19%|█▉        | 60/313 [00:28<01:53,  2.23it/s] 19%|█▉        | 61/313 [00:28<01:53,  2.22it/s] 20%|█▉        | 62/313 [00:29<01:52,  2.22it/s] 20%|██        | 63/313 [00:29<01:52,  2.22it/s] 20%|██        | 64/313 [00:30<01:52,  2.22it/s] 21%|██        | 65/313 [00:30<01:51,  2.22it/s] 21%|██        | 66/313 [00:31<01:51,  2.22it/s] 21%|██▏       | 67/313 [00:31<01:50,  2.22it/s] 22%|██▏       | 68/313 [00:31<01:50,  2.23it/s] 22%|██▏       | 69/313 [00:32<01:49,  2.23it/s] 22%|██▏       | 70/313 [00:32<01:49,  2.22it/s]                                                {'loss': 0.6117, 'learning_rate': 0.001, 'epoch': 0.22}
 22%|██▏       | 70/313 [00:32<01:49,  2.22it/s] 23%|██▎       | 71/313 [00:33<01:50,  2.19it/s] 23%|██▎       | 72/313 [00:33<01:50,  2.18it/s] 23%|██▎       | 73/313 [00:34<01:49,  2.19it/s] 24%|██▎       | 74/313 [00:34<01:50,  2.16it/s] 24%|██▍       | 75/313 [00:35<01:50,  2.15it/s] 24%|██▍       | 76/313 [00:35<02:00,  1.96it/s] 25%|██▍       | 77/313 [00:36<01:57,  2.01it/s] 25%|██▍       | 78/313 [00:36<01:55,  2.04it/s] 25%|██▌       | 79/313 [00:37<01:53,  2.06it/s] 26%|██▌       | 80/313 [00:37<01:51,  2.08it/s]                                                {'loss': 0.5404, 'learning_rate': 0.001, 'epoch': 0.26}
 26%|██▌       | 80/313 [00:37<01:51,  2.08it/s] 26%|██▌       | 81/313 [00:38<02:00,  1.93it/s] 26%|██▌       | 82/313 [00:38<01:56,  1.98it/s] 27%|██▋       | 83/313 [00:39<01:54,  2.01it/s] 27%|██▋       | 84/313 [00:39<01:51,  2.05it/s] 27%|██▋       | 85/313 [00:40<01:49,  2.09it/s] 27%|██▋       | 86/313 [00:40<01:47,  2.11it/s] 28%|██▊       | 87/313 [00:41<01:46,  2.12it/s] 28%|██▊       | 88/313 [00:41<01:45,  2.12it/s] 28%|██▊       | 89/313 [00:42<01:45,  2.12it/s] 29%|██▉       | 90/313 [00:42<01:44,  2.13it/s]                                                {'loss': 0.5398, 'learning_rate': 0.001, 'epoch': 0.29}
 29%|██▉       | 90/313 [00:42<01:44,  2.13it/s] 29%|██▉       | 91/313 [00:42<01:44,  2.13it/s] 29%|██▉       | 92/313 [00:43<01:43,  2.13it/s] 30%|██▉       | 93/313 [00:43<01:44,  2.12it/s] 30%|███       | 94/313 [00:44<01:43,  2.12it/s] 30%|███       | 95/313 [00:44<01:42,  2.12it/s] 31%|███       | 96/313 [00:45<01:41,  2.13it/s] 31%|███       | 97/313 [00:45<01:41,  2.14it/s] 31%|███▏      | 98/313 [00:46<01:40,  2.13it/s] 32%|███▏      | 99/313 [00:46<01:40,  2.13it/s] 32%|███▏      | 100/313 [00:47<01:39,  2.14it/s]                                                 {'loss': 0.5188, 'learning_rate': 0.001, 'epoch': 0.32}
 32%|███▏      | 100/313 [00:47<01:39,  2.14it/s] 32%|███▏      | 101/313 [00:47<01:41,  2.09it/s] 33%|███▎      | 102/313 [00:48<01:40,  2.11it/s] 33%|███▎      | 103/313 [00:48<01:39,  2.11it/s] 33%|███▎      | 104/313 [00:49<01:39,  2.11it/s] 34%|███▎      | 105/313 [00:49<01:38,  2.12it/s] 34%|███▍      | 106/313 [00:50<01:37,  2.13it/s] 34%|███▍      | 107/313 [00:50<01:36,  2.14it/s] 35%|███▍      | 108/313 [00:51<01:36,  2.13it/s] 35%|███▍      | 109/313 [00:51<01:35,  2.13it/s] 35%|███▌      | 110/313 [00:51<01:34,  2.14it/s]                                                 {'loss': 0.4862, 'learning_rate': 0.001, 'epoch': 0.35}
 35%|███▌      | 110/313 [00:51<01:34,  2.14it/s] 35%|███▌      | 111/313 [00:52<01:34,  2.14it/s] 36%|███▌      | 112/313 [00:53<01:43,  1.95it/s] 36%|███▌      | 113/313 [00:53<01:40,  1.99it/s] 36%|███▋      | 114/313 [00:53<01:37,  2.04it/s] 37%|███▋      | 115/313 [00:54<01:35,  2.07it/s] 37%|███▋      | 116/313 [00:54<01:33,  2.10it/s] 37%|███▋      | 117/313 [00:55<01:32,  2.11it/s] 38%|███▊      | 118/313 [00:55<01:31,  2.13it/s] 38%|███▊      | 119/313 [00:56<01:31,  2.13it/s] 38%|███▊      | 120/313 [00:56<01:30,  2.14it/s]                                                 {'loss': 0.4724, 'learning_rate': 0.001, 'epoch': 0.38}
 38%|███▊      | 120/313 [00:56<01:30,  2.14it/s] 39%|███▊      | 121/313 [00:57<01:29,  2.14it/s] 39%|███▉      | 122/313 [00:57<01:29,  2.13it/s] 39%|███▉      | 123/313 [00:58<01:29,  2.13it/s] 40%|███▉      | 124/313 [00:58<01:29,  2.11it/s] 40%|███▉      | 125/313 [00:59<01:28,  2.12it/s] 40%|████      | 126/313 [00:59<01:27,  2.13it/s] 41%|████      | 127/313 [01:00<01:27,  2.13it/s] 41%|████      | 128/313 [01:00<01:26,  2.13it/s] 41%|████      | 129/313 [01:00<01:26,  2.13it/s] 42%|████▏     | 130/313 [01:01<01:26,  2.13it/s]                                                 {'loss': 0.4519, 'learning_rate': 0.001, 'epoch': 0.42}
 42%|████▏     | 130/313 [01:01<01:26,  2.13it/s] 42%|████▏     | 131/313 [01:01<01:25,  2.13it/s] 42%|████▏     | 132/313 [01:02<01:25,  2.12it/s] 42%|████▏     | 133/313 [01:02<01:24,  2.12it/s] 43%|████▎     | 134/313 [01:03<01:24,  2.13it/s] 43%|████▎     | 135/313 [01:03<01:23,  2.13it/s] 43%|████▎     | 136/313 [01:04<01:22,  2.14it/s] 44%|████▍     | 137/313 [01:04<01:22,  2.14it/s] 44%|████▍     | 138/313 [01:05<01:21,  2.14it/s] 44%|████▍     | 139/313 [01:05<01:20,  2.15it/s] 45%|████▍     | 140/313 [01:06<01:21,  2.13it/s]                                                 {'loss': 0.4235, 'learning_rate': 0.001, 'epoch': 0.45}
 45%|████▍     | 140/313 [01:06<01:21,  2.13it/s] 45%|████▌     | 141/313 [01:06<01:21,  2.11it/s] 45%|████▌     | 142/313 [01:07<01:20,  2.12it/s] 46%|████▌     | 143/313 [01:07<01:20,  2.12it/s] 46%|████▌     | 144/313 [01:08<01:19,  2.13it/s] 46%|████▋     | 145/313 [01:08<01:19,  2.10it/s] 47%|████▋     | 146/313 [01:08<01:18,  2.12it/s] 47%|████▋     | 147/313 [01:09<01:17,  2.13it/s] 47%|████▋     | 148/313 [01:09<01:17,  2.14it/s] 48%|████▊     | 149/313 [01:10<01:16,  2.14it/s] 48%|████▊     | 150/313 [01:10<01:16,  2.12it/s]                                                 {'loss': 0.5712, 'learning_rate': 0.001, 'epoch': 0.48}
 48%|████▊     | 150/313 [01:10<01:16,  2.12it/s] 48%|████▊     | 151/313 [01:11<01:16,  2.12it/s] 49%|████▊     | 152/313 [01:11<01:16,  2.11it/s] 49%|████▉     | 153/313 [01:12<01:15,  2.11it/s] 49%|████▉     | 154/313 [01:12<01:15,  2.11it/s] 50%|████▉     | 155/313 [01:13<01:14,  2.12it/s] 50%|████▉     | 156/313 [01:13<01:14,  2.12it/s] 50%|█████     | 157/313 [01:14<01:20,  1.94it/s] 50%|█████     | 158/313 [01:14<01:17,  1.99it/s] 51%|█████     | 159/313 [01:15<01:16,  2.02it/s] 51%|█████     | 160/313 [01:15<01:14,  2.04it/s]                                                 {'loss': 0.5229, 'learning_rate': 0.001, 'epoch': 0.51}
 51%|█████     | 160/313 [01:15<01:14,  2.04it/s] 51%|█████▏    | 161/313 [01:16<01:13,  2.07it/s] 52%|█████▏    | 162/313 [01:16<01:11,  2.10it/s] 52%|█████▏    | 163/313 [01:17<01:10,  2.12it/s] 52%|█████▏    | 164/313 [01:17<01:10,  2.13it/s] 53%|█████▎    | 165/313 [01:18<01:09,  2.14it/s] 53%|█████▎    | 166/313 [01:18<01:09,  2.13it/s] 53%|█████▎    | 167/313 [01:19<01:08,  2.12it/s] 54%|█████▎    | 168/313 [01:19<01:08,  2.13it/s] 54%|█████▍    | 169/313 [01:19<01:07,  2.13it/s] 54%|█████▍    | 170/313 [01:20<01:07,  2.13it/s]                                                 {'loss': 0.4661, 'learning_rate': 0.001, 'epoch': 0.54}
 54%|█████▍    | 170/313 [01:20<01:07,  2.13it/s] 55%|█████▍    | 171/313 [01:20<01:06,  2.13it/s] 55%|█████▍    | 172/313 [01:21<01:06,  2.13it/s] 55%|█████▌    | 173/313 [01:21<01:05,  2.14it/s] 56%|█████▌    | 174/313 [01:22<01:04,  2.14it/s] 56%|█████▌    | 175/313 [01:22<01:10,  1.95it/s] 56%|█████▌    | 176/313 [01:23<01:08,  2.01it/s] 57%|█████▋    | 177/313 [01:23<01:07,  2.02it/s] 57%|█████▋    | 178/313 [01:24<01:05,  2.05it/s] 57%|█████▋    | 179/313 [01:24<01:04,  2.07it/s] 58%|█████▊    | 180/313 [01:25<01:03,  2.09it/s]                                                 {'loss': 0.4531, 'learning_rate': 0.001, 'epoch': 0.58}
 58%|█████▊    | 180/313 [01:25<01:03,  2.09it/s] 58%|█████▊    | 181/313 [01:25<01:02,  2.10it/s] 58%|█████▊    | 182/313 [01:26<01:02,  2.10it/s] 58%|█████▊    | 183/313 [01:26<01:00,  2.14it/s] 59%|█████▉    | 184/313 [01:27<00:59,  2.16it/s] 59%|█████▉    | 185/313 [01:27<00:58,  2.18it/s] 59%|█████▉    | 186/313 [01:28<00:58,  2.18it/s] 60%|█████▉    | 187/313 [01:28<00:57,  2.19it/s] 60%|██████    | 188/313 [01:28<00:56,  2.20it/s] 60%|██████    | 189/313 [01:29<00:56,  2.18it/s] 61%|██████    | 190/313 [01:29<00:56,  2.16it/s]                                                 {'loss': 0.5923, 'learning_rate': 0.001, 'epoch': 0.61}
 61%|██████    | 190/313 [01:29<00:56,  2.16it/s] 61%|██████    | 191/313 [01:30<00:56,  2.15it/s] 61%|██████▏   | 192/313 [01:30<01:01,  1.97it/s] 62%|██████▏   | 193/313 [01:31<00:59,  2.01it/s] 62%|██████▏   | 194/313 [01:32<01:03,  1.86it/s] 62%|██████▏   | 195/313 [01:32<01:01,  1.91it/s] 63%|██████▎   | 196/313 [01:33<00:59,  1.96it/s] 63%|██████▎   | 197/313 [01:33<00:57,  2.01it/s] 63%|██████▎   | 198/313 [01:33<00:56,  2.05it/s] 64%|██████▎   | 199/313 [01:34<00:54,  2.07it/s] 64%|██████▍   | 200/313 [01:34<00:53,  2.09it/s]                                                 {'loss': 0.4471, 'learning_rate': 0.001, 'epoch': 0.64}
 64%|██████▍   | 200/313 [01:34<00:53,  2.09it/s] 64%|██████▍   | 201/313 [01:35<00:53,  2.11it/s] 65%|██████▍   | 202/313 [01:35<00:52,  2.13it/s] 65%|██████▍   | 203/313 [01:36<00:51,  2.13it/s] 65%|██████▌   | 204/313 [01:36<00:51,  2.10it/s] 65%|██████▌   | 205/313 [01:37<00:51,  2.10it/s] 66%|██████▌   | 206/313 [01:37<00:50,  2.11it/s] 66%|██████▌   | 207/313 [01:38<00:49,  2.12it/s] 66%|██████▋   | 208/313 [01:38<00:49,  2.12it/s] 67%|██████▋   | 209/313 [01:39<00:49,  2.12it/s] 67%|██████▋   | 210/313 [01:39<00:50,  2.05it/s]                                                 {'loss': 0.4628, 'learning_rate': 0.001, 'epoch': 0.67}
 67%|██████▋   | 210/313 [01:39<00:50,  2.05it/s] 67%|██████▋   | 211/313 [01:40<00:49,  2.08it/s] 68%|██████▊   | 212/313 [01:40<00:48,  2.10it/s] 68%|██████▊   | 213/313 [01:41<00:47,  2.11it/s] 68%|██████▊   | 214/313 [01:41<00:47,  2.10it/s] 69%|██████▊   | 215/313 [01:41<00:46,  2.11it/s] 69%|██████▉   | 216/313 [01:42<00:45,  2.12it/s] 69%|██████▉   | 217/313 [01:42<00:45,  2.13it/s] 70%|██████▉   | 218/313 [01:43<00:44,  2.13it/s] 70%|██████▉   | 219/313 [01:43<00:43,  2.15it/s] 70%|███████   | 220/313 [01:44<00:42,  2.17it/s]                                                 {'loss': 0.4712, 'learning_rate': 0.001, 'epoch': 0.7}
 70%|███████   | 220/313 [01:44<00:42,  2.17it/s] 71%|███████   | 221/313 [01:44<00:42,  2.15it/s] 71%|███████   | 222/313 [01:45<00:42,  2.15it/s] 71%|███████   | 223/313 [01:45<00:42,  2.14it/s] 72%|███████▏  | 224/313 [01:46<00:41,  2.14it/s] 72%|███████▏  | 225/313 [01:46<00:41,  2.13it/s] 72%|███████▏  | 226/313 [01:47<00:40,  2.13it/s] 73%|███████▎  | 227/313 [01:47<00:40,  2.13it/s] 73%|███████▎  | 228/313 [01:48<00:40,  2.11it/s] 73%|███████▎  | 229/313 [01:48<00:39,  2.11it/s] 73%|███████▎  | 230/313 [01:49<00:39,  2.12it/s]                                                 {'loss': 0.457, 'learning_rate': 0.001, 'epoch': 0.73}
 73%|███████▎  | 230/313 [01:49<00:39,  2.12it/s] 74%|███████▍  | 231/313 [01:49<00:38,  2.11it/s] 74%|███████▍  | 232/313 [01:49<00:38,  2.12it/s] 74%|███████▍  | 233/313 [01:50<00:37,  2.11it/s] 75%|███████▍  | 234/313 [01:50<00:37,  2.10it/s] 75%|███████▌  | 235/313 [01:51<00:37,  2.08it/s] 75%|███████▌  | 236/313 [01:51<00:36,  2.10it/s] 76%|███████▌  | 237/313 [01:52<00:35,  2.12it/s] 76%|███████▌  | 238/313 [01:52<00:35,  2.12it/s] 76%|███████▋  | 239/313 [01:53<00:34,  2.12it/s] 77%|███████▋  | 240/313 [01:53<00:34,  2.13it/s]                                                 {'loss': 0.4761, 'learning_rate': 0.001, 'epoch': 0.77}
 77%|███████▋  | 240/313 [01:53<00:34,  2.13it/s] 77%|███████▋  | 241/313 [01:54<00:33,  2.14it/s] 77%|███████▋  | 242/313 [01:54<00:33,  2.14it/s] 78%|███████▊  | 243/313 [01:55<00:32,  2.13it/s] 78%|███████▊  | 244/313 [01:55<00:32,  2.13it/s] 78%|███████▊  | 245/313 [01:56<00:31,  2.13it/s] 79%|███████▊  | 246/313 [01:56<00:31,  2.12it/s] 79%|███████▉  | 247/313 [01:57<00:31,  2.12it/s] 79%|███████▉  | 248/313 [01:57<00:31,  2.07it/s] 80%|███████▉  | 249/313 [01:58<00:30,  2.09it/s] 80%|███████▉  | 250/313 [01:58<00:29,  2.10it/s]                                                 {'loss': 0.4384, 'learning_rate': 0.001, 'epoch': 0.8}
 80%|███████▉  | 250/313 [01:58<00:29,  2.10it/s] 80%|████████  | 251/313 [01:58<00:29,  2.12it/s] 81%|████████  | 252/313 [01:59<00:28,  2.13it/s] 81%|████████  | 253/313 [01:59<00:28,  2.13it/s] 81%|████████  | 254/313 [02:00<00:27,  2.13it/s] 81%|████████▏ | 255/313 [02:00<00:27,  2.13it/s] 82%|████████▏ | 256/313 [02:01<00:26,  2.13it/s] 82%|████████▏ | 257/313 [02:01<00:26,  2.13it/s] 82%|████████▏ | 258/313 [02:02<00:25,  2.13it/s] 83%|████████▎ | 259/313 [02:02<00:25,  2.13it/s] 83%|████████▎ | 260/313 [02:03<00:24,  2.14it/s]                                                 {'loss': 0.5247, 'learning_rate': 0.001, 'epoch': 0.83}
 83%|████████▎ | 260/313 [02:03<00:24,  2.14it/s] 83%|████████▎ | 261/313 [02:03<00:24,  2.13it/s] 84%|████████▎ | 262/313 [02:04<00:23,  2.13it/s] 84%|████████▍ | 263/313 [02:04<00:23,  2.14it/s] 84%|████████▍ | 264/313 [02:05<00:22,  2.13it/s] 85%|████████▍ | 265/313 [02:05<00:22,  2.14it/s] 85%|████████▍ | 266/313 [02:05<00:22,  2.14it/s] 85%|████████▌ | 267/313 [02:06<00:21,  2.13it/s] 86%|████████▌ | 268/313 [02:06<00:20,  2.14it/s] 86%|████████▌ | 269/313 [02:07<00:20,  2.17it/s] 86%|████████▋ | 270/313 [02:07<00:19,  2.18it/s]                                                 {'loss': 0.453, 'learning_rate': 0.001, 'epoch': 0.86}
 86%|████████▋ | 270/313 [02:07<00:19,  2.18it/s] 87%|████████▋ | 271/313 [02:08<00:19,  2.18it/s] 87%|████████▋ | 272/313 [02:08<00:18,  2.19it/s] 87%|████████▋ | 273/313 [02:09<00:18,  2.19it/s] 88%|████████▊ | 274/313 [02:09<00:17,  2.20it/s] 88%|████████▊ | 275/313 [02:10<00:17,  2.20it/s] 88%|████████▊ | 276/313 [02:10<00:16,  2.20it/s] 88%|████████▊ | 277/313 [02:11<00:16,  2.19it/s] 89%|████████▉ | 278/313 [02:11<00:15,  2.19it/s] 89%|████████▉ | 279/313 [02:11<00:15,  2.19it/s] 89%|████████▉ | 280/313 [02:12<00:15,  2.16it/s]                                                 {'loss': 0.4758, 'learning_rate': 0.001, 'epoch': 0.89}
 89%|████████▉ | 280/313 [02:12<00:15,  2.16it/s] 90%|████████▉ | 281/313 [02:12<00:14,  2.15it/s] 90%|█████████ | 282/313 [02:13<00:14,  2.14it/s] 90%|█████████ | 283/313 [02:13<00:14,  2.14it/s] 91%|█████████ | 284/313 [02:14<00:13,  2.14it/s] 91%|█████████ | 285/313 [02:14<00:13,  2.13it/s] 91%|█████████▏| 286/313 [02:15<00:12,  2.14it/s] 92%|█████████▏| 287/313 [02:15<00:12,  2.14it/s] 92%|█████████▏| 288/313 [02:16<00:11,  2.15it/s] 92%|█████████▏| 289/313 [02:16<00:11,  2.14it/s] 93%|█████████▎| 290/313 [02:17<00:10,  2.15it/s]                                                 {'loss': 0.4534, 'learning_rate': 0.001, 'epoch': 0.93}
 93%|█████████▎| 290/313 [02:17<00:10,  2.15it/s] 93%|█████████▎| 291/313 [02:17<00:10,  2.15it/s] 93%|█████████▎| 292/313 [02:17<00:09,  2.17it/s] 94%|█████████▎| 293/313 [02:18<00:09,  2.18it/s] 94%|█████████▍| 294/313 [02:18<00:08,  2.19it/s] 94%|█████████▍| 295/313 [02:19<00:08,  2.21it/s] 95%|█████████▍| 296/313 [02:19<00:07,  2.21it/s] 95%|█████████▍| 297/313 [02:20<00:07,  2.22it/s] 95%|█████████▌| 298/313 [02:20<00:06,  2.21it/s] 96%|█████████▌| 299/313 [02:21<00:06,  2.21it/s] 96%|█████████▌| 300/313 [02:21<00:05,  2.21it/s]                                                 {'loss': 0.4718, 'learning_rate': 0.001, 'epoch': 0.96}
 96%|█████████▌| 300/313 [02:21<00:05,  2.21it/s] 96%|█████████▌| 301/313 [02:22<00:05,  2.21it/s] 96%|█████████▋| 302/313 [02:22<00:04,  2.22it/s] 97%|█████████▋| 303/313 [02:22<00:04,  2.22it/s] 97%|█████████▋| 304/313 [02:23<00:04,  2.21it/s] 97%|█████████▋| 305/313 [02:23<00:03,  2.20it/s] 98%|█████████▊| 306/313 [02:24<00:03,  2.20it/s] 98%|█████████▊| 307/313 [02:24<00:02,  2.21it/s] 98%|█████████▊| 308/313 [02:25<00:02,  2.21it/s] 99%|█████████▊| 309/313 [02:25<00:01,  2.21it/s] 99%|█████████▉| 310/313 [02:26<00:01,  2.19it/s]                                                 {'loss': 0.5157, 'learning_rate': 0.001, 'epoch': 0.99}
 99%|█████████▉| 310/313 [02:26<00:01,  2.19it/s] 99%|█████████▉| 311/313 [02:26<00:00,  2.19it/s]100%|█████████▉| 312/313 [02:27<00:00,  2.18it/s]100%|██████████| 313/313 [02:27<00:00,  2.18it/s]                                                 {'train_runtime': 147.5234, 'train_samples_per_second': 33.893, 'train_steps_per_second': 2.122, 'train_loss': 0.6174449006589456, 'epoch': 1.0}
100%|██████████| 313/313 [02:27<00:00,  2.18it/s]100%|██████████| 313/313 [02:27<00:00,  2.12it/s]
***** train metrics *****
  epoch                    =        1.0
  train_loss               =     0.6174
  train_runtime            = 0:02:27.52
  train_samples            =       5000
  train_samples_per_second =     33.893
  train_steps_per_second   =      2.122
  0%|          | 0/60 [00:00<?, ?it/s]  3%|▎         | 2/60 [00:01<00:39,  1.47it/s]  5%|▌         | 3/60 [00:02<00:59,  1.05s/it]  7%|▋         | 4/60 [00:04<01:05,  1.17s/it]  8%|▊         | 5/60 [00:05<01:08,  1.25s/it] 10%|█         | 6/60 [00:07<01:09,  1.29s/it] 12%|█▏        | 7/60 [00:08<01:07,  1.28s/it] 13%|█▎        | 8/60 [00:09<01:07,  1.29s/it] 15%|█▌        | 9/60 [00:11<01:13,  1.45s/it] 17%|█▋        | 10/60 [00:13<01:16,  1.53s/it] 18%|█▊        | 11/60 [00:14<01:10,  1.45s/it] 20%|██        | 12/60 [00:15<01:07,  1.41s/it] 22%|██▏       | 13/60 [00:17<01:06,  1.41s/it] 23%|██▎       | 14/60 [00:18<01:05,  1.42s/it] 25%|██▌       | 15/60 [00:20<01:09,  1.54s/it] 27%|██▋       | 16/60 [00:21<01:04,  1.48s/it] 28%|██▊       | 17/60 [00:23<01:01,  1.43s/it] 30%|███       | 18/60 [00:24<00:59,  1.42s/it] 32%|███▏      | 19/60 [00:25<00:56,  1.38s/it] 33%|███▎      | 20/60 [00:27<00:54,  1.36s/it] 35%|███▌      | 21/60 [00:28<00:52,  1.34s/it] 37%|███▋      | 22/60 [00:29<00:50,  1.33s/it] 38%|███▊      | 23/60 [00:31<00:53,  1.44s/it] 40%|████      | 24/60 [00:32<00:53,  1.48s/it] 42%|████▏     | 25/60 [00:34<00:50,  1.45s/it] 43%|████▎     | 26/60 [00:35<00:47,  1.40s/it] 45%|████▌     | 27/60 [00:36<00:45,  1.37s/it] 47%|████▋     | 28/60 [00:38<00:42,  1.34s/it] 48%|████▊     | 29/60 [00:39<00:42,  1.39s/it] 50%|█████     | 30/60 [00:40<00:40,  1.36s/it] 52%|█████▏    | 31/60 [00:42<00:39,  1.35s/it] 53%|█████▎    | 32/60 [00:43<00:34,  1.25s/it] 55%|█████▌    | 33/60 [00:44<00:32,  1.19s/it] 57%|█████▋    | 34/60 [00:45<00:29,  1.12s/it] 58%|█████▊    | 35/60 [00:46<00:26,  1.08s/it] 60%|██████    | 36/60 [00:47<00:25,  1.04s/it] 62%|██████▏   | 37/60 [00:48<00:23,  1.00s/it] 63%|██████▎   | 38/60 [00:49<00:22,  1.02s/it] 65%|██████▌   | 39/60 [00:50<00:20,  1.01it/s] 67%|██████▋   | 40/60 [00:51<00:20,  1.00s/it] 68%|██████▊   | 41/60 [00:52<00:18,  1.00it/s] 70%|███████   | 42/60 [00:53<00:18,  1.02s/it] 72%|███████▏  | 43/60 [00:55<00:24,  1.46s/it] 73%|███████▎  | 44/60 [00:56<00:22,  1.41s/it] 75%|███████▌  | 45/60 [00:57<00:19,  1.28s/it] 77%|███████▋  | 46/60 [00:58<00:16,  1.16s/it] 78%|███████▊  | 47/60 [00:59<00:14,  1.09s/it] 80%|████████  | 48/60 [01:00<00:12,  1.04s/it] 82%|████████▏ | 49/60 [01:01<00:11,  1.02s/it] 83%|████████▎ | 50/60 [01:02<00:10,  1.00s/it] 85%|████████▌ | 51/60 [01:05<00:13,  1.45s/it] 87%|████████▋ | 52/60 [01:06<00:10,  1.31s/it] 88%|████████▊ | 53/60 [01:07<00:08,  1.20s/it] 90%|█████████ | 54/60 [01:08<00:07,  1.21s/it] 92%|█████████▏| 55/60 [01:09<00:06,  1.23s/it] 93%|█████████▎| 56/60 [01:10<00:04,  1.18s/it] 95%|█████████▌| 57/60 [01:11<00:03,  1.13s/it] 97%|█████████▋| 58/60 [01:12<00:02,  1.14s/it] 98%|█████████▊| 59/60 [01:13<00:01,  1.12s/it]100%|██████████| 60/60 [01:15<00:00,  1.15s/it]100%|██████████| 60/60 [01:21<00:00,  1.36s/it]
***** predict metrics *****
  epoch                           =        1.0
  predict_exact_match             =    56.2368
  predict_exact_match_for_SC      =    53.9474
  predict_exact_match_for_TC      =    58.5263
  predict_exact_match_for_amazon  =    53.9474
  predict_exact_match_for_dbpedia =    58.5263
  predict_gen_len                 =     2.7094
  predict_global_step             =        313
  predict_loss                    =     0.5945
  predict_rouge1                  =    64.6678
  predict_rouge1_for_SC           =    70.4342
  predict_rouge1_for_TC           =    58.9013
  predict_rouge1_for_amazon       =    70.4342
  predict_rouge1_for_dbpedia      =    58.9013
  predict_rougeL                  =    64.6678
  predict_rougeL_for_SC           =    70.4342
  predict_rougeL_for_TC           =    58.9013
  predict_rougeL_for_amazon       =    70.4342
  predict_rougeL_for_dbpedia      =    58.9013
  predict_runtime                 = 0:01:23.13
  predict_samples                 =      15200
  predict_samples_per_second      =    182.836
  predict_steps_per_second        =      0.722
[rank0]:[W827 18:30:29.944848660 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[2025-08-27 18:30:31,119] [INFO] [launch.py:347:main] Process 771148 exits successfully.
[2025-08-27 18:30:31,120] [INFO] [launch.py:347:main] Process 771147 exits successfully.
+ sleep 5
+ CUDA_VISIBLE_DEVICES=6,7
+ deepspeed --master_port 28490 src/run_uie_lora.py --do_train --do_predict --predict_with_generate --model_name_or_path logs_and_outputs/sdlora/order_1/outputs/2-amazon/adapter --data_dir CL_Benchmark --task_config_dir configs/order1_configs/yahoo --instruction_file configs/instruction_config.json --instruction_strategy single --output_dir logs_and_outputs/sdlora/order_1/outputs/3-yahoo --per_device_train_batch_size 8 --per_device_eval_batch_size 128 --gradient_accumulation_steps 1 --learning_rate 1e-03 --num_train_epochs 1 --deepspeed configs/ds_configs/stage2.config --run_name order1_round3_sdlora --max_source_length 512 --max_target_length 50 --generation_max_length 50 --add_task_name True --add_dataset_name True --overwrite_output_dir --overwrite_cache --lr_scheduler_type constant --warmup_steps 0 --logging_strategy steps --logging_steps 10 --evaluation_strategy no --save_strategy no --save_steps 1500 --lamda_1 0.5 --lamda_2 0 --peft_type SDLORA
[2025-08-27 18:30:39,311] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-08-27 18:30:40,461] [WARNING] [runner.py:196:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=6,7: setting --include=localhost:6,7
[2025-08-27 18:30:40,537] [INFO] [runner.py:555:main] cmd = /home/yongxi/miniconda3/envs/sd-lora/bin/python3.10 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbNiwgN119 --master_addr=127.0.0.1 --master_port=28490 --enable_each_rank_log=None src/run_uie_lora.py --do_train --do_predict --predict_with_generate --model_name_or_path logs_and_outputs/sdlora/order_1/outputs/2-amazon/adapter --data_dir CL_Benchmark --task_config_dir configs/order1_configs/yahoo --instruction_file configs/instruction_config.json --instruction_strategy single --output_dir logs_and_outputs/sdlora/order_1/outputs/3-yahoo --per_device_train_batch_size 8 --per_device_eval_batch_size 128 --gradient_accumulation_steps 1 --learning_rate 1e-03 --num_train_epochs 1 --deepspeed configs/ds_configs/stage2.config --run_name order1_round3_sdlora --max_source_length 512 --max_target_length 50 --generation_max_length 50 --add_task_name True --add_dataset_name True --overwrite_output_dir --overwrite_cache --lr_scheduler_type constant --warmup_steps 0 --logging_strategy steps --logging_steps 10 --evaluation_strategy no --save_strategy no --save_steps 1500 --lamda_1 0.5 --lamda_2 0 --peft_type SDLORA
[2025-08-27 18:30:41,704] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-08-27 18:30:42,983] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [6, 7]}
[2025-08-27 18:30:42,983] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=2, node_rank=0
[2025-08-27 18:30:42,983] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1]})
[2025-08-27 18:30:42,983] [INFO] [launch.py:163:main] dist_world_size=2
[2025-08-27 18:30:42,983] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=6,7
[2025-08-27 18:30:45,342] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-27 18:30:45,345] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/fairscale/experimental/nn/offload.py:19: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_fwd(orig_func)  # type: ignore
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/fairscale/experimental/nn/offload.py:30: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_bwd(orig_func)  # type: ignore
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/fairscale/experimental/nn/offload.py:19: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_fwd(orig_func)  # type: ignore
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/fairscale/experimental/nn/offload.py:30: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_bwd(orig_func)  # type: ignore
[2025-08-27 18:30:46,300] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2025-08-27 18:30:46,300] [INFO] [comm.py:616:init_distributed] cdb=None
[2025-08-27 18:30:46,300] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-08-27 18:30:46,303] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2025-08-27 18:30:46,303] [INFO] [comm.py:616:init_distributed] cdb=None
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
08/27/2025 18:30:46 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
08/27/2025 18:30:46 - WARNING - datasets.builder - Using custom data configuration default-d971c7bc1435f4ac
08/27/2025 18:30:46 - WARNING - datasets.builder - Reusing dataset uie_instructions (logs_and_outputs/sdlora/order_1/outputs/3-yahoo/b3f2d9fb75813b68e82efb3b6bab35bd/uie_instructions/default-d971c7bc1435f4ac/2.0.0/c490e7f13dec80785fc335819009163a45c86ae2816040c8d81800108e7e4374)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 692.09it/s]
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
08/27/2025 18:30:46 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: False
08/27/2025 18:30:46 - WARNING - datasets.builder - Using custom data configuration default-d971c7bc1435f4ac
08/27/2025 18:30:46 - WARNING - datasets.builder - Reusing dataset uie_instructions (logs_and_outputs/sdlora/order_1/outputs/3-yahoo/b3f2d9fb75813b68e82efb3b6bab35bd/uie_instructions/default-d971c7bc1435f4ac/2.0.0/c490e7f13dec80785fc335819009163a45c86ae2816040c8d81800108e7e4374)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 684.45it/s]
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/torch/nn/init.py:511: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/torch/nn/init.py:511: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
-----Gradient checkpointing: False -----
-----Gradient checkpointing: False -----
[93m [WARNING] [0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!
Using /home/yongxi/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /home/yongxi/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
[93m [WARNING] [0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!
Using /home/yongxi/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.412294864654541 seconds
Rank: 1 partition count [2] and sizes[(1179648, False)] 
[rank1]:[W827 18:30:58.204112888 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.4735472202301025 seconds
Rank: 0 partition count [2] and sizes[(1179648, False)] 
[rank0]:[W827 18:30:58.287892932 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3596: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  warnings.warn(
  0%|          | 0/625 [00:00<?, ?it/s]/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3596: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  warnings.warn(
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1830: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1830: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
  0%|          | 1/625 [00:00<07:13,  1.44it/s]  0%|          | 2/625 [00:01<05:59,  1.73it/s]  0%|          | 3/625 [00:01<05:45,  1.80it/s]  1%|          | 4/625 [00:02<05:32,  1.87it/s]  1%|          | 5/625 [00:02<05:13,  1.98it/s]  1%|          | 6/625 [00:03<05:04,  2.03it/s]  1%|          | 7/625 [00:03<05:07,  2.01it/s]  1%|▏         | 8/625 [00:04<05:14,  1.96it/s]  1%|▏         | 9/625 [00:04<05:07,  2.00it/s]  2%|▏         | 10/625 [00:05<05:06,  2.01it/s]                                                {'loss': 2.2742, 'learning_rate': 0.001, 'epoch': 0.02}
  2%|▏         | 10/625 [00:05<05:06,  2.01it/s]  2%|▏         | 11/625 [00:05<05:02,  2.03it/s]  2%|▏         | 12/625 [00:06<05:09,  1.98it/s]  2%|▏         | 13/625 [00:06<05:12,  1.96it/s]  2%|▏         | 14/625 [00:07<05:10,  1.97it/s]  2%|▏         | 15/625 [00:07<05:14,  1.94it/s]  3%|▎         | 16/625 [00:08<05:04,  2.00it/s]  3%|▎         | 17/625 [00:08<05:09,  1.97it/s]  3%|▎         | 18/625 [00:09<04:58,  2.04it/s]  3%|▎         | 19/625 [00:09<05:04,  1.99it/s]  3%|▎         | 20/625 [00:10<05:07,  1.97it/s]                                                {'loss': 0.5082, 'learning_rate': 0.001, 'epoch': 0.03}
  3%|▎         | 20/625 [00:10<05:07,  1.97it/s]  3%|▎         | 21/625 [00:10<05:10,  1.95it/s]  4%|▎         | 22/625 [00:11<05:09,  1.95it/s]  4%|▎         | 23/625 [00:11<05:10,  1.94it/s]  4%|▍         | 24/625 [00:12<04:59,  2.01it/s]  4%|▍         | 25/625 [00:12<05:03,  1.98it/s]  4%|▍         | 26/625 [00:13<05:08,  1.94it/s]  4%|▍         | 27/625 [00:13<05:09,  1.93it/s]  4%|▍         | 28/625 [00:14<05:10,  1.92it/s]  5%|▍         | 29/625 [00:14<05:09,  1.93it/s]  5%|▍         | 30/625 [00:15<05:00,  1.98it/s]                                                {'loss': 0.4352, 'learning_rate': 0.001, 'epoch': 0.05}
  5%|▍         | 30/625 [00:15<05:00,  1.98it/s]  5%|▍         | 31/625 [00:15<04:59,  1.98it/s]  5%|▌         | 32/625 [00:16<05:02,  1.96it/s]  5%|▌         | 33/625 [00:16<05:05,  1.94it/s]  5%|▌         | 34/625 [00:17<05:04,  1.94it/s]  6%|▌         | 35/625 [00:17<05:10,  1.90it/s]  6%|▌         | 36/625 [00:18<05:14,  1.87it/s]  6%|▌         | 37/625 [00:19<05:16,  1.86it/s]  6%|▌         | 38/625 [00:19<05:12,  1.88it/s]  6%|▌         | 39/625 [00:20<05:12,  1.87it/s]  6%|▋         | 40/625 [00:20<05:10,  1.89it/s]                                                {'loss': 0.3798, 'learning_rate': 0.001, 'epoch': 0.06}
  6%|▋         | 40/625 [00:20<05:10,  1.89it/s]  7%|▋         | 41/625 [00:21<05:09,  1.88it/s]  7%|▋         | 42/625 [00:21<05:09,  1.88it/s]  7%|▋         | 43/625 [00:22<05:10,  1.87it/s]  7%|▋         | 44/625 [00:22<05:09,  1.88it/s]  7%|▋         | 45/625 [00:23<05:04,  1.91it/s]  7%|▋         | 46/625 [00:23<04:56,  1.95it/s]  8%|▊         | 47/625 [00:24<04:48,  2.00it/s]  8%|▊         | 48/625 [00:24<04:50,  1.99it/s]  8%|▊         | 49/625 [00:25<04:53,  1.96it/s]  8%|▊         | 50/625 [00:25<04:55,  1.95it/s]                                                {'loss': 0.3476, 'learning_rate': 0.001, 'epoch': 0.08}
  8%|▊         | 50/625 [00:25<04:55,  1.95it/s]  8%|▊         | 51/625 [00:26<04:58,  1.92it/s]  8%|▊         | 52/625 [00:26<04:59,  1.92it/s]  8%|▊         | 53/625 [00:27<04:59,  1.91it/s]  9%|▊         | 54/625 [00:27<04:59,  1.91it/s]  9%|▉         | 55/625 [00:28<04:56,  1.92it/s]  9%|▉         | 56/625 [00:28<04:58,  1.91it/s]  9%|▉         | 57/625 [00:29<04:58,  1.90it/s]  9%|▉         | 58/625 [00:29<04:46,  1.98it/s]  9%|▉         | 59/625 [00:30<04:49,  1.95it/s] 10%|▉         | 60/625 [00:30<04:41,  2.01it/s]                                                {'loss': 0.3242, 'learning_rate': 0.001, 'epoch': 0.1}
 10%|▉         | 60/625 [00:30<04:41,  2.01it/s] 10%|▉         | 61/625 [00:31<04:37,  2.03it/s] 10%|▉         | 62/625 [00:31<04:36,  2.04it/s] 10%|█         | 63/625 [00:32<04:43,  1.98it/s] 10%|█         | 64/625 [00:32<04:47,  1.95it/s] 10%|█         | 65/625 [00:33<04:51,  1.92it/s] 11%|█         | 66/625 [00:34<04:46,  1.95it/s] 11%|█         | 67/625 [00:34<04:51,  1.91it/s] 11%|█         | 68/625 [00:35<04:41,  1.98it/s] 11%|█         | 69/625 [00:35<04:45,  1.95it/s] 11%|█         | 70/625 [00:36<04:41,  1.97it/s]                                                {'loss': 0.3432, 'learning_rate': 0.001, 'epoch': 0.11}
 11%|█         | 70/625 [00:36<04:41,  1.97it/s] 11%|█▏        | 71/625 [00:36<04:48,  1.92it/s] 12%|█▏        | 72/625 [00:37<04:50,  1.91it/s] 12%|█▏        | 73/625 [00:37<04:53,  1.88it/s] 12%|█▏        | 74/625 [00:38<04:54,  1.87it/s] 12%|█▏        | 75/625 [00:38<04:51,  1.88it/s] 12%|█▏        | 76/625 [00:39<04:54,  1.86it/s] 12%|█▏        | 77/625 [00:39<04:45,  1.92it/s] 12%|█▏        | 78/625 [00:40<04:48,  1.89it/s] 13%|█▎        | 79/625 [00:40<04:50,  1.88it/s] 13%|█▎        | 80/625 [00:41<04:43,  1.92it/s]                                                {'loss': 0.3399, 'learning_rate': 0.001, 'epoch': 0.13}
 13%|█▎        | 80/625 [00:41<04:43,  1.92it/s] 13%|█▎        | 81/625 [00:41<04:40,  1.94it/s] 13%|█▎        | 82/625 [00:42<04:44,  1.91it/s] 13%|█▎        | 83/625 [00:42<04:46,  1.89it/s] 13%|█▎        | 84/625 [00:43<04:47,  1.88it/s] 14%|█▎        | 85/625 [00:43<04:36,  1.95it/s] 14%|█▍        | 86/625 [00:44<04:41,  1.92it/s] 14%|█▍        | 87/625 [00:44<04:31,  1.98it/s] 14%|█▍        | 88/625 [00:45<04:28,  2.00it/s] 14%|█▍        | 89/625 [00:45<04:31,  1.98it/s] 14%|█▍        | 90/625 [00:46<04:34,  1.95it/s]                                                {'loss': 0.2893, 'learning_rate': 0.001, 'epoch': 0.14}
 14%|█▍        | 90/625 [00:46<04:34,  1.95it/s] 15%|█▍        | 91/625 [00:47<04:39,  1.91it/s] 15%|█▍        | 92/625 [00:47<04:34,  1.94it/s] 15%|█▍        | 93/625 [00:48<04:29,  1.98it/s] 15%|█▌        | 94/625 [00:48<04:34,  1.94it/s] 15%|█▌        | 95/625 [00:49<04:36,  1.91it/s] 15%|█▌        | 96/625 [00:49<04:38,  1.90it/s] 16%|█▌        | 97/625 [00:50<04:39,  1.89it/s] 16%|█▌        | 98/625 [00:50<04:42,  1.86it/s] 16%|█▌        | 99/625 [00:51<04:42,  1.86it/s] 16%|█▌        | 100/625 [00:51<04:58,  1.76it/s]                                                 {'loss': 0.305, 'learning_rate': 0.001, 'epoch': 0.16}
 16%|█▌        | 100/625 [00:51<04:58,  1.76it/s] 16%|█▌        | 101/625 [00:52<04:44,  1.84it/s] 16%|█▋        | 102/625 [00:52<04:42,  1.85it/s] 16%|█▋        | 103/625 [00:53<04:42,  1.85it/s] 17%|█▋        | 104/625 [00:53<04:37,  1.88it/s] 17%|█▋        | 105/625 [00:54<04:27,  1.95it/s] 17%|█▋        | 106/625 [00:55<04:32,  1.90it/s] 17%|█▋        | 107/625 [00:55<04:36,  1.87it/s] 17%|█▋        | 108/625 [00:56<04:38,  1.86it/s] 17%|█▋        | 109/625 [00:56<04:43,  1.82it/s] 18%|█▊        | 110/625 [00:57<04:41,  1.83it/s]                                                 {'loss': 0.2494, 'learning_rate': 0.001, 'epoch': 0.18}
 18%|█▊        | 110/625 [00:57<04:41,  1.83it/s] 18%|█▊        | 111/625 [00:57<04:30,  1.90it/s] 18%|█▊        | 112/625 [00:58<04:25,  1.93it/s] 18%|█▊        | 113/625 [00:58<04:28,  1.91it/s] 18%|█▊        | 114/625 [00:59<04:30,  1.89it/s] 18%|█▊        | 115/625 [00:59<04:22,  1.95it/s] 19%|█▊        | 116/625 [01:00<04:26,  1.91it/s] 19%|█▊        | 117/625 [01:00<04:20,  1.95it/s] 19%|█▉        | 118/625 [01:01<04:22,  1.93it/s] 19%|█▉        | 119/625 [01:01<04:27,  1.89it/s] 19%|█▉        | 120/625 [01:02<04:29,  1.88it/s]                                                 {'loss': 0.2659, 'learning_rate': 0.001, 'epoch': 0.19}
 19%|█▉        | 120/625 [01:02<04:29,  1.88it/s] 19%|█▉        | 121/625 [01:02<04:29,  1.87it/s] 20%|█▉        | 122/625 [01:03<04:22,  1.92it/s] 20%|█▉        | 123/625 [01:03<04:22,  1.91it/s] 20%|█▉        | 124/625 [01:04<04:22,  1.91it/s] 20%|██        | 125/625 [01:04<04:14,  1.97it/s] 20%|██        | 126/625 [01:05<04:18,  1.93it/s] 20%|██        | 127/625 [01:05<04:12,  1.97it/s] 20%|██        | 128/625 [01:06<04:06,  2.02it/s] 21%|██        | 129/625 [01:07<04:34,  1.81it/s] 21%|██        | 130/625 [01:07<04:25,  1.86it/s]                                                 {'loss': 0.2747, 'learning_rate': 0.001, 'epoch': 0.21}
 21%|██        | 130/625 [01:07<04:25,  1.86it/s] 21%|██        | 131/625 [01:08<04:16,  1.93it/s] 21%|██        | 132/625 [01:08<04:17,  1.91it/s] 21%|██▏       | 133/625 [01:09<04:08,  1.98it/s] 21%|██▏       | 134/625 [01:09<04:04,  2.01it/s] 22%|██▏       | 135/625 [01:10<04:10,  1.96it/s] 22%|██▏       | 136/625 [01:10<04:11,  1.95it/s] 22%|██▏       | 137/625 [01:11<04:13,  1.93it/s] 22%|██▏       | 138/625 [01:11<04:12,  1.93it/s] 22%|██▏       | 139/625 [01:12<04:10,  1.94it/s] 22%|██▏       | 140/625 [01:12<04:14,  1.90it/s]                                                 {'loss': 0.2734, 'learning_rate': 0.001, 'epoch': 0.22}
 22%|██▏       | 140/625 [01:12<04:14,  1.90it/s] 23%|██▎       | 141/625 [01:13<04:06,  1.96it/s] 23%|██▎       | 142/625 [01:13<04:11,  1.92it/s] 23%|██▎       | 143/625 [01:14<04:14,  1.89it/s] 23%|██▎       | 144/625 [01:14<04:15,  1.88it/s] 23%|██▎       | 145/625 [01:15<04:16,  1.87it/s] 23%|██▎       | 146/625 [01:15<04:13,  1.89it/s] 24%|██▎       | 147/625 [01:16<04:08,  1.92it/s] 24%|██▎       | 148/625 [01:16<04:09,  1.91it/s] 24%|██▍       | 149/625 [01:17<04:03,  1.95it/s] 24%|██▍       | 150/625 [01:17<04:06,  1.92it/s]                                                 {'loss': 0.2556, 'learning_rate': 0.001, 'epoch': 0.24}
 24%|██▍       | 150/625 [01:17<04:06,  1.92it/s] 24%|██▍       | 151/625 [01:18<04:04,  1.94it/s] 24%|██▍       | 152/625 [01:18<03:58,  1.98it/s] 24%|██▍       | 153/625 [01:19<03:56,  2.00it/s] 25%|██▍       | 154/625 [01:19<04:01,  1.95it/s] 25%|██▍       | 155/625 [01:20<04:03,  1.93it/s] 25%|██▍       | 156/625 [01:21<03:58,  1.96it/s] 25%|██▌       | 157/625 [01:21<03:54,  2.00it/s] 25%|██▌       | 158/625 [01:22<03:57,  1.96it/s] 25%|██▌       | 159/625 [01:22<04:01,  1.93it/s] 26%|██▌       | 160/625 [01:23<04:02,  1.91it/s]                                                 {'loss': 0.2154, 'learning_rate': 0.001, 'epoch': 0.26}
 26%|██▌       | 160/625 [01:23<04:02,  1.91it/s] 26%|██▌       | 161/625 [01:23<03:57,  1.95it/s] 26%|██▌       | 162/625 [01:24<03:51,  2.00it/s] 26%|██▌       | 163/625 [01:24<03:54,  1.97it/s] 26%|██▌       | 164/625 [01:25<03:49,  2.01it/s] 26%|██▋       | 165/625 [01:25<03:50,  2.00it/s] 27%|██▋       | 166/625 [01:26<03:44,  2.04it/s] 27%|██▋       | 167/625 [01:26<03:40,  2.08it/s] 27%|██▋       | 168/625 [01:27<03:46,  2.02it/s] 27%|██▋       | 169/625 [01:27<03:50,  1.98it/s] 27%|██▋       | 170/625 [01:28<03:53,  1.95it/s]                                                 {'loss': 0.2415, 'learning_rate': 0.001, 'epoch': 0.27}
 27%|██▋       | 170/625 [01:28<03:53,  1.95it/s] 27%|██▋       | 171/625 [01:28<03:55,  1.93it/s] 28%|██▊       | 172/625 [01:29<03:59,  1.89it/s] 28%|██▊       | 173/625 [01:29<03:57,  1.90it/s] 28%|██▊       | 174/625 [01:30<04:10,  1.80it/s] 28%|██▊       | 175/625 [01:30<04:05,  1.83it/s] 28%|██▊       | 176/625 [01:31<04:04,  1.84it/s] 28%|██▊       | 177/625 [01:31<04:04,  1.83it/s] 28%|██▊       | 178/625 [01:32<03:55,  1.90it/s] 29%|██▊       | 179/625 [01:32<04:01,  1.84it/s] 29%|██▉       | 180/625 [01:33<03:51,  1.92it/s]                                                 {'loss': 0.2455, 'learning_rate': 0.001, 'epoch': 0.29}
 29%|██▉       | 180/625 [01:33<03:51,  1.92it/s] 29%|██▉       | 181/625 [01:34<04:09,  1.78it/s] 29%|██▉       | 182/625 [01:34<04:07,  1.79it/s] 29%|██▉       | 183/625 [01:35<04:04,  1.81it/s] 29%|██▉       | 184/625 [01:35<04:01,  1.82it/s] 30%|██▉       | 185/625 [01:36<03:56,  1.86it/s] 30%|██▉       | 186/625 [01:36<03:50,  1.90it/s] 30%|██▉       | 187/625 [01:37<04:03,  1.80it/s] 30%|███       | 188/625 [01:37<03:57,  1.84it/s] 30%|███       | 189/625 [01:38<03:55,  1.85it/s] 30%|███       | 190/625 [01:38<03:54,  1.85it/s]                                                 {'loss': 0.2545, 'learning_rate': 0.001, 'epoch': 0.3}
 30%|███       | 190/625 [01:38<03:54,  1.85it/s] 31%|███       | 191/625 [01:39<03:53,  1.86it/s] 31%|███       | 192/625 [01:40<03:51,  1.87it/s] 31%|███       | 193/625 [01:40<03:52,  1.86it/s] 31%|███       | 194/625 [01:41<04:10,  1.72it/s] 31%|███       | 195/625 [01:41<04:04,  1.76it/s] 31%|███▏      | 196/625 [01:42<03:55,  1.82it/s] 32%|███▏      | 197/625 [01:42<03:47,  1.88it/s] 32%|███▏      | 198/625 [01:43<03:48,  1.87it/s] 32%|███▏      | 199/625 [01:43<03:38,  1.95it/s] 32%|███▏      | 200/625 [01:44<03:33,  1.99it/s]                                                 {'loss': 0.2024, 'learning_rate': 0.001, 'epoch': 0.32}
 32%|███▏      | 200/625 [01:44<03:33,  1.99it/s] 32%|███▏      | 201/625 [01:44<03:51,  1.83it/s] 32%|███▏      | 202/625 [01:45<03:48,  1.85it/s] 32%|███▏      | 203/625 [01:45<03:46,  1.86it/s] 33%|███▎      | 204/625 [01:46<03:46,  1.86it/s] 33%|███▎      | 205/625 [01:47<03:46,  1.85it/s] 33%|███▎      | 206/625 [01:47<03:46,  1.85it/s] 33%|███▎      | 207/625 [01:48<03:40,  1.90it/s] 33%|███▎      | 208/625 [01:48<03:39,  1.90it/s] 33%|███▎      | 209/625 [01:49<03:41,  1.88it/s] 34%|███▎      | 210/625 [01:49<03:37,  1.91it/s]                                                 {'loss': 0.2664, 'learning_rate': 0.001, 'epoch': 0.34}
 34%|███▎      | 210/625 [01:49<03:37,  1.91it/s] 34%|███▍      | 211/625 [01:50<03:37,  1.90it/s] 34%|███▍      | 212/625 [01:50<03:38,  1.89it/s] 34%|███▍      | 213/625 [01:51<03:37,  1.90it/s] 34%|███▍      | 214/625 [01:51<03:38,  1.88it/s] 34%|███▍      | 215/625 [01:52<03:31,  1.93it/s] 35%|███▍      | 216/625 [01:52<03:24,  2.00it/s] 35%|███▍      | 217/625 [01:53<03:29,  1.95it/s] 35%|███▍      | 218/625 [01:53<03:31,  1.93it/s] 35%|███▌      | 219/625 [01:54<03:33,  1.90it/s] 35%|███▌      | 220/625 [01:54<03:34,  1.89it/s]                                                 {'loss': 0.2558, 'learning_rate': 0.001, 'epoch': 0.35}
 35%|███▌      | 220/625 [01:54<03:34,  1.89it/s] 35%|███▌      | 221/625 [01:55<03:29,  1.92it/s] 36%|███▌      | 222/625 [01:55<03:31,  1.90it/s] 36%|███▌      | 223/625 [01:56<03:32,  1.90it/s] 36%|███▌      | 224/625 [01:57<03:32,  1.89it/s] 36%|███▌      | 225/625 [01:57<03:32,  1.88it/s] 36%|███▌      | 226/625 [01:58<03:26,  1.93it/s] 36%|███▋      | 227/625 [01:58<03:23,  1.95it/s] 36%|███▋      | 228/625 [01:59<03:27,  1.91it/s] 37%|███▋      | 229/625 [01:59<03:29,  1.89it/s] 37%|███▋      | 230/625 [02:00<03:28,  1.89it/s]                                                 {'loss': 0.2031, 'learning_rate': 0.001, 'epoch': 0.37}
 37%|███▋      | 230/625 [02:00<03:28,  1.89it/s] 37%|███▋      | 231/625 [02:00<03:28,  1.89it/s] 37%|███▋      | 232/625 [02:01<03:29,  1.88it/s] 37%|███▋      | 233/625 [02:01<03:28,  1.88it/s] 37%|███▋      | 234/625 [02:02<03:27,  1.88it/s] 38%|███▊      | 235/625 [02:02<03:21,  1.93it/s] 38%|███▊      | 236/625 [02:03<03:20,  1.94it/s] 38%|███▊      | 237/625 [02:03<03:21,  1.92it/s] 38%|███▊      | 238/625 [02:04<03:18,  1.95it/s] 38%|███▊      | 239/625 [02:04<03:16,  1.97it/s] 38%|███▊      | 240/625 [02:05<03:18,  1.94it/s]                                                 {'loss': 0.2286, 'learning_rate': 0.001, 'epoch': 0.38}
 38%|███▊      | 240/625 [02:05<03:18,  1.94it/s] 39%|███▊      | 241/625 [02:05<03:18,  1.94it/s] 39%|███▊      | 242/625 [02:06<03:12,  1.99it/s] 39%|███▉      | 243/625 [02:06<03:14,  1.96it/s] 39%|███▉      | 244/625 [02:07<03:08,  2.02it/s] 39%|███▉      | 245/625 [02:07<03:05,  2.05it/s] 39%|███▉      | 246/625 [02:08<03:10,  1.99it/s] 40%|███▉      | 247/625 [02:08<03:08,  2.01it/s] 40%|███▉      | 248/625 [02:09<03:11,  1.97it/s] 40%|███▉      | 249/625 [02:09<03:08,  1.99it/s] 40%|████      | 250/625 [02:10<03:23,  1.84it/s]                                                 {'loss': 0.22, 'learning_rate': 0.001, 'epoch': 0.4}
 40%|████      | 250/625 [02:10<03:23,  1.84it/s] 40%|████      | 251/625 [02:10<03:19,  1.88it/s] 40%|████      | 252/625 [02:11<03:27,  1.80it/s] 40%|████      | 253/625 [02:12<03:23,  1.82it/s] 41%|████      | 254/625 [02:12<03:20,  1.85it/s] 41%|████      | 255/625 [02:13<03:18,  1.87it/s] 41%|████      | 256/625 [02:13<03:16,  1.88it/s] 41%|████      | 257/625 [02:14<03:15,  1.89it/s] 41%|████▏     | 258/625 [02:14<03:14,  1.89it/s] 41%|████▏     | 259/625 [02:15<03:07,  1.95it/s] 42%|████▏     | 260/625 [02:15<03:05,  1.97it/s]                                                 {'loss': 0.2303, 'learning_rate': 0.001, 'epoch': 0.42}
 42%|████▏     | 260/625 [02:15<03:05,  1.97it/s] 42%|████▏     | 261/625 [02:16<03:08,  1.93it/s] 42%|████▏     | 262/625 [02:16<03:21,  1.80it/s] 42%|████▏     | 263/625 [02:17<03:18,  1.83it/s] 42%|████▏     | 264/625 [02:17<03:16,  1.84it/s] 42%|████▏     | 265/625 [02:18<03:12,  1.87it/s] 43%|████▎     | 266/625 [02:18<03:08,  1.91it/s] 43%|████▎     | 267/625 [02:19<03:09,  1.89it/s] 43%|████▎     | 268/625 [02:20<03:08,  1.89it/s] 43%|████▎     | 269/625 [02:20<03:03,  1.94it/s] 43%|████▎     | 270/625 [02:21<03:05,  1.91it/s]                                                 {'loss': 0.2048, 'learning_rate': 0.001, 'epoch': 0.43}
 43%|████▎     | 270/625 [02:21<03:05,  1.91it/s] 43%|████▎     | 271/625 [02:21<03:04,  1.92it/s] 44%|████▎     | 272/625 [02:22<03:00,  1.96it/s] 44%|████▎     | 273/625 [02:22<03:03,  1.92it/s] 44%|████▍     | 274/625 [02:23<03:14,  1.81it/s] 44%|████▍     | 275/625 [02:23<03:12,  1.82it/s] 44%|████▍     | 276/625 [02:24<03:11,  1.82it/s] 44%|████▍     | 277/625 [02:24<03:05,  1.88it/s] 44%|████▍     | 278/625 [02:25<03:04,  1.88it/s] 45%|████▍     | 279/625 [02:25<03:04,  1.87it/s] 45%|████▍     | 280/625 [02:26<03:04,  1.87it/s]                                                 {'loss': 0.2128, 'learning_rate': 0.001, 'epoch': 0.45}
 45%|████▍     | 280/625 [02:26<03:04,  1.87it/s] 45%|████▍     | 281/625 [02:26<03:04,  1.86it/s] 45%|████▌     | 282/625 [02:27<03:02,  1.88it/s] 45%|████▌     | 283/625 [02:27<02:55,  1.95it/s] 45%|████▌     | 284/625 [02:28<02:49,  2.01it/s] 46%|████▌     | 285/625 [02:28<02:53,  1.96it/s] 46%|████▌     | 286/625 [02:29<02:55,  1.93it/s] 46%|████▌     | 287/625 [02:30<02:56,  1.91it/s] 46%|████▌     | 288/625 [02:30<02:51,  1.97it/s] 46%|████▌     | 289/625 [02:30<02:48,  2.00it/s] 46%|████▋     | 290/625 [02:31<02:52,  1.95it/s]                                                 {'loss': 0.2318, 'learning_rate': 0.001, 'epoch': 0.46}
 46%|████▋     | 290/625 [02:31<02:52,  1.95it/s] 47%|████▋     | 291/625 [02:32<02:53,  1.92it/s] 47%|████▋     | 292/625 [02:32<02:54,  1.91it/s] 47%|████▋     | 293/625 [02:33<02:55,  1.89it/s] 47%|████▋     | 294/625 [02:33<02:54,  1.90it/s] 47%|████▋     | 295/625 [02:34<02:51,  1.92it/s] 47%|████▋     | 296/625 [02:34<02:48,  1.95it/s] 48%|████▊     | 297/625 [02:35<02:47,  1.96it/s] 48%|████▊     | 298/625 [02:35<02:45,  1.98it/s] 48%|████▊     | 299/625 [02:36<02:41,  2.02it/s] 48%|████▊     | 300/625 [02:36<02:45,  1.97it/s]                                                 {'loss': 0.2651, 'learning_rate': 0.001, 'epoch': 0.48}
 48%|████▊     | 300/625 [02:36<02:45,  1.97it/s] 48%|████▊     | 301/625 [02:37<02:41,  2.00it/s] 48%|████▊     | 302/625 [02:37<02:42,  1.99it/s] 48%|████▊     | 303/625 [02:38<02:44,  1.95it/s] 49%|████▊     | 304/625 [02:38<02:46,  1.92it/s] 49%|████▉     | 305/625 [02:39<02:42,  1.97it/s] 49%|████▉     | 306/625 [02:39<02:37,  2.02it/s] 49%|████▉     | 307/625 [02:40<02:39,  2.00it/s] 49%|████▉     | 308/625 [02:40<02:45,  1.91it/s] 49%|████▉     | 309/625 [02:41<02:46,  1.90it/s] 50%|████▉     | 310/625 [02:41<02:40,  1.97it/s]                                                 {'loss': 0.1962, 'learning_rate': 0.001, 'epoch': 0.5}
 50%|████▉     | 310/625 [02:41<02:40,  1.97it/s] 50%|████▉     | 311/625 [02:42<02:36,  2.01it/s] 50%|████▉     | 312/625 [02:42<02:33,  2.03it/s] 50%|█████     | 313/625 [02:43<02:36,  1.99it/s] 50%|█████     | 314/625 [02:43<02:38,  1.96it/s] 50%|█████     | 315/625 [02:44<02:40,  1.93it/s] 51%|█████     | 316/625 [02:44<02:37,  1.96it/s] 51%|█████     | 317/625 [02:45<02:33,  2.01it/s] 51%|█████     | 318/625 [02:45<02:36,  1.96it/s] 51%|█████     | 319/625 [02:46<02:32,  2.01it/s] 51%|█████     | 320/625 [02:46<02:29,  2.04it/s]                                                 {'loss': 0.2285, 'learning_rate': 0.001, 'epoch': 0.51}
 51%|█████     | 320/625 [02:46<02:29,  2.04it/s] 51%|█████▏    | 321/625 [02:47<02:27,  2.06it/s] 52%|█████▏    | 322/625 [02:47<02:31,  1.99it/s] 52%|█████▏    | 323/625 [02:48<02:33,  1.96it/s] 52%|█████▏    | 324/625 [02:48<02:36,  1.92it/s] 52%|█████▏    | 325/625 [02:49<02:36,  1.92it/s] 52%|█████▏    | 326/625 [02:49<02:30,  1.98it/s] 52%|█████▏    | 327/625 [02:50<02:32,  1.95it/s] 52%|█████▏    | 328/625 [02:50<02:34,  1.92it/s] 53%|█████▎    | 329/625 [02:51<02:36,  1.90it/s] 53%|█████▎    | 330/625 [02:51<02:36,  1.88it/s]                                                 {'loss': 0.2773, 'learning_rate': 0.001, 'epoch': 0.53}
 53%|█████▎    | 330/625 [02:51<02:36,  1.88it/s] 53%|█████▎    | 331/625 [02:52<02:31,  1.94it/s] 53%|█████▎    | 332/625 [02:53<02:38,  1.85it/s] 53%|█████▎    | 333/625 [02:53<02:37,  1.86it/s] 53%|█████▎    | 334/625 [02:54<02:34,  1.89it/s] 54%|█████▎    | 335/625 [02:54<02:31,  1.91it/s] 54%|█████▍    | 336/625 [02:55<02:31,  1.90it/s] 54%|█████▍    | 337/625 [02:55<02:30,  1.91it/s] 54%|█████▍    | 338/625 [02:56<02:30,  1.90it/s] 54%|█████▍    | 339/625 [02:56<02:31,  1.89it/s] 54%|█████▍    | 340/625 [02:57<02:26,  1.95it/s]                                                 {'loss': 0.2405, 'learning_rate': 0.001, 'epoch': 0.54}
 54%|█████▍    | 340/625 [02:57<02:26,  1.95it/s] 55%|█████▍    | 341/625 [02:57<02:24,  1.96it/s] 55%|█████▍    | 342/625 [02:58<02:21,  2.00it/s] 55%|█████▍    | 343/625 [02:58<02:24,  1.95it/s] 55%|█████▌    | 344/625 [02:59<02:26,  1.92it/s] 55%|█████▌    | 345/625 [02:59<02:24,  1.94it/s] 55%|█████▌    | 346/625 [03:00<02:24,  1.93it/s] 56%|█████▌    | 347/625 [03:00<02:22,  1.95it/s] 56%|█████▌    | 348/625 [03:01<02:23,  1.93it/s] 56%|█████▌    | 349/625 [03:01<02:19,  1.97it/s] 56%|█████▌    | 350/625 [03:02<02:22,  1.94it/s]                                                 {'loss': 0.2629, 'learning_rate': 0.001, 'epoch': 0.56}
 56%|█████▌    | 350/625 [03:02<02:22,  1.94it/s] 56%|█████▌    | 351/625 [03:02<02:18,  1.98it/s] 56%|█████▋    | 352/625 [03:03<02:19,  1.96it/s] 56%|█████▋    | 353/625 [03:03<02:21,  1.93it/s] 57%|█████▋    | 354/625 [03:04<02:22,  1.91it/s] 57%|█████▋    | 355/625 [03:04<02:22,  1.89it/s] 57%|█████▋    | 356/625 [03:05<02:18,  1.94it/s] 57%|█████▋    | 357/625 [03:05<02:19,  1.92it/s] 57%|█████▋    | 358/625 [03:06<02:20,  1.90it/s] 57%|█████▋    | 359/625 [03:06<02:15,  1.97it/s] 58%|█████▊    | 360/625 [03:07<02:17,  1.93it/s]                                                 {'loss': 0.2249, 'learning_rate': 0.001, 'epoch': 0.58}
 58%|█████▊    | 360/625 [03:07<02:17,  1.93it/s] 58%|█████▊    | 361/625 [03:08<02:14,  1.96it/s] 58%|█████▊    | 362/625 [03:08<02:10,  2.01it/s] 58%|█████▊    | 363/625 [03:09<02:14,  1.95it/s] 58%|█████▊    | 364/625 [03:09<02:18,  1.88it/s] 58%|█████▊    | 365/625 [03:10<02:14,  1.93it/s] 59%|█████▊    | 366/625 [03:10<02:13,  1.93it/s] 59%|█████▊    | 367/625 [03:11<02:14,  1.91it/s] 59%|█████▉    | 368/625 [03:11<02:12,  1.94it/s] 59%|█████▉    | 369/625 [03:12<02:13,  1.91it/s] 59%|█████▉    | 370/625 [03:12<02:10,  1.95it/s]                                                 {'loss': 0.2101, 'learning_rate': 0.001, 'epoch': 0.59}
 59%|█████▉    | 370/625 [03:12<02:10,  1.95it/s] 59%|█████▉    | 371/625 [03:13<02:09,  1.96it/s] 60%|█████▉    | 372/625 [03:13<02:10,  1.93it/s] 60%|█████▉    | 373/625 [03:14<02:11,  1.92it/s] 60%|█████▉    | 374/625 [03:14<02:11,  1.91it/s] 60%|██████    | 375/625 [03:15<02:11,  1.90it/s] 60%|██████    | 376/625 [03:15<02:10,  1.90it/s] 60%|██████    | 377/625 [03:16<02:06,  1.95it/s] 60%|██████    | 378/625 [03:16<02:06,  1.95it/s] 61%|██████    | 379/625 [03:17<02:06,  1.94it/s] 61%|██████    | 380/625 [03:17<02:07,  1.92it/s]                                                 {'loss': 0.2119, 'learning_rate': 0.001, 'epoch': 0.61}
 61%|██████    | 380/625 [03:17<02:07,  1.92it/s] 61%|██████    | 381/625 [03:18<02:02,  1.99it/s] 61%|██████    | 382/625 [03:18<02:04,  1.95it/s] 61%|██████▏   | 383/625 [03:19<02:05,  1.94it/s] 61%|██████▏   | 384/625 [03:19<02:04,  1.94it/s] 62%|██████▏   | 385/625 [03:20<02:04,  1.93it/s] 62%|██████▏   | 386/625 [03:20<02:03,  1.94it/s] 62%|██████▏   | 387/625 [03:21<02:00,  1.98it/s] 62%|██████▏   | 388/625 [03:21<02:02,  1.94it/s] 62%|██████▏   | 389/625 [03:22<01:59,  1.97it/s] 62%|██████▏   | 390/625 [03:22<02:00,  1.95it/s]                                                 {'loss': 0.179, 'learning_rate': 0.001, 'epoch': 0.62}
 62%|██████▏   | 390/625 [03:22<02:00,  1.95it/s] 63%|██████▎   | 391/625 [03:23<01:59,  1.96it/s] 63%|██████▎   | 392/625 [03:23<02:00,  1.94it/s] 63%|██████▎   | 393/625 [03:24<02:00,  1.93it/s] 63%|██████▎   | 394/625 [03:25<01:58,  1.95it/s] 63%|██████▎   | 395/625 [03:25<01:57,  1.95it/s] 63%|██████▎   | 396/625 [03:26<01:56,  1.96it/s] 64%|██████▎   | 397/625 [03:26<01:56,  1.95it/s] 64%|██████▎   | 398/625 [03:27<01:56,  1.94it/s] 64%|██████▍   | 399/625 [03:27<01:57,  1.92it/s] 64%|██████▍   | 400/625 [03:28<01:52,  2.00it/s]                                                 {'loss': 0.2186, 'learning_rate': 0.001, 'epoch': 0.64}
 64%|██████▍   | 400/625 [03:28<01:52,  2.00it/s] 64%|██████▍   | 401/625 [03:28<01:53,  1.97it/s] 64%|██████▍   | 402/625 [03:29<01:54,  1.94it/s] 64%|██████▍   | 403/625 [03:29<01:51,  1.99it/s] 65%|██████▍   | 404/625 [03:30<01:50,  2.00it/s] 65%|██████▍   | 405/625 [03:30<01:51,  1.97it/s] 65%|██████▍   | 406/625 [03:31<02:00,  1.82it/s] 65%|██████▌   | 407/625 [03:31<01:57,  1.85it/s] 65%|██████▌   | 408/625 [03:32<01:56,  1.86it/s] 65%|██████▌   | 409/625 [03:32<01:55,  1.88it/s] 66%|██████▌   | 410/625 [03:33<01:52,  1.92it/s]                                                 {'loss': 0.2179, 'learning_rate': 0.001, 'epoch': 0.66}
 66%|██████▌   | 410/625 [03:33<01:52,  1.92it/s] 66%|██████▌   | 411/625 [03:33<01:51,  1.91it/s] 66%|██████▌   | 412/625 [03:34<01:51,  1.91it/s] 66%|██████▌   | 413/625 [03:34<01:47,  1.97it/s] 66%|██████▌   | 414/625 [03:35<01:48,  1.94it/s] 66%|██████▋   | 415/625 [03:35<01:50,  1.91it/s] 67%|██████▋   | 416/625 [03:36<01:49,  1.90it/s] 67%|██████▋   | 417/625 [03:36<01:49,  1.90it/s] 67%|██████▋   | 418/625 [03:37<01:49,  1.89it/s] 67%|██████▋   | 419/625 [03:38<01:49,  1.89it/s] 67%|██████▋   | 420/625 [03:38<01:48,  1.88it/s]                                                 {'loss': 0.2518, 'learning_rate': 0.001, 'epoch': 0.67}
 67%|██████▋   | 420/625 [03:38<01:48,  1.88it/s] 67%|██████▋   | 421/625 [03:39<01:48,  1.88it/s] 68%|██████▊   | 422/625 [03:39<01:46,  1.91it/s] 68%|██████▊   | 423/625 [03:40<01:44,  1.94it/s] 68%|██████▊   | 424/625 [03:40<01:44,  1.93it/s] 68%|██████▊   | 425/625 [03:41<01:44,  1.91it/s] 68%|██████▊   | 426/625 [03:41<01:45,  1.89it/s] 68%|██████▊   | 427/625 [03:42<01:42,  1.92it/s] 68%|██████▊   | 428/625 [03:42<01:43,  1.90it/s] 69%|██████▊   | 429/625 [03:43<01:43,  1.89it/s] 69%|██████▉   | 430/625 [03:43<01:43,  1.89it/s]                                                 {'loss': 0.1957, 'learning_rate': 0.001, 'epoch': 0.69}
 69%|██████▉   | 430/625 [03:43<01:43,  1.89it/s] 69%|██████▉   | 431/625 [03:44<01:42,  1.89it/s] 69%|██████▉   | 432/625 [03:44<01:42,  1.88it/s] 69%|██████▉   | 433/625 [03:45<01:42,  1.88it/s] 69%|██████▉   | 434/625 [03:45<01:40,  1.90it/s] 70%|██████▉   | 435/625 [03:46<01:37,  1.95it/s] 70%|██████▉   | 436/625 [03:46<01:38,  1.92it/s] 70%|██████▉   | 437/625 [03:47<01:39,  1.90it/s] 70%|███████   | 438/625 [03:48<01:39,  1.88it/s] 70%|███████   | 439/625 [03:48<01:38,  1.90it/s] 70%|███████   | 440/625 [03:49<01:37,  1.91it/s]                                                 {'loss': 0.2555, 'learning_rate': 0.001, 'epoch': 0.7}
 70%|███████   | 440/625 [03:49<01:37,  1.91it/s] 71%|███████   | 441/625 [03:49<01:36,  1.91it/s] 71%|███████   | 442/625 [03:50<01:32,  1.99it/s] 71%|███████   | 443/625 [03:50<01:33,  1.95it/s] 71%|███████   | 444/625 [03:51<01:31,  1.97it/s] 71%|███████   | 445/625 [03:51<01:31,  1.98it/s] 71%|███████▏  | 446/625 [03:52<01:31,  1.95it/s] 72%|███████▏  | 447/625 [03:52<01:29,  1.98it/s] 72%|███████▏  | 448/625 [03:53<01:30,  1.95it/s] 72%|███████▏  | 449/625 [03:53<01:31,  1.92it/s] 72%|███████▏  | 450/625 [03:54<01:31,  1.91it/s]                                                 {'loss': 0.2374, 'learning_rate': 0.001, 'epoch': 0.72}
 72%|███████▏  | 450/625 [03:54<01:31,  1.91it/s] 72%|███████▏  | 451/625 [03:54<01:31,  1.90it/s] 72%|███████▏  | 452/625 [03:55<01:31,  1.89it/s] 72%|███████▏  | 453/625 [03:55<01:29,  1.93it/s] 73%|███████▎  | 454/625 [03:56<01:29,  1.92it/s] 73%|███████▎  | 455/625 [03:56<01:28,  1.91it/s] 73%|███████▎  | 456/625 [03:57<01:29,  1.90it/s] 73%|███████▎  | 457/625 [03:57<01:28,  1.89it/s] 73%|███████▎  | 458/625 [03:58<01:28,  1.88it/s] 73%|███████▎  | 459/625 [03:58<01:28,  1.87it/s] 74%|███████▎  | 460/625 [03:59<01:25,  1.93it/s]                                                 {'loss': 0.2298, 'learning_rate': 0.001, 'epoch': 0.74}
 74%|███████▎  | 460/625 [03:59<01:25,  1.93it/s] 74%|███████▍  | 461/625 [03:59<01:26,  1.90it/s] 74%|███████▍  | 462/625 [04:00<01:26,  1.89it/s] 74%|███████▍  | 463/625 [04:01<01:25,  1.90it/s] 74%|███████▍  | 464/625 [04:01<01:25,  1.87it/s] 74%|███████▍  | 465/625 [04:02<01:25,  1.87it/s] 75%|███████▍  | 466/625 [04:02<01:25,  1.86it/s] 75%|███████▍  | 467/625 [04:03<01:21,  1.93it/s] 75%|███████▍  | 468/625 [04:03<01:22,  1.90it/s] 75%|███████▌  | 469/625 [04:04<01:22,  1.89it/s] 75%|███████▌  | 470/625 [04:04<01:20,  1.93it/s]                                                 {'loss': 0.2307, 'learning_rate': 0.001, 'epoch': 0.75}
 75%|███████▌  | 470/625 [04:04<01:20,  1.93it/s] 75%|███████▌  | 471/625 [04:05<01:20,  1.91it/s] 76%|███████▌  | 472/625 [04:05<01:20,  1.89it/s] 76%|███████▌  | 473/625 [04:06<01:21,  1.88it/s] 76%|███████▌  | 474/625 [04:06<01:20,  1.87it/s] 76%|███████▌  | 475/625 [04:07<01:18,  1.90it/s] 76%|███████▌  | 476/625 [04:07<01:19,  1.88it/s] 76%|███████▋  | 477/625 [04:08<01:18,  1.88it/s] 76%|███████▋  | 478/625 [04:09<01:18,  1.87it/s] 77%|███████▋  | 479/625 [04:09<01:18,  1.87it/s] 77%|███████▋  | 480/625 [04:10<01:17,  1.87it/s]                                                 {'loss': 0.1865, 'learning_rate': 0.001, 'epoch': 0.77}
 77%|███████▋  | 480/625 [04:10<01:17,  1.87it/s] 77%|███████▋  | 481/625 [04:10<01:15,  1.90it/s] 77%|███████▋  | 482/625 [04:11<01:15,  1.89it/s] 77%|███████▋  | 483/625 [04:11<01:14,  1.90it/s] 77%|███████▋  | 484/625 [04:12<01:14,  1.90it/s] 78%|███████▊  | 485/625 [04:12<01:13,  1.90it/s] 78%|███████▊  | 486/625 [04:13<01:13,  1.89it/s] 78%|███████▊  | 487/625 [04:13<01:12,  1.90it/s] 78%|███████▊  | 488/625 [04:14<01:12,  1.89it/s] 78%|███████▊  | 489/625 [04:14<01:11,  1.89it/s] 78%|███████▊  | 490/625 [04:15<01:11,  1.89it/s]                                                 {'loss': 0.2376, 'learning_rate': 0.001, 'epoch': 0.78}
 78%|███████▊  | 490/625 [04:15<01:11,  1.89it/s] 79%|███████▊  | 491/625 [04:15<01:10,  1.89it/s] 79%|███████▊  | 492/625 [04:16<01:09,  1.90it/s] 79%|███████▉  | 493/625 [04:16<01:09,  1.90it/s] 79%|███████▉  | 494/625 [04:17<01:09,  1.89it/s] 79%|███████▉  | 495/625 [04:17<01:08,  1.89it/s] 79%|███████▉  | 496/625 [04:18<01:06,  1.95it/s] 80%|███████▉  | 497/625 [04:18<01:06,  1.93it/s] 80%|███████▉  | 498/625 [04:19<01:03,  1.99it/s] 80%|███████▉  | 499/625 [04:19<01:04,  1.96it/s] 80%|████████  | 500/625 [04:20<01:04,  1.93it/s]                                                 {'loss': 0.2402, 'learning_rate': 0.001, 'epoch': 0.8}
 80%|████████  | 500/625 [04:20<01:04,  1.93it/s] 80%|████████  | 501/625 [04:21<01:04,  1.92it/s] 80%|████████  | 502/625 [04:21<01:04,  1.91it/s] 80%|████████  | 503/625 [04:22<01:03,  1.93it/s] 81%|████████  | 504/625 [04:22<01:03,  1.92it/s] 81%|████████  | 505/625 [04:23<01:02,  1.92it/s] 81%|████████  | 506/625 [04:23<01:02,  1.91it/s] 81%|████████  | 507/625 [04:24<01:06,  1.78it/s] 81%|████████▏ | 508/625 [04:24<01:04,  1.82it/s] 81%|████████▏ | 509/625 [04:25<01:02,  1.85it/s] 82%|████████▏ | 510/625 [04:25<01:01,  1.86it/s]                                                 {'loss': 0.1812, 'learning_rate': 0.001, 'epoch': 0.82}
 82%|████████▏ | 510/625 [04:25<01:01,  1.86it/s] 82%|████████▏ | 511/625 [04:26<01:00,  1.87it/s] 82%|████████▏ | 512/625 [04:26<00:59,  1.91it/s] 82%|████████▏ | 513/625 [04:27<00:56,  1.98it/s] 82%|████████▏ | 514/625 [04:27<00:54,  2.04it/s] 82%|████████▏ | 515/625 [04:28<00:55,  2.00it/s] 83%|████████▎ | 516/625 [04:28<00:55,  1.96it/s] 83%|████████▎ | 517/625 [04:29<00:55,  1.96it/s] 83%|████████▎ | 518/625 [04:29<00:55,  1.94it/s] 83%|████████▎ | 519/625 [04:30<00:55,  1.93it/s] 83%|████████▎ | 520/625 [04:30<00:55,  1.91it/s]                                                 {'loss': 0.1858, 'learning_rate': 0.001, 'epoch': 0.83}
 83%|████████▎ | 520/625 [04:30<00:55,  1.91it/s] 83%|████████▎ | 521/625 [04:31<00:54,  1.90it/s] 84%|████████▎ | 522/625 [04:32<00:53,  1.93it/s] 84%|████████▎ | 523/625 [04:32<00:53,  1.92it/s] 84%|████████▍ | 524/625 [04:33<00:51,  1.96it/s] 84%|████████▍ | 525/625 [04:33<00:49,  2.01it/s] 84%|████████▍ | 526/625 [04:34<00:49,  1.98it/s] 84%|████████▍ | 527/625 [04:34<00:49,  1.97it/s] 84%|████████▍ | 528/625 [04:35<00:48,  2.01it/s] 85%|████████▍ | 529/625 [04:35<00:46,  2.06it/s] 85%|████████▍ | 530/625 [04:35<00:46,  2.03it/s]                                                 {'loss': 0.2134, 'learning_rate': 0.001, 'epoch': 0.85}
 85%|████████▍ | 530/625 [04:35<00:46,  2.03it/s] 85%|████████▍ | 531/625 [04:36<00:47,  1.98it/s] 85%|████████▌ | 532/625 [04:37<00:47,  1.96it/s] 85%|████████▌ | 533/625 [04:37<00:47,  1.95it/s] 85%|████████▌ | 534/625 [04:38<00:47,  1.93it/s] 86%|████████▌ | 535/625 [04:38<00:46,  1.93it/s] 86%|████████▌ | 536/625 [04:39<00:45,  1.95it/s] 86%|████████▌ | 537/625 [04:39<00:43,  2.00it/s] 86%|████████▌ | 538/625 [04:40<00:44,  1.98it/s] 86%|████████▌ | 539/625 [04:40<00:43,  1.96it/s] 86%|████████▋ | 540/625 [04:41<00:44,  1.93it/s]                                                 {'loss': 0.2194, 'learning_rate': 0.001, 'epoch': 0.86}
 86%|████████▋ | 540/625 [04:41<00:44,  1.93it/s] 87%|████████▋ | 541/625 [04:41<00:46,  1.79it/s] 87%|████████▋ | 542/625 [04:42<00:45,  1.82it/s] 87%|████████▋ | 543/625 [04:42<00:44,  1.85it/s] 87%|████████▋ | 544/625 [04:43<00:43,  1.87it/s] 87%|████████▋ | 545/625 [04:43<00:42,  1.88it/s] 87%|████████▋ | 546/625 [04:44<00:41,  1.90it/s] 88%|████████▊ | 547/625 [04:44<00:39,  1.96it/s] 88%|████████▊ | 548/625 [04:45<00:39,  1.95it/s] 88%|████████▊ | 549/625 [04:45<00:38,  1.98it/s] 88%|████████▊ | 550/625 [04:46<00:38,  1.96it/s]                                                 {'loss': 0.2398, 'learning_rate': 0.001, 'epoch': 0.88}
 88%|████████▊ | 550/625 [04:46<00:38,  1.96it/s] 88%|████████▊ | 551/625 [04:46<00:37,  1.97it/s] 88%|████████▊ | 552/625 [04:47<00:36,  1.99it/s] 88%|████████▊ | 553/625 [04:47<00:36,  1.96it/s] 89%|████████▊ | 554/625 [04:48<00:36,  1.93it/s] 89%|████████▉ | 555/625 [04:48<00:36,  1.92it/s] 89%|████████▉ | 556/625 [04:49<00:36,  1.91it/s] 89%|████████▉ | 557/625 [04:50<00:35,  1.90it/s] 89%|████████▉ | 558/625 [04:50<00:35,  1.89it/s] 89%|████████▉ | 559/625 [04:51<00:33,  1.95it/s] 90%|████████▉ | 560/625 [04:51<00:33,  1.92it/s]                                                 {'loss': 0.2106, 'learning_rate': 0.001, 'epoch': 0.9}
 90%|████████▉ | 560/625 [04:51<00:33,  1.92it/s] 90%|████████▉ | 561/625 [04:52<00:32,  1.98it/s] 90%|████████▉ | 562/625 [04:52<00:32,  1.95it/s] 90%|█████████ | 563/625 [04:53<00:30,  2.02it/s] 90%|█████████ | 564/625 [04:53<00:30,  1.99it/s] 90%|█████████ | 565/625 [04:54<00:30,  1.96it/s] 91%|█████████ | 566/625 [04:54<00:30,  1.95it/s] 91%|█████████ | 567/625 [04:55<00:28,  2.00it/s] 91%|█████████ | 568/625 [04:55<00:29,  1.95it/s] 91%|█████████ | 569/625 [04:56<00:28,  1.94it/s] 91%|█████████ | 570/625 [04:56<00:28,  1.93it/s]                                                 {'loss': 0.2693, 'learning_rate': 0.001, 'epoch': 0.91}
 91%|█████████ | 570/625 [04:56<00:28,  1.93it/s] 91%|█████████▏| 571/625 [04:57<00:27,  1.99it/s] 92%|█████████▏| 572/625 [04:57<00:26,  2.03it/s] 92%|█████████▏| 573/625 [04:58<00:26,  1.98it/s] 92%|█████████▏| 574/625 [04:58<00:26,  1.95it/s] 92%|█████████▏| 575/625 [04:59<00:25,  1.95it/s] 92%|█████████▏| 576/625 [04:59<00:24,  2.00it/s] 92%|█████████▏| 577/625 [05:00<00:24,  1.96it/s] 92%|█████████▏| 578/625 [05:00<00:23,  2.02it/s] 93%|█████████▎| 579/625 [05:01<00:23,  1.97it/s] 93%|█████████▎| 580/625 [05:01<00:23,  1.95it/s]                                                 {'loss': 0.2416, 'learning_rate': 0.001, 'epoch': 0.93}
 93%|█████████▎| 580/625 [05:01<00:23,  1.95it/s] 93%|█████████▎| 581/625 [05:02<00:22,  1.92it/s] 93%|█████████▎| 582/625 [05:02<00:22,  1.91it/s] 93%|█████████▎| 583/625 [05:03<00:22,  1.90it/s] 93%|█████████▎| 584/625 [05:03<00:21,  1.91it/s] 94%|█████████▎| 585/625 [05:04<00:21,  1.90it/s] 94%|█████████▍| 586/625 [05:04<00:20,  1.94it/s] 94%|█████████▍| 587/625 [05:05<00:19,  1.93it/s] 94%|█████████▍| 588/625 [05:05<00:19,  1.90it/s] 94%|█████████▍| 589/625 [05:06<00:19,  1.89it/s] 94%|█████████▍| 590/625 [05:06<00:17,  1.94it/s]                                                 {'loss': 0.257, 'learning_rate': 0.001, 'epoch': 0.94}
 94%|█████████▍| 590/625 [05:06<00:17,  1.94it/s] 95%|█████████▍| 591/625 [05:07<00:17,  1.93it/s] 95%|█████████▍| 592/625 [05:07<00:16,  1.97it/s] 95%|█████████▍| 593/625 [05:08<00:16,  1.97it/s] 95%|█████████▌| 594/625 [05:09<00:16,  1.91it/s] 95%|█████████▌| 595/625 [05:09<00:15,  1.92it/s] 95%|█████████▌| 596/625 [05:10<00:15,  1.90it/s] 96%|█████████▌| 597/625 [05:10<00:14,  1.91it/s] 96%|█████████▌| 598/625 [05:11<00:13,  1.96it/s] 96%|█████████▌| 599/625 [05:11<00:12,  2.00it/s] 96%|█████████▌| 600/625 [05:12<00:12,  1.97it/s]                                                 {'loss': 0.2241, 'learning_rate': 0.001, 'epoch': 0.96}
 96%|█████████▌| 600/625 [05:12<00:12,  1.97it/s] 96%|█████████▌| 601/625 [05:12<00:12,  1.93it/s] 96%|█████████▋| 602/625 [05:13<00:11,  1.94it/s] 96%|█████████▋| 603/625 [05:13<00:11,  1.98it/s] 97%|█████████▋| 604/625 [05:14<00:10,  1.94it/s] 97%|█████████▋| 605/625 [05:14<00:10,  1.93it/s] 97%|█████████▋| 606/625 [05:15<00:09,  1.92it/s] 97%|█████████▋| 607/625 [05:15<00:09,  1.91it/s] 97%|█████████▋| 608/625 [05:16<00:08,  1.93it/s] 97%|█████████▋| 609/625 [05:16<00:08,  1.92it/s] 98%|█████████▊| 610/625 [05:17<00:07,  1.95it/s]                                                 {'loss': 0.2474, 'learning_rate': 0.001, 'epoch': 0.98}
 98%|█████████▊| 610/625 [05:17<00:07,  1.95it/s] 98%|█████████▊| 611/625 [05:17<00:06,  2.01it/s] 98%|█████████▊| 612/625 [05:18<00:06,  2.05it/s] 98%|█████████▊| 613/625 [05:18<00:05,  2.03it/s] 98%|█████████▊| 614/625 [05:19<00:05,  2.04it/s] 98%|█████████▊| 615/625 [05:19<00:04,  2.08it/s] 99%|█████████▊| 616/625 [05:20<00:04,  2.01it/s] 99%|█████████▊| 617/625 [05:20<00:04,  1.98it/s] 99%|█████████▉| 618/625 [05:21<00:03,  1.84it/s] 99%|█████████▉| 619/625 [05:21<00:03,  1.92it/s] 99%|█████████▉| 620/625 [05:22<00:02,  1.91it/s]                                                 {'loss': 0.2468, 'learning_rate': 0.001, 'epoch': 0.99}
 99%|█████████▉| 620/625 [05:22<00:02,  1.91it/s] 99%|█████████▉| 621/625 [05:22<00:02,  1.93it/s]100%|█████████▉| 622/625 [05:23<00:01,  1.92it/s]100%|█████████▉| 623/625 [05:23<00:01,  1.90it/s]100%|█████████▉| 624/625 [05:24<00:00,  1.97it/s]100%|██████████| 625/625 [05:24<00:00,  2.02it/s]                                                 {'train_runtime': 324.8461, 'train_samples_per_second': 30.784, 'train_steps_per_second': 1.924, 'train_loss': 0.28364091796875, 'epoch': 1.0}
100%|██████████| 625/625 [05:24<00:00,  2.02it/s]100%|██████████| 625/625 [05:24<00:00,  1.92it/s]
***** train metrics *****
  epoch                    =        1.0
  train_loss               =     0.2836
  train_runtime            = 0:05:24.84
  train_samples            =      10000
  train_samples_per_second =     30.784
  train_steps_per_second   =      1.924
  0%|          | 0/90 [00:00<?, ?it/s]  2%|▏         | 2/90 [00:02<01:59,  1.36s/it]  3%|▎         | 3/90 [00:05<02:49,  1.95s/it]  4%|▍         | 4/90 [00:07<03:05,  2.15s/it]  6%|▌         | 5/90 [00:10<03:21,  2.37s/it]  7%|▋         | 6/90 [00:13<03:30,  2.51s/it]  8%|▊         | 7/90 [00:15<03:03,  2.21s/it]  9%|▉         | 8/90 [00:17<03:11,  2.34s/it] 10%|█         | 9/90 [00:21<03:36,  2.68s/it] 11%|█         | 10/90 [00:23<03:23,  2.54s/it] 12%|█▏        | 11/90 [00:25<03:00,  2.29s/it] 13%|█▎        | 12/90 [00:27<03:07,  2.40s/it] 14%|█▍        | 13/90 [00:29<02:45,  2.15s/it] 16%|█▌        | 14/90 [00:31<02:51,  2.25s/it] 17%|█▋        | 15/90 [00:34<02:57,  2.37s/it] 18%|█▊        | 16/90 [00:37<03:01,  2.46s/it] 19%|█▉        | 17/90 [00:38<02:40,  2.19s/it] 20%|██        | 18/90 [00:41<02:48,  2.35s/it] 21%|██        | 19/90 [00:43<02:49,  2.38s/it] 22%|██▏       | 20/90 [00:46<02:50,  2.44s/it] 23%|██▎       | 21/90 [00:49<02:50,  2.48s/it] 24%|██▍       | 22/90 [00:51<02:45,  2.43s/it] 26%|██▌       | 23/90 [00:53<02:31,  2.26s/it] 27%|██▋       | 24/90 [00:54<02:17,  2.09s/it] 28%|██▊       | 25/90 [00:56<02:05,  1.93s/it] 29%|██▉       | 26/90 [00:59<02:16,  2.13s/it] 30%|███       | 27/90 [01:01<02:24,  2.29s/it] 31%|███       | 28/90 [01:03<02:05,  2.03s/it] 32%|███▏      | 29/90 [01:06<02:21,  2.32s/it] 33%|███▎      | 30/90 [01:08<02:24,  2.41s/it] 34%|███▍      | 31/90 [01:11<02:25,  2.47s/it] 36%|███▌      | 32/90 [01:13<02:25,  2.51s/it] 37%|███▋      | 33/90 [01:16<02:24,  2.53s/it] 38%|███▊      | 34/90 [01:19<02:22,  2.55s/it] 39%|███▉      | 35/90 [01:21<02:21,  2.56s/it] 40%|████      | 36/90 [01:24<02:19,  2.58s/it] 41%|████      | 37/90 [01:26<02:17,  2.59s/it] 42%|████▏     | 38/90 [01:29<02:13,  2.58s/it] 43%|████▎     | 39/90 [01:32<02:11,  2.58s/it] 44%|████▍     | 40/90 [01:34<02:09,  2.59s/it] 46%|████▌     | 41/90 [01:37<02:07,  2.60s/it] 47%|████▋     | 42/90 [01:39<02:04,  2.60s/it] 48%|████▊     | 43/90 [01:42<02:02,  2.60s/it] 49%|████▉     | 44/90 [01:45<01:59,  2.60s/it] 50%|█████     | 45/90 [01:47<01:56,  2.60s/it] 51%|█████     | 46/90 [01:50<01:54,  2.59s/it] 52%|█████▏    | 47/90 [01:52<01:51,  2.59s/it] 53%|█████▎    | 48/90 [01:55<01:48,  2.59s/it] 54%|█████▍    | 49/90 [01:58<01:45,  2.58s/it] 56%|█████▌    | 50/90 [02:00<01:43,  2.59s/it] 57%|█████▋    | 51/90 [02:03<01:41,  2.60s/it] 58%|█████▊    | 52/90 [02:05<01:38,  2.60s/it] 59%|█████▉    | 53/90 [02:08<01:36,  2.60s/it] 60%|██████    | 54/90 [02:11<01:33,  2.60s/it] 61%|██████    | 55/90 [02:13<01:31,  2.60s/it] 62%|██████▏   | 56/90 [02:16<01:28,  2.60s/it] 63%|██████▎   | 57/90 [02:18<01:25,  2.60s/it] 64%|██████▍   | 58/90 [02:21<01:23,  2.59s/it] 66%|██████▌   | 59/90 [02:24<01:20,  2.60s/it] 67%|██████▋   | 60/90 [02:26<01:20,  2.67s/it] 68%|██████▊   | 61/90 [02:28<01:06,  2.29s/it] 69%|██████▉   | 62/90 [02:29<00:53,  1.91s/it] 70%|███████   | 63/90 [02:30<00:45,  1.68s/it] 71%|███████   | 64/90 [02:31<00:38,  1.49s/it] 72%|███████▏  | 65/90 [02:32<00:33,  1.35s/it] 73%|███████▎  | 66/90 [02:33<00:30,  1.26s/it] 74%|███████▍  | 67/90 [02:34<00:27,  1.18s/it] 76%|███████▌  | 68/90 [02:35<00:25,  1.17s/it] 77%|███████▋  | 69/90 [02:36<00:23,  1.12s/it] 78%|███████▊  | 70/90 [02:38<00:23,  1.17s/it] 79%|███████▉  | 71/90 [02:39<00:21,  1.14s/it] 80%|████████  | 72/90 [02:41<00:28,  1.56s/it] 81%|████████  | 73/90 [02:42<00:23,  1.39s/it] 82%|████████▏ | 74/90 [02:44<00:22,  1.39s/it] 83%|████████▎ | 75/90 [02:45<00:18,  1.26s/it] 84%|████████▍ | 76/90 [02:46<00:16,  1.18s/it] 86%|████████▌ | 77/90 [02:46<00:14,  1.11s/it] 87%|████████▋ | 78/90 [02:47<00:12,  1.06s/it] 88%|████████▊ | 79/90 [02:48<00:11,  1.03s/it] 89%|████████▉ | 80/90 [02:49<00:10,  1.04s/it] 90%|█████████ | 81/90 [02:52<00:13,  1.49s/it] 91%|█████████ | 82/90 [02:53<00:10,  1.37s/it] 92%|█████████▏| 83/90 [02:54<00:09,  1.31s/it] 93%|█████████▎| 84/90 [02:56<00:07,  1.32s/it] 94%|█████████▍| 85/90 [02:57<00:06,  1.30s/it] 96%|█████████▌| 86/90 [02:58<00:05,  1.25s/it] 97%|█████████▋| 87/90 [02:59<00:03,  1.20s/it] 98%|█████████▊| 88/90 [03:00<00:02,  1.21s/it] 99%|█████████▉| 89/90 [03:01<00:01,  1.19s/it]100%|██████████| 90/90 [03:03<00:00,  1.33s/it]100%|██████████| 90/90 [03:14<00:00,  2.16s/it]
***** predict metrics *****
  epoch                           =        1.0
  predict_exact_match             =       30.5
  predict_exact_match_for_SC      =    18.3816
  predict_exact_match_for_TC      =    36.5592
  predict_exact_match_for_amazon  =    18.3816
  predict_exact_match_for_dbpedia =       0.75
  predict_exact_match_for_yahoo   =    72.3684
  predict_gen_len                 =     4.8822
  predict_global_step             =        625
  predict_loss                    =     1.4589
  predict_rouge1                  =    35.7187
  predict_rouge1_for_SC           =    30.7141
  predict_rouge1_for_TC           =     38.221
  predict_rouge1_for_amazon       =    30.7141
  predict_rouge1_for_dbpedia      =     4.0737
  predict_rouge1_for_yahoo        =    72.3684
  predict_rougeL                  =    35.7187
  predict_rougeL_for_SC           =    30.7141
  predict_rougeL_for_TC           =     38.221
  predict_rougeL_for_amazon       =    30.7141
  predict_rougeL_for_dbpedia      =     4.0737
  predict_rougeL_for_yahoo        =    72.3684
  predict_runtime                 = 0:03:16.32
  predict_samples                 =      22800
  predict_samples_per_second      =    116.134
  predict_steps_per_second        =      0.458
[rank0]:[W827 18:39:40.671017051 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[2025-08-27 18:39:42,545] [INFO] [launch.py:347:main] Process 776864 exits successfully.
[2025-08-27 18:39:42,546] [INFO] [launch.py:347:main] Process 776863 exits successfully.
+ sleep 5
+ CUDA_VISIBLE_DEVICES=6,7
+ deepspeed --master_port 28490 src/run_uie_lora.py --do_train --do_predict --predict_with_generate --model_name_or_path logs_and_outputs/sdlora/order_1/outputs/3-yahoo/adapter --data_dir CL_Benchmark --task_config_dir configs/order1_configs/agnews --instruction_file configs/instruction_config.json --instruction_strategy single --output_dir logs_and_outputs/sdlora/order_1/outputs/4-agnews --per_device_train_batch_size 8 --per_device_eval_batch_size 128 --gradient_accumulation_steps 1 --learning_rate 1e-03 --num_train_epochs 1 --deepspeed configs/ds_configs/stage2.config --run_name order1_round4_sdlora --max_source_length 512 --max_target_length 50 --generation_max_length 50 --add_task_name True --add_dataset_name True --overwrite_output_dir --overwrite_cache --lr_scheduler_type constant --warmup_steps 0 --logging_strategy steps --logging_steps 10 --evaluation_strategy no --save_strategy no --save_steps 1500 --lamda_1 0.5 --lamda_2 0 --peft_type SDLORA
[2025-08-27 18:39:50,784] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-08-27 18:39:51,956] [WARNING] [runner.py:196:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected CUDA_VISIBLE_DEVICES=6,7: setting --include=localhost:6,7
[2025-08-27 18:39:52,032] [INFO] [runner.py:555:main] cmd = /home/yongxi/miniconda3/envs/sd-lora/bin/python3.10 -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbNiwgN119 --master_addr=127.0.0.1 --master_port=28490 --enable_each_rank_log=None src/run_uie_lora.py --do_train --do_predict --predict_with_generate --model_name_or_path logs_and_outputs/sdlora/order_1/outputs/3-yahoo/adapter --data_dir CL_Benchmark --task_config_dir configs/order1_configs/agnews --instruction_file configs/instruction_config.json --instruction_strategy single --output_dir logs_and_outputs/sdlora/order_1/outputs/4-agnews --per_device_train_batch_size 8 --per_device_eval_batch_size 128 --gradient_accumulation_steps 1 --learning_rate 1e-03 --num_train_epochs 1 --deepspeed configs/ds_configs/stage2.config --run_name order1_round4_sdlora --max_source_length 512 --max_target_length 50 --generation_max_length 50 --add_task_name True --add_dataset_name True --overwrite_output_dir --overwrite_cache --lr_scheduler_type constant --warmup_steps 0 --logging_strategy steps --logging_steps 10 --evaluation_strategy no --save_strategy no --save_steps 1500 --lamda_1 0.5 --lamda_2 0 --peft_type SDLORA
[2025-08-27 18:39:53,217] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
[2025-08-27 18:39:54,488] [INFO] [launch.py:145:main] WORLD INFO DICT: {'localhost': [6, 7]}
[2025-08-27 18:39:54,488] [INFO] [launch.py:151:main] nnodes=1, num_local_procs=2, node_rank=0
[2025-08-27 18:39:54,488] [INFO] [launch.py:162:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1]})
[2025-08-27 18:39:54,488] [INFO] [launch.py:163:main] dist_world_size=2
[2025-08-27 18:39:54,488] [INFO] [launch.py:165:main] Setting CUDA_VISIBLE_DEVICES=6,7
[2025-08-27 18:39:56,738] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-27 18:39:56,759] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:49: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  def forward(ctx, input, weight, bias=None):
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/linear.py:67: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  def backward(ctx, grad_output):
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/fairscale/experimental/nn/offload.py:19: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_fwd(orig_func)  # type: ignore
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/fairscale/experimental/nn/offload.py:30: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_bwd(orig_func)  # type: ignore
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/fairscale/experimental/nn/offload.py:19: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_fwd(orig_func)  # type: ignore
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/fairscale/experimental/nn/offload.py:30: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  return torch.cuda.amp.custom_bwd(orig_func)  # type: ignore
[2025-08-27 18:39:57,646] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2025-08-27 18:39:57,646] [INFO] [comm.py:616:init_distributed] cdb=None
[2025-08-27 18:39:57,662] [WARNING] [comm.py:152:init_deepspeed_backend] NCCL backend in DeepSpeed not yet implemented
[2025-08-27 18:39:57,662] [INFO] [comm.py:616:init_distributed] cdb=None
[2025-08-27 18:39:57,662] [INFO] [comm.py:643:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
08/27/2025 18:39:58 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: False
08/27/2025 18:39:58 - WARNING - datasets.builder - Using custom data configuration default-c1ffe425bee4d951
Downloading and preparing dataset uie_instructions/default to logs_and_outputs/sdlora/order_1/outputs/4-agnews/895e4cf9c1b5eba6adaea9579a065a61/uie_instructions/default-c1ffe425bee4d951/2.0.0/c490e7f13dec80785fc335819009163a45c86ae2816040c8d81800108e7e4374...
Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).
08/27/2025 18:39:58 - WARNING - __main__ - Process rank: 1, device: cuda:1, n_gpu: 1distributed training: True, 16-bits training: False
08/27/2025 18:39:58 - WARNING - datasets.builder - Using custom data configuration default-c1ffe425bee4d951
08/27/2025 18:39:58 - WARNING - datasets.builder - HF google storage unreachable. Downloading and preparing it from source
0 examples [00:00, ? examples/s]3165 examples [00:00, 31645.88 examples/s]                                          0 examples [00:00, ? examples/s]                                0 examples [00:00, ? examples/s]1275 examples [00:00, 7643.00 examples/s]4553 examples [00:00, 19236.42 examples/s]7601 examples [00:00, 21213.89 examples/s]10000 examples [00:00, 22137.39 examples/s]13355 examples [00:00, 25843.21 examples/s]16112 examples [00:00, 26387.97 examples/s]19458 examples [00:00, 28590.17 examples/s]22383 examples [00:00, 27642.87 examples/s]25501 examples [00:01, 28692.55 examples/s]28450 examples [00:01, 21811.45 examples/s]                                           Dataset uie_instructions downloaded and prepared to logs_and_outputs/sdlora/order_1/outputs/4-agnews/895e4cf9c1b5eba6adaea9579a065a61/uie_instructions/default-c1ffe425bee4d951/2.0.0/c490e7f13dec80785fc335819009163a45c86ae2816040c8d81800108e7e4374. Subsequent calls will reuse this data.
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 1096.65it/s]
08/27/2025 18:40:00 - WARNING - datasets.builder - Reusing dataset uie_instructions (logs_and_outputs/sdlora/order_1/outputs/4-agnews/895e4cf9c1b5eba6adaea9579a065a61/uie_instructions/default-c1ffe425bee4d951/2.0.0/c490e7f13dec80785fc335819009163a45c86ae2816040c8d81800108e7e4374)
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 624.80it/s]
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/torch/nn/init.py:511: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/torch/nn/init.py:511: UserWarning: Initializing zero-element tensors is a no-op
  warnings.warn("Initializing zero-element tensors is a no-op")
-----Gradient checkpointing: False -----
-----Gradient checkpointing: False -----
[93m [WARNING] [0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!
Using /home/yongxi/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
[93m [WARNING] [0m cpu_adam cuda is missing or is incompatible with installed torch, only cpu ops can be compiled!
Using /home/yongxi/.cache/torch_extensions/py310_cu124 as PyTorch extensions root...
Emitting ninja build file /home/yongxi/.cache/torch_extensions/py310_cu124/cpu_adam/build.ninja...
Building extension module cpu_adam...
Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)
ninja: no work to do.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.4321014881134033 seconds
Rank: 0 partition count [2] and sizes[(1179648, False)] 
[rank0]:[W827 18:40:12.128642030 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
Loading extension module cpu_adam...
Time to load cpu_adam op: 2.4835901260375977 seconds
Rank: 1 partition count [2] and sizes[(1179648, False)] 
[rank1]:[W827 18:40:12.172947354 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3596: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  warnings.warn(
  0%|          | 0/250 [00:00<?, ?it/s]/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3596: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.
  warnings.warn(
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/torch/autograd/graph.py:823: UserWarning: c10d::broadcast_: an autograd kernel was not registered to the Autograd key(s) but we are trying to backprop through it. This may lead to silently incorrect behavior. This behavior is deprecated and will be removed in a future version of PyTorch. If your operator is differentiable, please ensure you have registered an autograd kernel to the correct Autograd key (e.g. DispatchKey::Autograd, DispatchKey::CompositeImplicitAutograd). If your operator is not differentiable, or to squash this warning and use the previous behavior, please register torch::CppFunction::makeFallthrough() to DispatchKey::Autograd. (Triggered internally at /pytorch/torch/csrc/autograd/autograd_not_implemented_fallback.cpp:62.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1830: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
/home/yongxi/miniconda3/envs/sd-lora/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1830: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /pytorch/torch/csrc/tensor/python_tensor.cpp:78.)
  overflow_gpu = get_accelerator().ByteTensor([overflow])
  0%|          | 1/250 [00:00<03:02,  1.36it/s]  1%|          | 2/250 [00:01<02:23,  1.73it/s]  1%|          | 3/250 [00:01<02:13,  1.86it/s]  2%|▏         | 4/250 [00:02<02:05,  1.95it/s]  2%|▏         | 5/250 [00:02<02:00,  2.03it/s]  2%|▏         | 6/250 [00:03<01:56,  2.09it/s]  3%|▎         | 7/250 [00:03<01:53,  2.13it/s]  3%|▎         | 8/250 [00:03<01:51,  2.16it/s]  4%|▎         | 9/250 [00:04<01:50,  2.18it/s]  4%|▍         | 10/250 [00:04<01:50,  2.18it/s]                                                {'loss': 1.4019, 'learning_rate': 0.001, 'epoch': 0.04}
  4%|▍         | 10/250 [00:04<01:50,  2.18it/s]  4%|▍         | 11/250 [00:05<01:49,  2.18it/s]  5%|▍         | 12/250 [00:05<01:48,  2.20it/s]  5%|▌         | 13/250 [00:06<01:49,  2.17it/s]  6%|▌         | 14/250 [00:06<01:48,  2.18it/s]  6%|▌         | 15/250 [00:07<01:47,  2.19it/s]  6%|▋         | 16/250 [00:07<01:46,  2.20it/s]  7%|▋         | 17/250 [00:08<01:45,  2.21it/s]  7%|▋         | 18/250 [00:08<01:45,  2.20it/s]  8%|▊         | 19/250 [00:08<01:44,  2.21it/s]  8%|▊         | 20/250 [00:09<01:43,  2.21it/s]                                                {'loss': 0.3103, 'learning_rate': 0.001, 'epoch': 0.08}
  8%|▊         | 20/250 [00:09<01:43,  2.21it/s]  8%|▊         | 21/250 [00:09<01:43,  2.20it/s]  9%|▉         | 22/250 [00:10<01:44,  2.19it/s]  9%|▉         | 23/250 [00:10<01:44,  2.18it/s] 10%|▉         | 24/250 [00:11<01:44,  2.16it/s] 10%|█         | 25/250 [00:11<01:43,  2.18it/s] 10%|█         | 26/250 [00:12<01:42,  2.18it/s] 11%|█         | 27/250 [00:12<01:42,  2.17it/s] 11%|█         | 28/250 [00:13<01:42,  2.16it/s] 12%|█▏        | 29/250 [00:13<01:42,  2.16it/s] 12%|█▏        | 30/250 [00:14<01:41,  2.17it/s]                                                {'loss': 0.1839, 'learning_rate': 0.001, 'epoch': 0.12}
 12%|█▏        | 30/250 [00:14<01:41,  2.17it/s] 12%|█▏        | 31/250 [00:14<01:41,  2.15it/s] 13%|█▎        | 32/250 [00:14<01:41,  2.14it/s] 13%|█▎        | 33/250 [00:15<01:41,  2.13it/s] 14%|█▎        | 34/250 [00:15<01:40,  2.15it/s] 14%|█▍        | 35/250 [00:16<01:39,  2.16it/s] 14%|█▍        | 36/250 [00:16<01:38,  2.17it/s] 15%|█▍        | 37/250 [00:17<01:38,  2.17it/s] 15%|█▌        | 38/250 [00:17<01:37,  2.18it/s] 16%|█▌        | 39/250 [00:18<01:37,  2.16it/s] 16%|█▌        | 40/250 [00:18<01:37,  2.15it/s]                                                {'loss': 0.2614, 'learning_rate': 0.001, 'epoch': 0.16}
 16%|█▌        | 40/250 [00:18<01:37,  2.15it/s] 16%|█▋        | 41/250 [00:19<01:36,  2.17it/s] 17%|█▋        | 42/250 [00:19<01:35,  2.18it/s] 17%|█▋        | 43/250 [00:20<01:35,  2.18it/s] 18%|█▊        | 44/250 [00:20<01:33,  2.19it/s] 18%|█▊        | 45/250 [00:20<01:32,  2.21it/s] 18%|█▊        | 46/250 [00:21<01:32,  2.20it/s] 19%|█▉        | 47/250 [00:21<01:31,  2.21it/s] 19%|█▉        | 48/250 [00:22<01:32,  2.18it/s] 20%|█▉        | 49/250 [00:22<01:31,  2.18it/s] 20%|██        | 50/250 [00:23<01:40,  1.98it/s]                                                {'loss': 0.1726, 'learning_rate': 0.001, 'epoch': 0.2}
 20%|██        | 50/250 [00:23<01:40,  1.98it/s] 20%|██        | 51/250 [00:23<01:37,  2.05it/s] 21%|██        | 52/250 [00:24<01:34,  2.09it/s] 21%|██        | 53/250 [00:24<01:33,  2.10it/s] 22%|██▏       | 54/250 [00:25<01:34,  2.07it/s] 22%|██▏       | 55/250 [00:25<01:33,  2.09it/s] 22%|██▏       | 56/250 [00:26<01:31,  2.11it/s] 23%|██▎       | 57/250 [00:26<01:30,  2.12it/s] 23%|██▎       | 58/250 [00:27<01:29,  2.14it/s] 24%|██▎       | 59/250 [00:27<01:29,  2.14it/s] 24%|██▍       | 60/250 [00:28<01:28,  2.14it/s]                                                {'loss': 0.188, 'learning_rate': 0.001, 'epoch': 0.24}
 24%|██▍       | 60/250 [00:28<01:28,  2.14it/s] 24%|██▍       | 61/250 [00:28<01:28,  2.14it/s] 25%|██▍       | 62/250 [00:28<01:27,  2.14it/s] 25%|██▌       | 63/250 [00:29<01:27,  2.14it/s] 26%|██▌       | 64/250 [00:29<01:26,  2.14it/s] 26%|██▌       | 65/250 [00:30<01:27,  2.12it/s] 26%|██▋       | 66/250 [00:30<01:26,  2.13it/s] 27%|██▋       | 67/250 [00:31<01:25,  2.14it/s] 27%|██▋       | 68/250 [00:31<01:25,  2.14it/s] 28%|██▊       | 69/250 [00:32<01:24,  2.14it/s] 28%|██▊       | 70/250 [00:32<01:23,  2.16it/s]                                                {'loss': 0.2032, 'learning_rate': 0.001, 'epoch': 0.28}
 28%|██▊       | 70/250 [00:32<01:23,  2.16it/s] 28%|██▊       | 71/250 [00:33<01:23,  2.13it/s] 29%|██▉       | 72/250 [00:33<01:23,  2.14it/s] 29%|██▉       | 73/250 [00:34<01:22,  2.14it/s] 30%|██▉       | 74/250 [00:34<01:22,  2.12it/s] 30%|███       | 75/250 [00:35<01:22,  2.12it/s] 30%|███       | 76/250 [00:35<01:22,  2.12it/s] 31%|███       | 77/250 [00:36<01:21,  2.13it/s] 31%|███       | 78/250 [00:36<01:20,  2.13it/s] 32%|███▏      | 79/250 [00:36<01:20,  2.13it/s] 32%|███▏      | 80/250 [00:37<01:19,  2.13it/s]                                                {'loss': 0.1633, 'learning_rate': 0.001, 'epoch': 0.32}
 32%|███▏      | 80/250 [00:37<01:19,  2.13it/s] 32%|███▏      | 81/250 [00:37<01:19,  2.13it/s] 33%|███▎      | 82/250 [00:38<01:18,  2.13it/s] 33%|███▎      | 83/250 [00:38<01:18,  2.14it/s] 34%|███▎      | 84/250 [00:39<01:18,  2.12it/s] 34%|███▍      | 85/250 [00:39<01:17,  2.12it/s] 34%|███▍      | 86/250 [00:40<01:18,  2.10it/s] 35%|███▍      | 87/250 [00:40<01:17,  2.10it/s] 35%|███▌      | 88/250 [00:41<01:18,  2.05it/s] 36%|███▌      | 89/250 [00:41<01:17,  2.08it/s] 36%|███▌      | 90/250 [00:42<01:16,  2.08it/s]                                                {'loss': 0.2301, 'learning_rate': 0.001, 'epoch': 0.36}
 36%|███▌      | 90/250 [00:42<01:16,  2.08it/s] 36%|███▋      | 91/250 [00:42<01:15,  2.09it/s] 37%|███▋      | 92/250 [00:43<01:14,  2.11it/s] 37%|███▋      | 93/250 [00:43<01:14,  2.10it/s] 38%|███▊      | 94/250 [00:44<01:15,  2.06it/s] 38%|███▊      | 95/250 [00:44<01:22,  1.88it/s] 38%|███▊      | 96/250 [00:45<01:19,  1.94it/s] 39%|███▉      | 97/250 [00:45<01:16,  2.00it/s] 39%|███▉      | 98/250 [00:46<01:14,  2.04it/s] 40%|███▉      | 99/250 [00:46<01:13,  2.06it/s] 40%|████      | 100/250 [00:47<01:12,  2.06it/s]                                                 {'loss': 0.1643, 'learning_rate': 0.001, 'epoch': 0.4}
 40%|████      | 100/250 [00:47<01:12,  2.06it/s] 40%|████      | 101/250 [00:47<01:12,  2.07it/s] 41%|████      | 102/250 [00:48<01:11,  2.07it/s] 41%|████      | 103/250 [00:48<01:10,  2.09it/s] 42%|████▏     | 104/250 [00:49<01:09,  2.10it/s] 42%|████▏     | 105/250 [00:49<01:08,  2.11it/s] 42%|████▏     | 106/250 [00:49<01:08,  2.11it/s] 43%|████▎     | 107/250 [00:50<01:13,  1.95it/s] 43%|████▎     | 108/250 [00:51<01:11,  2.00it/s] 44%|████▎     | 109/250 [00:51<01:09,  2.03it/s] 44%|████▍     | 110/250 [00:52<01:07,  2.06it/s]                                                 {'loss': 0.1682, 'learning_rate': 0.001, 'epoch': 0.44}
 44%|████▍     | 110/250 [00:52<01:07,  2.06it/s] 44%|████▍     | 111/250 [00:52<01:13,  1.90it/s] 45%|████▍     | 112/250 [00:53<01:10,  1.96it/s] 45%|████▌     | 113/250 [00:53<01:08,  2.01it/s] 46%|████▌     | 114/250 [00:54<01:06,  2.05it/s] 46%|████▌     | 115/250 [00:54<01:04,  2.08it/s] 46%|████▋     | 116/250 [00:54<01:04,  2.09it/s] 47%|████▋     | 117/250 [00:55<01:03,  2.09it/s] 47%|████▋     | 118/250 [00:55<01:02,  2.10it/s] 48%|████▊     | 119/250 [00:56<01:02,  2.11it/s] 48%|████▊     | 120/250 [00:56<01:01,  2.12it/s]                                                 {'loss': 0.1507, 'learning_rate': 0.001, 'epoch': 0.48}
 48%|████▊     | 120/250 [00:56<01:01,  2.12it/s] 48%|████▊     | 121/250 [00:57<01:00,  2.12it/s] 49%|████▉     | 122/250 [00:57<01:01,  2.09it/s] 49%|████▉     | 123/250 [00:58<01:00,  2.09it/s] 50%|████▉     | 124/250 [00:58<00:59,  2.10it/s] 50%|█████     | 125/250 [00:59<00:59,  2.11it/s] 50%|█████     | 126/250 [00:59<00:58,  2.12it/s] 51%|█████     | 127/250 [01:00<00:57,  2.13it/s] 51%|█████     | 128/250 [01:00<01:03,  1.93it/s] 52%|█████▏    | 129/250 [01:01<01:00,  1.99it/s] 52%|█████▏    | 130/250 [01:01<00:59,  2.02it/s]                                                 {'loss': 0.212, 'learning_rate': 0.001, 'epoch': 0.52}
 52%|█████▏    | 130/250 [01:01<00:59,  2.02it/s] 52%|█████▏    | 131/250 [01:02<00:58,  2.04it/s] 53%|█████▎    | 132/250 [01:02<00:57,  2.06it/s] 53%|█████▎    | 133/250 [01:03<00:58,  2.00it/s] 54%|█████▎    | 134/250 [01:03<00:56,  2.04it/s] 54%|█████▍    | 135/250 [01:04<00:55,  2.07it/s] 54%|█████▍    | 136/250 [01:04<00:54,  2.08it/s] 55%|█████▍    | 137/250 [01:05<00:54,  2.06it/s] 55%|█████▌    | 138/250 [01:05<00:54,  2.06it/s] 56%|█████▌    | 139/250 [01:06<00:53,  2.07it/s] 56%|█████▌    | 140/250 [01:06<00:58,  1.89it/s]                                                 {'loss': 0.1534, 'learning_rate': 0.001, 'epoch': 0.56}
 56%|█████▌    | 140/250 [01:06<00:58,  1.89it/s] 56%|█████▋    | 141/250 [01:07<00:56,  1.94it/s] 57%|█████▋    | 142/250 [01:07<00:54,  1.99it/s] 57%|█████▋    | 143/250 [01:08<00:52,  2.03it/s] 58%|█████▊    | 144/250 [01:08<00:51,  2.05it/s] 58%|█████▊    | 145/250 [01:09<00:50,  2.08it/s] 58%|█████▊    | 146/250 [01:09<00:50,  2.08it/s] 59%|█████▉    | 147/250 [01:10<00:49,  2.09it/s] 59%|█████▉    | 148/250 [01:10<00:48,  2.11it/s] 60%|█████▉    | 149/250 [01:10<00:47,  2.12it/s] 60%|██████    | 150/250 [01:11<00:47,  2.11it/s]                                                 {'loss': 0.1516, 'learning_rate': 0.001, 'epoch': 0.6}
 60%|██████    | 150/250 [01:11<00:47,  2.11it/s] 60%|██████    | 151/250 [01:11<00:46,  2.12it/s] 61%|██████    | 152/250 [01:12<00:46,  2.12it/s] 61%|██████    | 153/250 [01:12<00:45,  2.11it/s] 62%|██████▏   | 154/250 [01:13<00:45,  2.11it/s] 62%|██████▏   | 155/250 [01:13<00:44,  2.12it/s] 62%|██████▏   | 156/250 [01:14<00:44,  2.12it/s] 63%|██████▎   | 157/250 [01:14<00:44,  2.09it/s] 63%|██████▎   | 158/250 [01:15<00:44,  2.08it/s] 64%|██████▎   | 159/250 [01:15<00:43,  2.08it/s] 64%|██████▍   | 160/250 [01:16<00:43,  2.09it/s]                                                 {'loss': 0.197, 'learning_rate': 0.001, 'epoch': 0.64}
 64%|██████▍   | 160/250 [01:16<00:43,  2.09it/s] 64%|██████▍   | 161/250 [01:16<00:42,  2.10it/s] 65%|██████▍   | 162/250 [01:17<00:41,  2.10it/s] 65%|██████▌   | 163/250 [01:17<00:41,  2.11it/s] 66%|██████▌   | 164/250 [01:18<00:40,  2.11it/s] 66%|██████▌   | 165/250 [01:18<00:40,  2.08it/s] 66%|██████▋   | 166/250 [01:19<00:40,  2.08it/s] 67%|██████▋   | 167/250 [01:19<00:39,  2.09it/s] 67%|██████▋   | 168/250 [01:20<00:39,  2.07it/s] 68%|██████▊   | 169/250 [01:20<00:38,  2.09it/s] 68%|██████▊   | 170/250 [01:21<00:37,  2.11it/s]                                                 {'loss': 0.128, 'learning_rate': 0.001, 'epoch': 0.68}
 68%|██████▊   | 170/250 [01:21<00:37,  2.11it/s] 68%|██████▊   | 171/250 [01:21<00:37,  2.09it/s] 69%|██████▉   | 172/250 [01:21<00:37,  2.08it/s] 69%|██████▉   | 173/250 [01:22<00:40,  1.92it/s] 70%|██████▉   | 174/250 [01:23<00:38,  1.97it/s] 70%|███████   | 175/250 [01:23<00:37,  2.01it/s] 70%|███████   | 176/250 [01:24<00:36,  2.04it/s] 71%|███████   | 177/250 [01:24<00:35,  2.06it/s] 71%|███████   | 178/250 [01:24<00:34,  2.08it/s] 72%|███████▏  | 179/250 [01:25<00:34,  2.06it/s] 72%|███████▏  | 180/250 [01:25<00:33,  2.08it/s]                                                 {'loss': 0.1749, 'learning_rate': 0.001, 'epoch': 0.72}
 72%|███████▏  | 180/250 [01:25<00:33,  2.08it/s] 72%|███████▏  | 181/250 [01:26<00:33,  2.08it/s] 73%|███████▎  | 182/250 [01:26<00:32,  2.09it/s] 73%|███████▎  | 183/250 [01:27<00:31,  2.10it/s] 74%|███████▎  | 184/250 [01:27<00:31,  2.12it/s] 74%|███████▍  | 185/250 [01:28<00:30,  2.13it/s] 74%|███████▍  | 186/250 [01:28<00:29,  2.13it/s] 75%|███████▍  | 187/250 [01:29<00:29,  2.14it/s] 75%|███████▌  | 188/250 [01:29<00:29,  2.13it/s] 76%|███████▌  | 189/250 [01:30<00:28,  2.13it/s] 76%|███████▌  | 190/250 [01:30<00:28,  2.13it/s]                                                 {'loss': 0.2144, 'learning_rate': 0.001, 'epoch': 0.76}
 76%|███████▌  | 190/250 [01:30<00:28,  2.13it/s] 76%|███████▋  | 191/250 [01:31<00:27,  2.13it/s] 77%|███████▋  | 192/250 [01:31<00:27,  2.13it/s] 77%|███████▋  | 193/250 [01:32<00:26,  2.13it/s] 78%|███████▊  | 194/250 [01:32<00:26,  2.12it/s] 78%|███████▊  | 195/250 [01:32<00:26,  2.11it/s] 78%|███████▊  | 196/250 [01:33<00:25,  2.12it/s] 79%|███████▉  | 197/250 [01:33<00:25,  2.05it/s] 79%|███████▉  | 198/250 [01:34<00:25,  2.05it/s] 80%|███████▉  | 199/250 [01:34<00:24,  2.05it/s] 80%|████████  | 200/250 [01:35<00:24,  2.06it/s]                                                 {'loss': 0.1314, 'learning_rate': 0.001, 'epoch': 0.8}
 80%|████████  | 200/250 [01:35<00:24,  2.06it/s] 80%|████████  | 201/250 [01:35<00:23,  2.08it/s] 81%|████████  | 202/250 [01:36<00:24,  1.93it/s] 81%|████████  | 203/250 [01:36<00:23,  1.97it/s] 82%|████████▏ | 204/250 [01:37<00:22,  2.01it/s] 82%|████████▏ | 205/250 [01:37<00:22,  2.03it/s] 82%|████████▏ | 206/250 [01:38<00:21,  2.07it/s] 83%|████████▎ | 207/250 [01:38<00:20,  2.09it/s] 83%|████████▎ | 208/250 [01:39<00:19,  2.10it/s] 84%|████████▎ | 209/250 [01:39<00:19,  2.11it/s] 84%|████████▍ | 210/250 [01:40<00:18,  2.12it/s]                                                 {'loss': 0.237, 'learning_rate': 0.001, 'epoch': 0.84}
 84%|████████▍ | 210/250 [01:40<00:18,  2.12it/s] 84%|████████▍ | 211/250 [01:40<00:18,  2.13it/s] 85%|████████▍ | 212/250 [01:41<00:17,  2.13it/s] 85%|████████▌ | 213/250 [01:41<00:17,  2.14it/s] 86%|████████▌ | 214/250 [01:42<00:16,  2.14it/s] 86%|████████▌ | 215/250 [01:42<00:16,  2.14it/s] 86%|████████▋ | 216/250 [01:43<00:15,  2.15it/s] 87%|████████▋ | 217/250 [01:43<00:15,  2.14it/s] 87%|████████▋ | 218/250 [01:44<00:14,  2.13it/s] 88%|████████▊ | 219/250 [01:44<00:14,  2.12it/s] 88%|████████▊ | 220/250 [01:44<00:14,  2.11it/s]                                                 {'loss': 0.1663, 'learning_rate': 0.001, 'epoch': 0.88}
 88%|████████▊ | 220/250 [01:44<00:14,  2.11it/s] 88%|████████▊ | 221/250 [01:45<00:13,  2.11it/s] 89%|████████▉ | 222/250 [01:45<00:13,  2.11it/s] 89%|████████▉ | 223/250 [01:46<00:12,  2.12it/s] 90%|████████▉ | 224/250 [01:46<00:12,  2.11it/s] 90%|█████████ | 225/250 [01:47<00:11,  2.11it/s] 90%|█████████ | 226/250 [01:47<00:11,  2.11it/s] 91%|█████████ | 227/250 [01:48<00:11,  2.08it/s] 91%|█████████ | 228/250 [01:48<00:10,  2.09it/s] 92%|█████████▏| 229/250 [01:49<00:09,  2.11it/s] 92%|█████████▏| 230/250 [01:49<00:09,  2.09it/s]                                                 {'loss': 0.1756, 'learning_rate': 0.001, 'epoch': 0.92}
 92%|█████████▏| 230/250 [01:49<00:09,  2.09it/s] 92%|█████████▏| 231/250 [01:50<00:09,  2.10it/s] 93%|█████████▎| 232/250 [01:50<00:08,  2.12it/s] 93%|█████████▎| 233/250 [01:51<00:07,  2.13it/s] 94%|█████████▎| 234/250 [01:51<00:07,  2.12it/s] 94%|█████████▍| 235/250 [01:52<00:07,  2.10it/s] 94%|█████████▍| 236/250 [01:52<00:06,  2.12it/s] 95%|█████████▍| 237/250 [01:53<00:06,  2.06it/s] 95%|█████████▌| 238/250 [01:53<00:05,  2.08it/s] 96%|█████████▌| 239/250 [01:54<00:05,  2.10it/s] 96%|█████████▌| 240/250 [01:54<00:04,  2.11it/s]                                                 {'loss': 0.1713, 'learning_rate': 0.001, 'epoch': 0.96}
 96%|█████████▌| 240/250 [01:54<00:04,  2.11it/s] 96%|█████████▋| 241/250 [01:54<00:04,  2.12it/s] 97%|█████████▋| 242/250 [01:55<00:03,  2.11it/s] 97%|█████████▋| 243/250 [01:55<00:03,  2.12it/s] 98%|█████████▊| 244/250 [01:56<00:02,  2.14it/s] 98%|█████████▊| 245/250 [01:56<00:02,  2.14it/s] 98%|█████████▊| 246/250 [01:57<00:01,  2.15it/s] 99%|█████████▉| 247/250 [01:57<00:01,  2.15it/s] 99%|█████████▉| 248/250 [01:58<00:00,  2.14it/s]100%|█████████▉| 249/250 [01:58<00:00,  2.14it/s]100%|██████████| 250/250 [01:59<00:00,  2.14it/s]                                                 {'loss': 0.1533, 'learning_rate': 0.001, 'epoch': 1.0}
100%|██████████| 250/250 [01:59<00:00,  2.14it/s]                                                 {'train_runtime': 119.1667, 'train_samples_per_second': 33.566, 'train_steps_per_second': 2.098, 'train_loss': 0.23456982421875, 'epoch': 1.0}
100%|██████████| 250/250 [01:59<00:00,  2.14it/s]100%|██████████| 250/250 [01:59<00:00,  2.10it/s]
***** train metrics *****
  epoch                    =        1.0
  train_loss               =     0.2346
  train_runtime            = 0:01:59.16
  train_samples            =       4000
  train_samples_per_second =     33.566
  train_steps_per_second   =      2.098
  0%|          | 0/119 [00:00<?, ?it/s]  2%|▏         | 2/119 [00:01<01:24,  1.39it/s]  3%|▎         | 3/119 [00:03<02:08,  1.11s/it]  3%|▎         | 4/119 [00:04<02:22,  1.23s/it]  4%|▍         | 5/119 [00:06<02:30,  1.32s/it]  5%|▌         | 6/119 [00:07<02:34,  1.37s/it]  6%|▌         | 7/119 [00:08<02:31,  1.35s/it]  7%|▋         | 8/119 [00:10<02:30,  1.36s/it]  8%|▊         | 9/119 [00:12<02:47,  1.53s/it]  8%|▊         | 10/119 [00:13<02:58,  1.64s/it]  9%|▉         | 11/119 [00:15<02:46,  1.54s/it] 10%|█         | 12/119 [00:16<02:41,  1.51s/it] 11%|█         | 13/119 [00:18<02:38,  1.49s/it] 12%|█▏        | 14/119 [00:19<02:38,  1.51s/it] 13%|█▎        | 15/119 [00:21<02:48,  1.62s/it] 13%|█▎        | 16/119 [00:23<02:40,  1.56s/it] 14%|█▍        | 17/119 [00:25<03:11,  1.87s/it] 15%|█▌        | 18/119 [00:27<02:56,  1.75s/it] 16%|█▌        | 19/119 [00:28<02:43,  1.63s/it] 17%|█▋        | 20/119 [00:29<02:33,  1.56s/it] 18%|█▊        | 21/119 [00:31<02:26,  1.49s/it] 18%|█▊        | 22/119 [00:32<02:21,  1.46s/it] 19%|█▉        | 23/119 [00:34<02:28,  1.55s/it] 20%|██        | 24/119 [00:35<02:31,  1.59s/it] 21%|██        | 25/119 [00:37<02:26,  1.56s/it] 22%|██▏       | 26/119 [00:38<02:19,  1.50s/it] 23%|██▎       | 27/119 [00:40<02:15,  1.47s/it] 24%|██▎       | 28/119 [00:41<02:09,  1.42s/it] 24%|██▍       | 29/119 [00:43<02:12,  1.48s/it] 25%|██▌       | 30/119 [00:45<02:41,  1.81s/it] 26%|██▌       | 31/119 [00:48<03:00,  2.05s/it] 27%|██▋       | 32/119 [00:50<03:13,  2.22s/it] 28%|██▊       | 33/119 [00:53<03:20,  2.33s/it] 29%|██▊       | 34/119 [00:56<03:25,  2.42s/it] 29%|██▉       | 35/119 [00:58<03:27,  2.47s/it] 30%|███       | 36/119 [01:01<03:29,  2.52s/it] 31%|███       | 37/119 [01:04<03:29,  2.55s/it] 32%|███▏      | 38/119 [01:06<03:26,  2.55s/it] 33%|███▎      | 39/119 [01:09<03:25,  2.57s/it] 34%|███▎      | 40/119 [01:11<03:23,  2.58s/it] 34%|███▍      | 41/119 [01:14<03:21,  2.59s/it] 35%|███▌      | 42/119 [01:16<03:19,  2.59s/it] 36%|███▌      | 43/119 [01:19<03:17,  2.60s/it] 37%|███▋      | 44/119 [01:22<03:15,  2.60s/it] 38%|███▊      | 45/119 [01:24<03:12,  2.60s/it] 39%|███▊      | 46/119 [01:27<03:09,  2.60s/it] 39%|███▉      | 47/119 [01:30<03:07,  2.60s/it] 40%|████      | 48/119 [01:32<03:05,  2.61s/it] 41%|████      | 49/119 [01:35<03:02,  2.60s/it] 42%|████▏     | 50/119 [01:37<02:59,  2.60s/it] 43%|████▎     | 51/119 [01:40<02:57,  2.61s/it] 44%|████▎     | 52/119 [01:43<02:54,  2.61s/it] 45%|████▍     | 53/119 [01:45<02:52,  2.61s/it] 45%|████▌     | 54/119 [01:48<02:49,  2.61s/it] 46%|████▌     | 55/119 [01:50<02:47,  2.61s/it] 47%|████▋     | 56/119 [01:53<02:44,  2.61s/it] 48%|████▊     | 57/119 [01:56<02:42,  2.61s/it] 49%|████▊     | 58/119 [01:58<02:39,  2.61s/it] 50%|████▉     | 59/119 [02:01<02:36,  2.62s/it] 50%|█████     | 60/119 [02:03<02:33,  2.60s/it] 51%|█████▏    | 61/119 [02:05<02:08,  2.21s/it] 52%|█████▏    | 62/119 [02:06<01:44,  1.84s/it] 53%|█████▎    | 63/119 [02:07<01:29,  1.60s/it] 54%|█████▍    | 64/119 [02:08<01:17,  1.40s/it] 55%|█████▍    | 65/119 [02:09<01:08,  1.27s/it] 55%|█████▌    | 66/119 [02:10<01:01,  1.16s/it] 56%|█████▋    | 67/119 [02:10<00:56,  1.08s/it] 57%|█████▋    | 68/119 [02:11<00:54,  1.06s/it] 58%|█████▊    | 69/119 [02:12<00:50,  1.02s/it] 59%|█████▉    | 70/119 [02:13<00:50,  1.02s/it] 60%|█████▉    | 71/119 [02:14<00:48,  1.01s/it] 61%|██████    | 72/119 [02:17<01:07,  1.44s/it] 61%|██████▏   | 73/119 [02:18<00:59,  1.29s/it] 62%|██████▏   | 74/119 [02:19<00:57,  1.28s/it] 63%|██████▎   | 75/119 [02:20<00:50,  1.16s/it] 64%|██████▍   | 76/119 [02:21<00:46,  1.08s/it] 65%|██████▍   | 77/119 [02:22<00:43,  1.04s/it] 66%|██████▌   | 78/119 [02:23<00:40,  1.00it/s] 66%|██████▋   | 79/119 [02:24<00:39,  1.01it/s] 67%|██████▋   | 80/119 [02:25<00:38,  1.03it/s] 68%|██████▊   | 81/119 [02:27<00:53,  1.42s/it] 69%|██████▉   | 82/119 [02:28<00:47,  1.28s/it] 70%|██████▉   | 83/119 [02:29<00:42,  1.19s/it] 71%|███████   | 84/119 [02:30<00:42,  1.20s/it] 71%|███████▏  | 85/119 [02:31<00:40,  1.18s/it] 72%|███████▏  | 86/119 [02:32<00:37,  1.14s/it] 73%|███████▎  | 87/119 [02:33<00:35,  1.10s/it] 74%|███████▍  | 88/119 [02:34<00:34,  1.11s/it] 75%|███████▍  | 89/119 [02:36<00:32,  1.09s/it] 76%|███████▌  | 90/119 [02:37<00:34,  1.19s/it] 76%|███████▋  | 91/119 [02:38<00:30,  1.08s/it] 77%|███████▋  | 92/119 [02:39<00:26,  1.02it/s] 78%|███████▊  | 93/119 [02:39<00:23,  1.10it/s] 79%|███████▉  | 94/119 [02:40<00:23,  1.09it/s] 80%|███████▉  | 95/119 [02:41<00:22,  1.09it/s] 81%|████████  | 96/119 [02:42<00:21,  1.08it/s] 82%|████████▏ | 97/119 [02:43<00:20,  1.06it/s] 82%|████████▏ | 98/119 [02:44<00:20,  1.03it/s] 83%|████████▎ | 99/119 [02:45<00:18,  1.10it/s] 84%|████████▍ | 100/119 [02:46<00:17,  1.07it/s] 85%|████████▍ | 101/119 [02:47<00:19,  1.08s/it] 86%|████████▌ | 102/119 [02:48<00:18,  1.11s/it] 87%|████████▋ | 103/119 [02:50<00:17,  1.10s/it] 87%|████████▋ | 104/119 [02:51<00:16,  1.11s/it] 88%|████████▊ | 105/119 [02:51<00:14,  1.01s/it] 89%|████████▉ | 106/119 [02:53<00:13,  1.03s/it] 90%|████████▉ | 107/119 [02:53<00:11,  1.06it/s] 91%|█████████ | 108/119 [02:54<00:09,  1.14it/s] 92%|█████████▏| 109/119 [02:55<00:09,  1.10it/s] 92%|█████████▏| 110/119 [02:56<00:08,  1.09it/s] 93%|█████████▎| 111/119 [02:57<00:06,  1.17it/s] 94%|█████████▍| 112/119 [02:57<00:05,  1.23it/s] 95%|█████████▍| 113/119 [02:58<00:04,  1.29it/s] 96%|█████████▌| 114/119 [02:59<00:03,  1.31it/s] 97%|█████████▋| 115/119 [03:00<00:03,  1.16it/s] 97%|█████████▋| 116/119 [03:01<00:02,  1.21it/s] 98%|█████████▊| 117/119 [03:02<00:01,  1.09it/s] 99%|█████████▉| 118/119 [03:02<00:00,  1.15it/s]100%|██████████| 119/119 [03:04<00:00,  1.06s/it]100%|██████████| 119/119 [03:18<00:00,  1.67s/it]
***** predict metrics *****
  epoch                           =        1.0
  predict_exact_match             =    28.0296
  predict_exact_match_for_SC      =     0.4342
  predict_exact_match_for_TC      =    37.2281
  predict_exact_match_for_agnews  =    87.5132
  predict_exact_match_for_amazon  =     0.4342
  predict_exact_match_for_dbpedia =     0.3553
  predict_exact_match_for_yahoo   =    23.8158
  predict_gen_len                 =     4.1542
  predict_global_step             =        250
  predict_loss                    =     1.8622
  predict_rouge1                  =    30.7956
  predict_rouge1_for_SC           =     1.4583
  predict_rouge1_for_TC           =    40.5747
  predict_rouge1_for_agnews       =    87.5132
  predict_rouge1_for_amazon       =     1.4583
  predict_rouge1_for_dbpedia      =     4.1737
  predict_rouge1_for_yahoo        =    30.0373
  predict_rougeL                  =    30.7956
  predict_rougeL_for_SC           =     1.4583
  predict_rougeL_for_TC           =    40.5747
  predict_rougeL_for_agnews       =    87.5132
  predict_rougeL_for_amazon       =     1.4583
  predict_rougeL_for_dbpedia      =     4.1737
  predict_rougeL_for_yahoo        =    30.0373
  predict_runtime                 = 0:03:19.73
  predict_samples                 =      30400
  predict_samples_per_second      =    152.205
  predict_steps_per_second        =      0.596
[rank0]:[W827 18:45:32.376005633 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[2025-08-27 18:45:33,841] [INFO] [launch.py:347:main] Process 788056 exits successfully.
[2025-08-27 18:45:33,841] [INFO] [launch.py:347:main] Process 788055 exits successfully.
